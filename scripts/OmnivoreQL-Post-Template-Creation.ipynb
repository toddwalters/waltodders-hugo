{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Try with omnivoreql python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 23:34:58,197 - INFO - >>> {\"query\": \"query Search($after: String, $first: Int, $query: String, $format: String, $includeContent: Boolean) {\\n  search(\\n    after: $after\\n    first: $first\\n    query: $query\\n    format: $format\\n    includeContent: $includeContent\\n  ) {\\n    ... on SearchSuccess {\\n      edges {\\n        cursor\\n        node {\\n          id\\n          title\\n          slug\\n          url\\n          pageType\\n          contentReader\\n          createdAt\\n          isArchived\\n          readingProgressPercent\\n          readingProgressTopPercent\\n          readingProgressAnchorIndex\\n          author\\n          image\\n          description\\n          publishedAt\\n          ownedByViewer\\n          originalArticleUrl\\n          uploadFileId\\n          labels {\\n            id\\n            name\\n            color\\n          }\\n          pageId\\n          shortId\\n          quote\\n          annotation\\n          state\\n          siteName\\n          subscription\\n          readAt\\n          savedAt\\n          wordsCount\\n          recommendations {\\n            id\\n            name\\n            note\\n            user {\\n              userId\\n              name\\n              username\\n              profileImageURL\\n            }\\n            recommendedAt\\n          }\\n          highlights {\\n            ...HighlightFields\\n          }\\n        }\\n      }\\n      pageInfo {\\n        hasNextPage\\n        hasPreviousPage\\n        startCursor\\n        endCursor\\n        totalCount\\n      }\\n    }\\n    ... on SearchError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\", \"variables\": {\"first\": 100, \"after\": null, \"query\": \"in:inbox AND label:projects\", \"format\": \"markdown\", \"includeContent\": false}}\n",
      "2024-07-04 23:34:58,630 - INFO - <<< {\"data\":{\"search\":{\"edges\":[{\"cursor\":\"15\",\"node\":{\"id\":\"2e4b0a72-13a3-45e4-b5b0-bab886c0b111\",\"title\":\"Deploying A GPT-4o Model to Azure OpenAI Service - Trailhead Technology Partners\",\"slug\":\"https-trailheadtechnology-com-deploying-a-gpt-4-o-model-to-azure-1906b182ea4\",\"url\":\"https://trailheadtechnology.com/deploying-a-gpt-4o-model-to-azure-openai-service/\",\"pageType\":\"ARTICLE\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-06-30T21:41:05.000Z\",\"isArchived\":false,\"readingProgressPercent\":0.1,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"author\":\"Rodrigo Juarez\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sKZK6kFR7_PKqX_JIdummEkeaCkcWcKdOr0XoXy9JAI4/https://trailheadtechnology.com/wp-content/uploads/2024/05/deploying-4o-featured.jpeg\",\"description\":\"Azure OpenAI Service enables easy deployment of powerful language models like GPT-4o. This guide walks you through the process, from securing access and creating resources in the Azure portal to navigating the updated Azure AI Studio for model selection and configuration. The interactive playground allows for testing and fine-tuning, while secure API access ensures robust integration into your applications.\",\"publishedAt\":\"2024-06-27T14:00:00.000Z\",\"ownedByViewer\":null,\"originalArticleUrl\":\"https://trailheadtechnology.com/deploying-a-gpt-4o-model-to-azure-openai-service/\",\"uploadFileId\":null,\"labels\":[{\"id\":\"9bff1418-3729-11ef-b015-b3532a972baf\",\"name\":\"azure\",\"color\":\"#524A9E\"},{\"id\":\"be7ee338-ad04-11ee-b29e-cf84be09e663\",\"name\":\"openai\",\"color\":\"#57B5D4\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"Trailhead Technology Partners\",\"subscription\":null,\"readAt\":\"2024-07-01T15:00:00.000Z\",\"savedAt\":\"2024-07-03T13:34:16.000Z\",\"wordsCount\":1033,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"94b33d3a-c5e7-4347-aab4-73324363ab25\",\"title\":\"Using Generative AI to Create Runnable Markdown | Docker\",\"slug\":\"https-www-docker-com-blog-using-generative-ai-to-create-runnable-19078cbf9fa\",\"url\":\"https://www.docker.com/blog/using-generative-ai-to-create-runnable-markdown/\",\"pageType\":\"ARTICLE\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-07-03T13:32:32.000Z\",\"isArchived\":false,\"readingProgressPercent\":0,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"author\":null,\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,smSkV8X7PVY76JCcwEy8b6gGRsLBdP4fZbdsD5bWrW3A/https://www.docker.com/wp-content/uploads/2024/06/1300x1300_docker-labs-genai-1024x1024.png\",\"description\":\"Explore the innovative realm of AI developer tools with Docker's GenAI Docker Labs series. Join us as we dive deep into the potential of AI. Discover how generative AI can assist with documentation, project-specific tasks, and more throughout the software lifecycle. Stay updated and get involved with Docker's latest projects and tools.\",\"publishedAt\":\"2024-07-01T13:00:00.000Z\",\"ownedByViewer\":null,\"originalArticleUrl\":\"https://www.docker.com/blog/using-generative-ai-to-create-runnable-markdown/\",\"uploadFileId\":null,\"labels\":[{\"id\":\"34f92374-3884-11ef-b94a-9763ab0a35f8\",\"name\":\"tools\",\"color\":\"#34FFE6\"},{\"id\":\"9fff5d06-0a20-11ef-bcb5-ebe254c07f4f\",\"name\":\"markdown\",\"color\":\"#290845\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"Docker\",\"subscription\":null,\"readAt\":null,\"savedAt\":\"2024-07-03T13:32:35.000Z\",\"wordsCount\":941,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"544cff6c-b982-4e94-8bd1-23900d88039b\",\"title\":\"GitHub - posit-dev/positron: Positron, a next-generation data science IDE\",\"slug\":\"https-github-com-posit-dev-positron-19078b49470\",\"url\":\"https://github.com/posit-dev/positron\",\"pageType\":\"UNKNOWN\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-07-03T13:06:58.000Z\",\"isArchived\":false,\"readingProgressPercent\":0,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"author\":\"posit-dev\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,skhjgBSx8AkqOY6W_NexziPCNp5kV3_cpU4NAM1zeuMI/https://opengraph.githubassets.com/64033c9202d1a6346bb5042f625e396da1dbf5fa4f956a171bf31f9de5658c49/posit-dev/positron\",\"description\":\"Positron, a next-generation data science IDE. Contribute to posit-dev/positron development by creating an account on GitHub.\",\"publishedAt\":null,\"ownedByViewer\":null,\"originalArticleUrl\":\"https://github.com/posit-dev/positron\",\"uploadFileId\":null,\"labels\":[{\"id\":\"34f92374-3884-11ef-b94a-9763ab0a35f8\",\"name\":\"tools\",\"color\":\"#34FFE6\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"},{\"id\":\"fcf97d42-3163-11ef-be29-f7e1d42d0b74\",\"name\":\"data-science\",\"color\":\"#7CFF7B\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"GitHub\",\"subscription\":null,\"readAt\":null,\"savedAt\":\"2024-07-03T13:06:58.000Z\",\"wordsCount\":74,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"00111934-bc85-40cc-9bd3-ef4b1c701cf9\",\"title\":\"Quill - AI-powered SEC filing platform\",\"slug\":\"https-quillai-com-ref-therundown-190789acd1b\",\"url\":\"https://quillai.com/?ref=therundown\",\"pageType\":\"UNKNOWN\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-07-03T12:38:49.000Z\",\"isArchived\":false,\"readingProgressPercent\":0,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"author\":null,\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sglEwXZ_KqQSnTWe23tHPK_RPUiD67mlYUbtZAYyTs-s/https://raw.githubusercontent.com/quill-ai/images/main/quill-banner-black.png\",\"description\":\"Leverage Quill's financially-tuned AI to quickly answer questions about any company’s public investor materials. Each response includes state-of-the-art sentence-level source citations that take you back to the relevant filings.\",\"publishedAt\":\"2023-06-27T00:00:00.000Z\",\"ownedByViewer\":null,\"originalArticleUrl\":\"https://quillai.com/?ref=therundown\",\"uploadFileId\":null,\"labels\":[{\"id\":\"34f92374-3884-11ef-b94a-9763ab0a35f8\",\"name\":\"tools\",\"color\":\"#34FFE6\"},{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"quillai.com\",\"subscription\":null,\"readAt\":null,\"savedAt\":\"2024-07-03T12:38:51.000Z\",\"wordsCount\":482,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"ef15fb74-5366-4fd4-9ced-06ce936ccaab\",\"title\":\"GPT4All\",\"slug\":\"https-www-nomic-ai-gpt-4-all-ref-therundown-1907899156f\",\"url\":\"https://www.nomic.ai/gpt4all?ref=therundown\",\"pageType\":\"UNKNOWN\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-07-03T12:36:56.000Z\",\"isArchived\":false,\"readingProgressPercent\":100,\"readingProgressTopPercent\":87,\"readingProgressAnchorIndex\":91,\"author\":null,\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sFEYiFq3AJZNc0AOguBGbrLuBAv3DsYxAVaeZpqKti1g/https://homepage-gw3wguthh-nomic-ai.vercel.app/opengraph-image-gpt4all.png\",\"description\":\"Run Large Language Models Locally: privacy-first and no internet required\",\"publishedAt\":null,\"ownedByViewer\":null,\"originalArticleUrl\":\"https://www.nomic.ai/gpt4all?ref=therundown\",\"uploadFileId\":null,\"labels\":[{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"nomic.ai\",\"subscription\":null,\"readAt\":\"2024-07-04T17:20:02.000Z\",\"savedAt\":\"2024-07-03T12:37:00.000Z\",\"wordsCount\":323,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"73d61177-38d3-442b-9ad7-a41bd7800591\",\"title\":\"My 5 favorite ways of keeping the technical axe sharp - same stuff, different day\",\"slug\":\"https-samestuffdifferentday-net-2024-06-27-learning-part-2-19064954fdc\",\"url\":\"https://samestuffdifferentday.net/2024/06/27/learning-part2/\",\"pageType\":\"ARTICLE\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-06-29T15:20:25.000Z\",\"isArchived\":false,\"readingProgressPercent\":0.1,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"author\":\"Michael Eaton\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sGqD6dR3e0aHiXwDyRtGAC6A5SpbmDkmANshRHKpJqUs/https://samestuffdifferentday.net/assets/2024/learning.jpg\",\"description\":\"The one where I talk about keeping my tech skills sharp.\",\"publishedAt\":\"2024-06-27T11:00:00.000Z\",\"ownedByViewer\":null,\"originalArticleUrl\":\"https://samestuffdifferentday.net/2024/06/27/learning-part2/\",\"uploadFileId\":null,\"labels\":[{\"id\":\"8ccf8c92-a729-11ee-86b2-131a6b51de26\",\"name\":\"learning\",\"color\":\"#DEF0BA\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"same stuff, different day\",\"subscription\":null,\"readAt\":\"2024-07-01T15:01:01.000Z\",\"savedAt\":\"2024-06-29T15:20:25.000Z\",\"wordsCount\":567,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"af8eec2b-780e-4a94-bf7a-19e2a72d0ea1\",\"title\":\"Build Rag With Llamaindex To Make LLM Answer About Yourself, Like in an Interview or About General Information | by Lakshmi Narayana Santha | May, 2024 | Towards AI\",\"slug\":\"https-pub-towardsai-net-build-rag-with-llamaindex-to-make-llm-an-1905674e7f5\",\"url\":\"https://pub.towardsai.net/build-rag-with-llamaindex-to-make-llm-answer-about-yourself-like-in-interview-or-about-general-68bb2037f8b6?gi=d379a686b47c\",\"pageType\":\"ARTICLE\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-06-26T21:30:26.000Z\",\"isArchived\":false,\"readingProgressPercent\":0.1,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"author\":\"Lakshmi Narayana Santha\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sF_ePdV29i1LheQhORBjVkHFTGUYA0d4sx8ExVHt8_Mk/https://miro.medium.com/v2/resize:fit:1200/1*6q69styF-M0oDu-f9k8AHw.jpeg\",\"description\":\"From the day ChatGPT was introduced, the whole NLP/AI ecosystem was changed and came up with numerous new techniques to integrate the LLMs into various fields and use-cases. One of those gems that…\",\"publishedAt\":\"2024-05-26T21:05:24.000Z\",\"ownedByViewer\":null,\"originalArticleUrl\":\"https://pub.towardsai.net/build-rag-with-llamaindex-to-make-llm-answer-about-yourself-like-in-interview-or-about-general-68bb2037f8b6?gi=d379a686b47c\",\"uploadFileId\":null,\"labels\":[{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"},{\"id\":\"23050f0a-a754-11ee-9ac0-7781771f40cc\",\"name\":\"rag\",\"color\":\"#2B33B3\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"Towards AI\",\"subscription\":null,\"readAt\":\"2024-07-01T15:01:01.000Z\",\"savedAt\":\"2024-06-26T21:30:25.000Z\",\"wordsCount\":1769,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"2b01bd32-2b2b-48a2-9269-75c3fe1e973c\",\"title\":\"GitHub - squaredtechnologies/thread: AI-Powered Jupyter Notebook built using React\",\"slug\":\"https-github-com-squaredtechnologies-thread-19007f81c32\",\"url\":\"https://github.com/squaredtechnologies/thread\",\"pageType\":\"UNKNOWN\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-06-11T15:43:39.000Z\",\"isArchived\":false,\"readingProgressPercent\":79,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":12,\"author\":\"squaredtechnologies\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,svAp5XibUO3Uvpk8PCo6uVacWJlrnUJalSbKo_T0Zs4I/https://github.com/AI-Powered%20Jupyter%20Notebook%20built%20using%20React.%20Contribute%20to%20squaredtechnologies/thread%20development%20by%20creating%20an%20account%20on%20GitHub.\",\"description\":\"AI-Powered Jupyter Notebook built using React. Contribute to squaredtechnologies/thread development by creating an account on GitHub.\",\"publishedAt\":null,\"ownedByViewer\":null,\"originalArticleUrl\":\"https://github.com/squaredtechnologies/thread\",\"uploadFileId\":null,\"labels\":[{\"id\":\"4784410c-3160-11ef-af1b-d3d9c4d57542\",\"name\":\"jupyter-notebook\",\"color\":\"#5791C7\"},{\"id\":\"4d188510-3160-11ef-95ac-476b5d5c1917\",\"name\":\"ollama\",\"color\":\"#CC5433\"},{\"id\":\"7b8cce22-ad05-11ee-8a20-cb19d834d783\",\"name\":\"ai\",\"color\":\"#FFFCE3\"},{\"id\":\"b02fecd0-b7f6-11ee-a2a9-c3207c9538ff\",\"name\":\"python\",\"color\":\"#21BDFF\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"GitHub\",\"subscription\":null,\"readAt\":\"2024-06-24T02:11:01.000Z\",\"savedAt\":\"2024-06-11T15:43:42.000Z\",\"wordsCount\":74,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"933c6b4b-0a25-4f5a-9b0f-e44b352bddd8\",\"title\":\"Meet Verba 1.0: Run State-of-the-Art RAG Locally with Ollama Integration and Open Source Models - MarkTechPost\",\"slug\":\"https-www-marktechpost-com-2024-05-19-meet-verba-1-0-run-state-o-18f9da53dc3\",\"url\":\"https://www.marktechpost.com/2024/05/19/meet-verba-1-0-run-state-of-the-art-rag-locally-with-ollama-integration-and-open-source-models/?amp=\",\"pageType\":\"ARTICLE\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-05-22T00:13:23.000Z\",\"isArchived\":false,\"readingProgressPercent\":94,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":28,\"author\":\"Asif Razzaq\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,svK9eP_lW5jXltNjE2p6kB7-ajWFH1QTZ3X3Q3eKGAxY/https://www.marktechpost.com/wp-content/uploads/2024/05/verba_screen.png\",\"description\":\"Retrieval-augmented generation (RAG) is a cutting-edge technique in artificial intelligence that combines the strengths of retrieval-based approaches with generative models. This integration allows for creating high-quality, contextually relevant responses by leveraging vast datasets. RAG has significantly improved the performance of virtual assistants, chatbots, and information retrieval systems by ensuring that generated responses are accurate and contextually appropriate. The synergy of retrieval and generation enhances the user experience by providing detailed and specific information. One of the primary challenges in AI is delivering precise and contextually relevant information from extensive datasets. Traditional methods often need help maintaining the necessary context, leading\",\"publishedAt\":\"2024-05-20T04:45:10.000Z\",\"ownedByViewer\":null,\"originalArticleUrl\":\"https://www.marktechpost.com/2024/05/19/meet-verba-1-0-run-state-of-the-art-rag-locally-with-ollama-integration-and-open-source-models/?amp=\",\"uploadFileId\":null,\"labels\":[{\"id\":\"23050f0a-a754-11ee-9ac0-7781771f40cc\",\"name\":\"rag\",\"color\":\"#2B33B3\"},{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\"},{\"id\":\"8f4ce554-2916-11ef-8161-fbb712d47c7f\",\"name\":\"github\",\"color\":\"#3B7AD6\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"},{\"id\":\"ccd77f96-315a-11ef-9ad5-3f5267ab5c7e\",\"name\":\"_add2blog\",\"color\":\"#DC34FF\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"MarkTechPost\",\"subscription\":null,\"readAt\":\"2024-06-11T00:23:01.000Z\",\"savedAt\":\"2024-05-22T00:13:26.000Z\",\"wordsCount\":755,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"81756117-7cc2-4c9a-8f99-2ad9b09072d8\",\"title\":\"How to Use LangChain to Build With LLMs – A Beginner's Guide\",\"slug\":\"https-www-freecodecamp-org-news-beginners-guide-to-langchain-18ed9ea2aae\",\"url\":\"https://www.freecodecamp.org/news/beginners-guide-to-langchain/\",\"pageType\":\"ARTICLE\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-04-14T00:03:06.000Z\",\"isArchived\":false,\"readingProgressPercent\":0,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"author\":\"Jacob Lee\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,slAcKNRHBeiEW8ZyPZLa2cI44rOXxk049Ah0RHUQePmg/https://www.freecodecamp.org/news/content/images/2024/04/freecodecamp_cover_image.png\",\"description\":\"Large language models (LLMs) are incredibly powerful general reasoning tools\\nthat are useful in a wide range of situations. \\n\\nBut working with LLMs presents challenges that are different from building\\ntraditional software:\\n\\n * Calls tend to be long-running, and stream generate output as it becomes\\n   available.\\n * Instead of structured input (something like JSON) with fixed parameters, they\\n   take unstructured and arbitrary natural language as input. They are capable\\n   of “understanding” subtl\",\"publishedAt\":\"2024-04-11T23:11:37.000Z\",\"ownedByViewer\":null,\"originalArticleUrl\":\"https://www.freecodecamp.org/news/beginners-guide-to-langchain/\",\"uploadFileId\":null,\"labels\":[{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"},{\"id\":\"e50d4514-3164-11ef-897b-8f6ac75b1612\",\"name\":\"langchain\",\"color\":\"#7BE4FF\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"freeCodeCamp.org\",\"subscription\":null,\"readAt\":null,\"savedAt\":\"2024-04-14T00:03:10.000Z\",\"wordsCount\":2572,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"1a1a23df-2977-455b-80f8-7958f2d8c11b\",\"title\":\"Introduction - Open Interpreter\",\"slug\":\"introduction-open-interpreter-18e7765057c\",\"url\":\"https://docs.openinterpreter.com/getting-started/introduction\",\"pageType\":\"UNKNOWN\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-03-25T20:54:53.000Z\",\"isArchived\":false,\"readingProgressPercent\":100,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"author\":null,\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sJhVNVdK3qw95mAyrYEbDZDcIFesQNquDiDAbDCQOSu8/https://docs.openinterpreter.com/api/og?division=Documentation%C2%A7ion=Getting+Started&title=Introduction&description=A+new+way+to+use+computers&logoLight=https%3A%2F%2Fmintlify.s3-us-west-1.amazonaws.com%2Fopeninterpreter%2Fassets%2Flogo%2Fcircle.png&logoDark=https%3A%2F%2Fmintlify.s3-us-west-1.amazonaws.com%2Fopeninterpreter%2Fassets%2Flogo%2Fcircle-inverted.png&primaryColor=%23000000&lightColor=%23FFFFFF&darkColor=%23000000\",\"description\":\"A new way to use computers\",\"publishedAt\":null,\"ownedByViewer\":null,\"originalArticleUrl\":\"https://docs.openinterpreter.com/getting-started/introduction\",\"uploadFileId\":null,\"labels\":[{\"id\":\"8f4ce554-2916-11ef-8161-fbb712d47c7f\",\"name\":\"github\",\"color\":\"#3B7AD6\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"Open Interpreter\",\"subscription\":null,\"readAt\":\"2024-04-01T00:24:02.000Z\",\"savedAt\":\"2024-04-01T00:42:33.000Z\",\"wordsCount\":104,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"12efde9d-aec8-4604-99ea-b140a5cb9b16\",\"title\":\"Python & JavaScript Libraries · Ollama Blog\",\"slug\":\"https-ollama-com-blog-python-javascript-libraries-18e970293fe\",\"url\":\"https://ollama.com/blog/python-javascript-libraries\",\"pageType\":\"WEBSITE\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-04-01T00:15:12.000Z\",\"isArchived\":false,\"readingProgressPercent\":28,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":6,\"author\":null,\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sh_dHK_3wIH8JihLKmaH7nJq-niK_G2seQYIRSbzczUg/https://ollama.com/public/og-twitter.png\",\"description\":\"The initial versions of the Ollama Python and JavaScript libraries are now available, making it easy to integrate your Python or JavaScript, or Typescript app with Ollama in a few lines of code. Both libraries include all the features of the Ollama REST API, are familiar in design, and compatible with new and previous versions of Ollama.\",\"publishedAt\":\"2024-01-23T00:00:00.000Z\",\"ownedByViewer\":null,\"originalArticleUrl\":\"https://ollama.com/blog/python-javascript-libraries\",\"uploadFileId\":null,\"labels\":[{\"id\":\"4d188510-3160-11ef-95ac-476b5d5c1917\",\"name\":\"ollama\",\"color\":\"#CC5433\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"ollama.com\",\"subscription\":null,\"readAt\":\"2024-06-23T13:25:06.000Z\",\"savedAt\":\"2024-04-01T00:15:13.000Z\",\"wordsCount\":330,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"d56091fb-d260-4a7b-8eee-09402b5bc07d\",\"title\":\"Data Science Projects | Aman Kharwal\",\"slug\":\"data-science-projects-aman-kharwal-18d9509d85d\",\"url\":\"https://thecleverprogrammer.com/2022/03/09/data-science-projects\",\"pageType\":\"ARTICLE\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-02-10T22:01:07.000Z\",\"isArchived\":false,\"readingProgressPercent\":0,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"author\":\"Aman Kharwal\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sC2g9xmhEhGKgP8hLCKLbzbo9GjO-owKdy2l1nrfU52M/https://i0.wp.com/thecleverprogrammer.com/wp-content/uploads/2024/02/185-Data-Science-Projects-using-Python.png?fit=2240%2C1260&ssl=1\",\"description\":\"In this article, I will take you through a list of data science projects with Python that will help you learn and implement Data Science.\",\"publishedAt\":\"2022-03-09T07:53:07.000Z\",\"ownedByViewer\":null,\"originalArticleUrl\":\"https://thecleverprogrammer.com/2022/03/09/data-science-projects\",\"uploadFileId\":null,\"labels\":[{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"},{\"id\":\"fcf97d42-3163-11ef-be29-f7e1d42d0b74\",\"name\":\"data-science\",\"color\":\"#7CFF7B\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"thecleverprogrammer\",\"subscription\":null,\"readAt\":null,\"savedAt\":\"2024-02-10T22:01:07.000Z\",\"wordsCount\":977,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"415a74b1-a135-4178-bb5f-c20d0ba5a6dc\",\"title\":\"An introduction to building autonomous AI agents - Geeky Gadgets\",\"slug\":\"an-introduction-to-building-autonomous-ai-agents-geeky-gadgets-18d3e8fd387\",\"url\":\"https://www.geeky-gadgets.com/building-autonomous-ai-agents/\",\"pageType\":\"ARTICLE\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-01-25T03:00:28.000Z\",\"isArchived\":false,\"readingProgressPercent\":100,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":90,\"author\":\"Julian Horsey\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,s7Ulpb4bZxOJaErnZY6kbQfrrNrVY66IqLsw8n7qleNk/https://www.geeky-gadgets.com/wp-content/uploads/2023/09/building-autonomous-AI-agents.jpg\",\"description\":\"If you would like to learn the basics of what an AI agent is and how to build autonomous AI agents for business, clients or personal workflows\",\"publishedAt\":\"2023-09-08T07:55:11.000Z\",\"ownedByViewer\":null,\"originalArticleUrl\":\"https://www.geeky-gadgets.com/building-autonomous-ai-agents/\",\"uploadFileId\":null,\"labels\":[{\"id\":\"b1cf66be-3164-11ef-b788-e783d7a226aa\",\"name\":\"ai-agents\",\"color\":\"#FF5D99\"},{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"Geeky Gadgets\",\"subscription\":null,\"readAt\":\"2024-07-02T15:14:59.000Z\",\"savedAt\":\"2024-01-25T03:00:29.000Z\",\"wordsCount\":1194,\"recommendations\":[],\"highlights\":[]}},{\"cursor\":\"15\",\"node\":{\"id\":\"287583a2-3237-4f86-a2a1-26df352bc21c\",\"title\":\"How to build an autonomous AI research agent running 24/7 - Geeky Gadgets\",\"slug\":\"how-to-build-an-autonomous-ai-research-agent-running-24-7-geeky--18d3e8facb2\",\"url\":\"https://www.geeky-gadgets.com/build-an-autonomous-ai-research-agent/\",\"pageType\":\"ARTICLE\",\"contentReader\":\"WEB\",\"createdAt\":\"2024-01-25T03:00:17.000Z\",\"isArchived\":false,\"readingProgressPercent\":100,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":74,\"author\":\"Julian Horsey\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sh0ra00QgWg-ZNzSdIu7E7vcalX2_z0YaiZrYCHnLE2k/https://www.geeky-gadgets.com/wp-content/uploads/2023/09/build-an-autonomous-AI-research-agent.jpg\",\"description\":\"Learn how to build an autonomous AI research agent using LangChain allowing you to can doubt research 24-hour is a day seven days a week.\",\"publishedAt\":\"2023-09-22T13:35:37.000Z\",\"ownedByViewer\":null,\"originalArticleUrl\":\"https://www.geeky-gadgets.com/build-an-autonomous-ai-research-agent/\",\"uploadFileId\":null,\"labels\":[{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\"},{\"id\":\"b1cf66be-3164-11ef-b788-e783d7a226aa\",\"name\":\"ai-agents\",\"color\":\"#FF5D99\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\"}],\"pageId\":null,\"shortId\":null,\"quote\":null,\"annotation\":null,\"state\":\"SUCCEEDED\",\"siteName\":\"Geeky Gadgets\",\"subscription\":null,\"readAt\":\"2024-01-25T03:02:34.000Z\",\"savedAt\":\"2024-01-25T03:00:18.000Z\",\"wordsCount\":715,\"recommendations\":[],\"highlights\":[]}}],\"pageInfo\":{\"hasNextPage\":false,\"hasPreviousPage\":false,\"startCursor\":\"\",\"endCursor\":\"15\",\"totalCount\":15}}}}\n",
      "\n",
      "2024-07-04 23:34:58,638 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"https-trailheadtechnology-com-deploying-a-gpt-4-o-model-to-azure-1906b182ea4\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:34:58,857 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"2e4b0a72-13a3-45e4-b5b0-bab886c0b111\",\"title\":\"Deploying A GPT-4o Model to Azure OpenAI Service - Trailhead Technology Partners\",\"url\":\"https://trailheadtechnology.com/deploying-a-gpt-4o-model-to-azure-openai-service/\",\"author\":\"Rodrigo Juarez\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sKZK6kFR7_PKqX_JIdummEkeaCkcWcKdOr0XoXy9JAI4/https://trailheadtechnology.com/wp-content/uploads/2024/05/deploying-4o-featured.jpeg\",\"savedAt\":\"2024-07-03T13:34:16.000Z\",\"createdAt\":\"2024-06-30T21:41:05.000Z\",\"publishedAt\":\"2024-06-27T14:00:00.000Z\",\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://trailheadtechnology.com/deploying-a-gpt-4o-model-to-azure-openai-service/\",\"readingProgressPercent\":0.1,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"slug\":\"https-trailheadtechnology-com-deploying-a-gpt-4-o-model-to-azure-1906b182ea4\",\"isArchived\":false,\"description\":\"Azure OpenAI Service enables easy deployment of powerful language models like GPT-4o. This guide walks you through the process, from securing access and creating resources in the Azure portal to navigating the updated Azure AI Studio for model selection and configuration. The interactive playground allows for testing and fine-tuning, while secure API access ensures robust integration into your applications.\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":1033,\"content\":\"  \\nAzure OpenAI Service offers API access to powerful OpenAI language models like [GPT-4o](https://openai.com/index/hello-gpt-4o/), enabling tasks such as content generation, summarization, natural language, and code translation.\\n\\nIn this post, I want to show you how easy it is to deploy a language model to an existing Azure OpenAI resource whenever new models become available.\\n\\n## Prerequisite\\n\\nYou need an active Azure subscription and access to the Azure OpenAI service, which you can request using [this link](https://aka.ms/oai/access). At the time I’m writing this, it took just a couple of hours for me to gain access, but it says it take up to 10 business days.\\n\\n## Creating an Azure OpenAI Resource\\n\\nThe first step is the creation of a resource. After logging into the [Azure portal](https://portal.azure.com/#home), select the **Create a resource** option.\\n\\n![](https://proxy-prod.omnivore-image-cache.app/1024x407,skvDJ8OVgfJUvK6zSAOHBMleRCoJme4RJx9rrXNduU1I/https://trailheadtechnology.com/wp-content/uploads/2024/05/image-19-1024x407.png.webp)\\n\\nThen search for **Azure OpenAI**, click on it, and then use the **Create** button.\\n\\n![](https://proxy-prod.omnivore-image-cache.app/1024x598,snjZJdXpnDImygfi5IFT6iSY7ZaGDSnWywF9FhQLM7ms/https://trailheadtechnology.com/wp-content/uploads/2024/05/image-20-1024x598.png.webp)\\n\\nIn the new dialog, you will:\\n\\n1- Select the subscription where the new resources will be located.\\n\\n2- Create or select a resource group.\\n\\n3- Set the region. NOTE: not every model type is available in every region. For access to gpt-4o models, you need to select **East US 2** at the moment of writing this post.\\n\\n4- Create a unique name for the resource.\\n\\n5- Choose the pricing tier.\\n\\nAfter this, you can leave other values as default and use the **Next** button to go forward, then the **Create** button to complete the resource creation.\\n\\n![](https://proxy-prod.omnivore-image-cache.app/863x913,sifOUC3Kgxi7TLN0uDa_tZVlrsNLb_rpGdzkkC0vV6Wo/https://trailheadtechnology.com/wp-content/uploads/2024/05/image-21.png.webp)\\n\\nThe resource creation can take a couple of minutes, after which you will be redirected to a summary page for your deployment. Select the **Go to resource** button to work with your new Azure OpenAI resource.\\n\\n![](https://proxy-prod.omnivore-image-cache.app/956x587,sBbgy-__9HMq1exoO521MekSByVONk_JbTEJsgugBRFo/https://trailheadtechnology.com/wp-content/uploads/2024/05/image-22.png.webp)\\n\\n## Deploy the Model\\n\\nNavigating through the Azure portal has recently seen some changes, particularly in managing AI model deployments. Users accustomed to finding model deployment options under the “Model deployments” section within their resource group will now see a prompt indicating that these features have moved to Azure OpenAI Studio.\\n\\n![](https://proxy-prod.omnivore-image-cache.app/709x457,sgiopDz0p88SL0ZMaq4Yk30CI_dwLOsWwaavGvIUOSds/https://trailheadtechnology.com/wp-content/uploads/2024/05/image-23.png.webp)\\n\\n### Model Availability\\n\\nIn the updated Azure AI Studio, users can now access a comprehensive list of AI models, as shown in the image. It’s crucial to note that the availability of these models depends on the location selected during the creation step.\\n\\n![](https://proxy-prod.omnivore-image-cache.app/1024x680,shEUlXjOl_D3ZCYLt9PrPQUvXDF_x1TGwNSrPZRX-Gdk/https://trailheadtechnology.com/wp-content/uploads/2024/05/image-24-1024x680.png.webp)\\n\\nNow we can select the gpt-4o model and the Deploy option\\n\\n![](https://proxy-prod.omnivore-image-cache.app/580x761,sF1hJ2zRf08r7qIoU9L88YhkaV8IXwlXM5TH_IdXzJ9E/https://trailheadtechnology.com/wp-content/uploads/2024/05/image-25.png.webp)\\n\\nWhen setting up a new deployment, users can configure several key parameters, including the model version, deployment type, and name. A crucial aspect to consider is the rate limit, which dictates the number of tokens processed per minute. In this example, the rate limit is set to 1,000 tokens per minute, translating to 6 requests per minute (RPM). Additionally, the dynamic quota feature, which is enabled here, allows Azure to automatically adjust the rate limits based on demand and resource availability.\\n\\n![](https://proxy-prod.omnivore-image-cache.app/751x967,sIsDMqZCIBQGwZvAqOxF8Vr7A7CPFdf5ILAXg68vwzIo/https://trailheadtechnology.com/wp-content/uploads/2024/05/image-26.png.webp)\\n\\n## Test the Model in Playground\\n\\nOnce our new deployment is ready, and we can use it in the playground to test it.\\n\\n![](https://proxy-prod.omnivore-image-cache.app/1024x371,sWHJJDyrDdPzwhBSoIpyy7Rhl2T3UdiVoHX_jJ4ea_KY/https://trailheadtechnology.com/wp-content/uploads/2024/05/image-27-1024x371.png.webp)\\n\\nThe **Playground** in Azure OpenAI Studio provides a dynamic environment for testing and fine-tuning AI models. The image shows a practical example of using the deployment “rj-gpt-4o” to generate responses based on user prompts. \\n\\nThe setup panel on the left allows users to define system messages, use templates, and add examples to guide the AI’s responses. The configuration panel on the right lets users select their deployment and adjust session settings, such as the number of past messages included and the current token count. Here, we prompted the model to print the first 100 prime numbers, showcasing the model’s ability to handle mathematical queries effectively. This interactive playground is invaluable for developers to experiment with different configurations and optimize their AI models for various applications.\\n\\n![](https://proxy-prod.omnivore-image-cache.app/1024x418,slMV_VUDp5IeGsHwgl-37_VyEx-PtakNhwKibvWiA7I8/https://trailheadtechnology.com/wp-content/uploads/2024/05/image-29-1024x418.png.webp)\\n\\n## Keys and API Access\\n\\nIn the Azure portal, securing and managing access to your AI services is crucial, and the “Keys and Endpoint” section facilitates this process effectively. \\n\\nAs shown in the image, within the “rj-gpt-demo” resource group, users can navigate to the “Keys and Endpoint” option highlighted by red arrows in the left sidebar. This section displays essential information, including two access keys and an endpoint URL, which are vital for making API calls to Azure AI services. Users are advised to store these keys securely and regenerate them regularly to maintain security, with options to regenerate each key separately, ensuring uninterrupted access during the update process.\\n\\n![](https://proxy-prod.omnivore-image-cache.app/1024x677,sqgIoiB_VQMESCJFT7PBpNMI7piv0Gjdc35lEDxpq7g4/https://trailheadtechnology.com/wp-content/uploads/2024/05/image-30-1024x677.png.webp)\\n\\n## Testing with cURL\\n\\nUsing the Endpoint and Key provided, we can test our model using cURL asking the same question we used in the playground with the following command (replace **YOUR\\\\_API\\\\_KEY** with either of the 2 keys)\\n\\n```lsl\\ncurl \\\"https://rj-gpt-demo.openai.azure.com/openai/deployments/rj-gpt-4o/chat/completions?api-version=2024-02-15-preview\\\" -H \\\"Content-Type: application/json\\\" -H \\\"api-key: YOUR_API_KEY\\\" -d \\\"{\\\\\\\"messages\\\\\\\": [{\\\\\\\"role\\\\\\\":\\\\\\\"user\\\\\\\",\\\\\\\"content\\\\\\\":\\\\\\\"Find the first 100 prime numbers.\\\\\\\"}], \\\\\\\"max_tokens\\\\\\\": 200}\\\"\\n\\n```\\n\\nThis will return a JSON response with the numbers and additional information regarding the call itself.\\n\\n## Conclusion\\n\\nDeploying new language models using Azure OpenAI Service is a streamlined process that begins with securing access and creating the necessary resources in the Azure portal. Once the resources are set up, navigating the updated Azure AI Studio allows for selecting and configuring models like GPT-4o, ensuring optimal performance and scalability. \\n\\nThe interactive playground provides a valuable environment for testing and fine-tuning model responses, while securing access through the “Keys and Endpoint” section is critical for maintaining secure API interactions. By following these steps, developers can leverage Azure’s robust infrastructure to integrate powerful AI capabilities into their applications efficiently and securely.\\n\\n[ ![Picture of Rodrigo Juarez](https://proxy-prod.omnivore-image-cache.app/1748x1748,s82Uf7FmvM0Y8pmruu53BsnDol_dQVTcbWSWVa23Kg7U/https://trailheadtechnology.com/wp-content/uploads/2023/12/Rodrigo-Juarez-Headshot.jpg.webp) ](https://trailheadtechnology.com/author/rodrigo/)\\n\\n[  Rodrigo Juarez ](https://trailheadtechnology.com/author/rodrigo/)\\n\\n Rodrigo Juarez has over 25 years of experience in software development, specializing in Microsoft technologies. His mission is to solve complex problems for his clients, with a focus on results. He achieves this by applying the appropriate technology and using best practices to ensure the delivery of high-quality solutions. Over the past 6 years, Rodrigo has honed his skills in back-end development and in creating mobile applications, initially using Xamarin and now transitioning to .NET MAUI. He is a Lead Mobile Developer at Trailhead Technology Partners and the co-author, along with Jesse Liberty, of the book \\\".NET MAUI for C# Developers\\\" \",\"highlights\":[],\"labels\":[{\"id\":\"9bff1418-3729-11ef-b015-b3532a972baf\",\"name\":\"azure\",\"color\":\"#524A9E\",\"description\":null,\"createdAt\":\"2024-06-30T21:42:12.000Z\"},{\"id\":\"be7ee338-ad04-11ee-b29e-cf84be09e663\",\"name\":\"openai\",\"color\":\"#57B5D4\",\"description\":\"\",\"createdAt\":\"2024-01-07T02:30:38.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:34:58,859 - INFO - Processing article: Deploying A GPT-4o Model to Azure OpenAI Service - Trailhead Technology Partners\n",
      "2024-07-04 23:35:04,555 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"https-www-docker-com-blog-using-generative-ai-to-create-runnable-19078cbf9fa\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:35:04,839 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"94b33d3a-c5e7-4347-aab4-73324363ab25\",\"title\":\"Using Generative AI to Create Runnable Markdown | Docker\",\"url\":\"https://www.docker.com/blog/using-generative-ai-to-create-runnable-markdown/\",\"author\":null,\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,smSkV8X7PVY76JCcwEy8b6gGRsLBdP4fZbdsD5bWrW3A/https://www.docker.com/wp-content/uploads/2024/06/1300x1300_docker-labs-genai-1024x1024.png\",\"savedAt\":\"2024-07-03T13:32:35.000Z\",\"createdAt\":\"2024-07-03T13:32:32.000Z\",\"publishedAt\":\"2024-07-01T13:00:00.000Z\",\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://www.docker.com/blog/using-generative-ai-to-create-runnable-markdown/\",\"readingProgressPercent\":0,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"slug\":\"https-www-docker-com-blog-using-generative-ai-to-create-runnable-19078cbf9fa\",\"isArchived\":false,\"description\":\"Explore the innovative realm of AI developer tools with Docker's GenAI Docker Labs series. Join us as we dive deep into the potential of AI. Discover how generative AI can assist with documentation, project-specific tasks, and more throughout the software lifecycle. Stay updated and get involved with Docker's latest projects and tools.\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":941,\"content\":\"_This ongoing GenAI Docker Labs series will explore the exciting space of AI developer tools. At Docker, we believe there is a vast scope to explore, openly and without the hype. We will share our explorations and collaborate with the developer community in real-time. Although developers have adopted autocomplete tooling like GitHub Copilot and use chat, there is significant potential for AI tools to assist with more specific tasks and interfaces throughout the entire software lifecycle. Therefore, our exploration will be broad. We will be releasing things as open source so you can play, explore, and hack with us, too._\\n\\nGenerative AI (GenAI) is changing how we interact with tools. Today, we might experience this predominantly through the use of new AI-powered chat assistants, but there are other opportunities for generative AI to improve the life of a developer.\\n\\nWhen developers start working on a new project, they need to get up to speed on the tools used in that project. A common practice is to document these practices in a project `README.md` and to version that documentation along with the project. \\n\\nCan we use generative AI to generate this content? We want this content to represent best practices for how tools should be used in general but, more importantly, how tools should be used in this particular project.\\n\\nWe can think of this as a kind of conversation between developers, agents representing tools used by a project, and the project itself. Let’s look at this for the Docker tool itself.\\n\\n![2400x1260 docker labs genai](https://proxy-prod.omnivore-image-cache.app/1110x583,sAjojVLuTR1v3wVy_xOPWGA9xCGpsxHdyTwu_pkcdunA/https://www.docker.com/wp-content/uploads/2024/06/2400x1260_docker-labs-genai-1110x583.png \\\"- 2400X1260 Docker Labs Genai\\\")\\n\\n## Generating Markdown in VSCode\\n\\nFor this project, we have written a[ VSCode extension](https://github.com/docker/labs-make-runbook) that adds one new command called “Generate a runbook for this project.” Figure 1 shows it in action:\\n\\n![Animated gif showing vscode extension to generate a runbook for this project.](https://proxy-prod.omnivore-image-cache.app/800x443,scJUW81R6WVIZdatJfd_DnhoBa0tzXmqzzFnlnPYNhyM/https://www.docker.com/wp-content/uploads/2024/06/F1-VSCode-extension.gif \\\"Animated Gif Showing Vscode Extension To Generate A Runbook For This Project. - F1 Vscode\\\")\\n\\n**Figure 1:** VSCode extension to generate a runbook.\\n\\nThis approach combines prompts written by tool experts with knowledge about the project itself. This combined context improves the LLM’s ability to generate documentation (Figure 2).\\n\\n![Illustration showing process flow from expert prompts plus project facts to llm.](https://proxy-prod.omnivore-image-cache.app/1110x495,sYcdw7FJcO336jGUwJpBJibjX6AsD8Nlbf0oQ7KpoXr8/https://www.docker.com/wp-content/uploads/2024/06/F2-AI-process-1110x495.png \\\"Illustration Showing Process Flow From Expert Prompts Plus Project Facts To Llm. - F2 Ai Process\\\")\\n\\n**Figure 2:** This approach combines expert prompts with knowledge about the project itself.\\n\\nAlthough we’re illustrating this idea on a tool that we know very well (Docker!), the idea of generating content in this manner is quite generic. [The prompts we used](https://github.com/docker/labs-make-runbook/blob/main/prompts/docker/020%5Fuser%5Fprompt.md) for getting started with the Docker build, run, and compose are available from GitHub. There is certainly an art to writing these prompts, but we think that tool experts have the right knowledge to create prompts of this kind, especially if AI assistants can then help them make their work easier to consume.\\n\\nThere is also an essential point here. If we think of the project as a database from which we can retrieve context, then we’re effectively giving an LLM the ability to retrieve facts about the project. This allows our prompts to depend on local context. For a Docker-specific example, we might want to prompt the AI to not talk about compose if the project has no `compose.yaml` files. \\n\\n_“I am not using Docker Compose in this project.”_\\n\\nThat turns out to be a transformative user prompt if it’s true. This is what we’d normally learn through a conversation. However, there are certain project details that are always useful. This is why having our assistants right there in the local project can be so helpful.\\n\\nAlthough Markdown files are mainly for reading, they often contain runnable things. LLMs converse with us in text that often contains code blocks that represent actual runnable commands. And, in VSCode, developers use the embedded terminal to run commands against the currently open project. Let’s short-circuit this interaction and make commands runnable directly from these Markdown runbooks.\\n\\nIn the current extension, we’ve added a code action to every code block that contains a shell command so that users can launch that command in the embedded terminal. During our exploration of this functionality, we have found that treating the Markdown file as a kind of REPL (read-eval-print-loop) can help to refine the output from the LLM and improve the final content. Figure 3 what this looks like in action:\\n\\n![Animated gif showing addition of code action that contains a shell command so users can launch that command in the embedded terminal.](https://proxy-prod.omnivore-image-cache.app/800x450,saGQOdsRT6L6K6Urk76jkMryxxqqTSrmW6AHqiN6QNrg/https://www.docker.com/wp-content/uploads/2024/06/F3-Adding-launch-code.gif \\\"Animated Gif Showing Addition Of Code Action That Contains A Shell Command So Users Can Launch That Command In The Embedded Terminal. - F3 Adding Launch Code\\\")\\n\\n**Figure 3:** Adding code to allow users to launch the command in the embedded terminal. \\n\\n## Markdown extends your editor\\n\\nIn the long run, nobody is going to navigate to a Markdown file in order to run a command. However, we can treat these Markdown files as scripts that create commands for the developer’s edit session. We can even let developers bind them to keystrokes (e.g., type ,b to run the build code block from your project runbook).\\n\\nIn the end, this is just the AI Assistant talking to itself. The Assistant recommends a command. We find the command useful. We turn it into a shortcut. The Assistant remembers this shortcut because it’s in our runbook, and then makes it available whenever we’re developing this project.\\n\\n![Animated gif showing the ai assistant generating context-aware content.](https://proxy-prod.omnivore-image-cache.app/800x450,sO0zXBjSikye6dg-FTPvWRC_WoageMiadmFIXe4wSFp8/https://www.docker.com/wp-content/uploads/2024/06/F4.AI-Assistant-action.gif \\\"Animated Gif Showing The Ai Assistant Generating Context-Aware Content. - F4.Ai Assistant Action\\\")\\n\\n**Figure 4**: The Assistant in action.\\n\\nFigure 4 shows a real feedback loop between the Assistant, the generated content, and the developer that is actually running these commands. \\n\\nAs developers, we tend to vote with our keyboards. If this command is useful, let’s make it really easy to run! And if it’s useful for me, it might be useful for other members of my team, too.\\n\\nThe[ GitHub repository](https://github.com/docker/labs-make-runbook) and[ install instructions](https://github.com/docker/labs-make-runbook?tab=readme-ov-file#getting-started) are ready for you to try today. \\n\\nFor more, see this demo:[ VSCode Walkthrough of Runnable Markdown from GenAI](https://youtu.be/bed68z24sPo).\\n\\n**[Subscribe to Docker Navigator](https://www.docker.com/newsletter-subscription/)** to stay current on the latest Docker news.\\n\\n## Learn more\\n\\n* Subscribe to the [Docker Newsletter](https://www.docker.com/newsletter-subscription/).\\n* Read [Docker, Putting the AI in Containers](https://www.docker.com/resources/docker-putting-the-ai-in-containers-white-paper/).\\n* Read the [AI Trends Report 2024: AI’s Growing Role in Software Development](https://www.docker.com/blog/ai-trends-report-2024/).\",\"highlights\":[],\"labels\":[{\"id\":\"34f92374-3884-11ef-b94a-9763ab0a35f8\",\"name\":\"tools\",\"color\":\"#34FFE6\",\"description\":null,\"createdAt\":\"2024-07-02T15:03:14.000Z\"},{\"id\":\"9fff5d06-0a20-11ef-bcb5-ebe254c07f4f\",\"name\":\"markdown\",\"color\":\"#290845\",\"description\":null,\"createdAt\":\"2024-05-04T14:14:31.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:35:04,843 - INFO - Processing article: Using Generative AI to Create Runnable Markdown | Docker\n",
      "2024-07-04 23:35:09,560 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"https-github-com-posit-dev-positron-19078b49470\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:35:09,769 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"544cff6c-b982-4e94-8bd1-23900d88039b\",\"title\":\"GitHub - posit-dev/positron: Positron, a next-generation data science IDE\",\"url\":\"https://github.com/posit-dev/positron\",\"author\":\"posit-dev\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,skhjgBSx8AkqOY6W_NexziPCNp5kV3_cpU4NAM1zeuMI/https://opengraph.githubassets.com/64033c9202d1a6346bb5042f625e396da1dbf5fa4f956a171bf31f9de5658c49/posit-dev/positron\",\"savedAt\":\"2024-07-03T13:06:58.000Z\",\"createdAt\":\"2024-07-03T13:06:58.000Z\",\"publishedAt\":null,\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://github.com/posit-dev/positron\",\"readingProgressPercent\":0,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"slug\":\"https-github-com-posit-dev-positron-19078b49470\",\"isArchived\":false,\"description\":\"Positron, a next-generation data science IDE. Contribute to posit-dev/positron development by creating an account on GitHub.\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":74,\"content\":\"* * [ Actions Automate any workflow ](https://github.com/features/actions)  \\n   * [ Packages Host and manage packages ](https://github.com/features/packages)  \\n   * [ Security Find and fix vulnerabilities ](https://github.com/features/security)  \\n   * [ Codespaces Instant dev environments ](https://github.com/features/codespaces)  \\n   * [ GitHub Copilot Write better code with AI ](https://github.com/features/copilot)  \\n   * [ Code review Manage code changes ](https://github.com/features/code-review)  \\n   * [ Issues Plan and track work ](https://github.com/features/issues)  \\n   * [ Discussions Collaborate outside of code ](https://github.com/features/discussions)\\n* * [ GitHub Sponsors Fund open source developers ](https://github.com/sponsors)  \\n   * [ The ReadME Project GitHub community articles ](https://github.com/readme)\\n* * [ Enterprise platform AI-powered developer platform ](https://github.com/enterprise)\\n* [Pricing](https://github.com/pricing)\\n\\n##  Provide feedback\\n\\n##  Saved searches\\n\\n## Use saved searches to filter your results more quickly\\n\\n[ Sign up](https://github.com/signup?ref%5Fcta=Sign+up&ref%5Floc=header+logged+out&ref%5Fpage=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source%5Frepo=posit-dev%2Fpositron) \",\"highlights\":[],\"labels\":[{\"id\":\"34f92374-3884-11ef-b94a-9763ab0a35f8\",\"name\":\"tools\",\"color\":\"#34FFE6\",\"description\":null,\"createdAt\":\"2024-07-02T15:03:14.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"},{\"id\":\"fcf97d42-3163-11ef-be29-f7e1d42d0b74\",\"name\":\"data-science\",\"color\":\"#7CFF7B\",\"description\":null,\"createdAt\":\"2024-06-23T13:24:58.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:35:09,774 - INFO - Processing article: GitHub - posit-dev/positron: Positron, a next-generation data science IDE\n",
      "2024-07-04 23:35:14,619 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"https-quillai-com-ref-therundown-190789acd1b\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:35:14,812 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"00111934-bc85-40cc-9bd3-ef4b1c701cf9\",\"title\":\"Quill - AI-powered SEC filing platform\",\"url\":\"https://quillai.com/?ref=therundown\",\"author\":null,\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sglEwXZ_KqQSnTWe23tHPK_RPUiD67mlYUbtZAYyTs-s/https://raw.githubusercontent.com/quill-ai/images/main/quill-banner-black.png\",\"savedAt\":\"2024-07-03T12:38:51.000Z\",\"createdAt\":\"2024-07-03T12:38:49.000Z\",\"publishedAt\":\"2023-06-27T00:00:00.000Z\",\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://quillai.com/?ref=therundown\",\"readingProgressPercent\":0,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"slug\":\"https-quillai-com-ref-therundown-190789acd1b\",\"isArchived\":false,\"description\":\"Leverage Quill's financially-tuned AI to quickly answer questions about any company’s public investor materials. Each response includes state-of-the-art sentence-level source citations that take you back to the relevant filings.\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":482,\"content\":\"Quill AI\\n\\nMeet the AI-powered SEC filing platform.\\n\\n[Get started](#pricing)\\n\\nUSED BY ANALYSTS AT\\n\\n![](https://proxy-prod.omnivore-image-cache.app/0x0,sNin69jT-5ZthW4kyl7lzbVbrKYRXxUQSy77Q7tU3iP0/https://quillai.com/mslogo.svg) ![](https://proxy-prod.omnivore-image-cache.app/0x0,sHPLCWJhgia7ax0o9TKpE4WD5ZfpOWK9wIQ7IY7wSauQ/https://quillai.com/gslogo.svg) ![](https://proxy-prod.omnivore-image-cache.app/0x0,s36S0OmFKUrbLz0vc9ATbR0rKhucAQTs5uNZGoFtR7D0/https://quillai.com/tglogo.svg)\\n\\nFEATURED ON\\n\\n![](https://proxy-prod.omnivore-image-cache.app/0x0,sjdosBnRQ47FMLeRvnYZN1DHXbLkEXD_YGC-hZtW5ky4/https://quillai.com/bloomberglogo.svg)\\n\\nFEATURES\\n\\nExtract key information from filings _just by asking_\\n\\nLeverage Quill's financially-tuned AI to quickly answer questions about any company’s public investor materials. Each response includes state-of-the-art sentence-level source citations that take you back to the relevant filings. This also prevents the AI from hallucinating information.\\n\\n Unlike ChatGPT, which has a training cutoff date, Quill always has up-to-date financial data.\\n\\nChat\\n\\nAsk about companies and their 10K/10Q/8K filings. You can also extract numerical data into spreadsheets.\\n\\nTell me about TSLA's new factories.What was Amazon's AWS spend, revenue, and margin % for the last 4 quarters?What are some differences between the way that AMD and Intel manufacture their chips? To what extent does each manufacture in house, vs outsourcing, and to whom do they outsource?\\n\\nNo chats. Use the chat box at the bottom. \\n\\nHistorical financials for a fraction of the cost\\n\\nQuill has complete tabular historical financial data, collected and organized by our in-house models. Each number comes with a link to its location in the original filing, making the data easily verifiable. All data is Excel-downloadable, so you’ll never manually fill in historicals again.\\n\\nSee $AAPL Historicals (desktop recommended)\\n\\nReal-time filings\\n\\nAccess real-time SEC Filings, earnings call transcripts, insider transactions, and investor presentations. As soon as filings are uploaded to the SEC, they are available on Quill.\\n\\n Files are highlightable in our in-house document viewer, and highlights are shareable for easy collaboration with team members.\\n\\nInstant summaries and spreadsheet updates\\n\\nWhenever a company you’re tracking releases a filing, Quill Alerts will email you with a customizable analysis of the filing. Quill can also send you an updated version of your metrics spreadsheet the minute the information is released on the SEC.\\n\\nEarnings call Q&A Analysis\\n\\nAchieve a fast and accurate understanding of Wall Street analysts’ main concerns with regards to any public company with Quill’s earnings call Q&A sentiment analysis.\\n\\n$NVDA earnings call Q&A breakdown (last 4 quarters):\\n\\nTransform Any PDF into a Spreadsheet\\n\\nUsing our in-house AI models, Quill magically converts any PDF into a detailed spreadsheet, with each number linked to its source in the original document. You can also perform textual analysis on uploaded PDFs.\\n\\n![](https://proxy-prod.omnivore-image-cache.app/0x0,sxMU0Xs4jGr0NeBk9qAD8EC3Bc4RGS5bR15pn5fGpHrw/https://quillai.com/pdfspreadsheet.png)\\n\\nPRICING\\n\\nFREE\\n\\nFree\\n\\nTry Quill with limited features. Access the last 6 months of filings for viewing, highlights, and extraction.\\n\\n[Start](https://app.quillai.com/auth/signin?f)\\n\\nPRO\\n\\n$39/month\\n\\nGet full access to the Quill platform. SEC filings, earnings transcripts, alerts, custom data extraction, PDF to spreadsheet, and more.\\n\\n[Buy - free month with annual billing!](https://buy.stripe.com/3csdT0bhbfYxb7i7sB)\\n\\nENTERPRISE\\n\\nContact us\\n\\nSchedule a 30-minute demo to see how Quill's Enterprise Suite can benefit your firm. API service, dataroom, PDF integrations, custom workflow automation, and more.\\n\\n[Contact](https://app.quillai.com/other/buy/enterprise)\\n\\nPRESS\",\"highlights\":[],\"labels\":[{\"id\":\"34f92374-3884-11ef-b94a-9763ab0a35f8\",\"name\":\"tools\",\"color\":\"#34FFE6\",\"description\":null,\"createdAt\":\"2024-07-02T15:03:14.000Z\"},{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\",\"description\":\"\",\"createdAt\":\"2023-12-30T20:44:43.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:35:14,817 - INFO - Processing article: Quill - AI-powered SEC filing platform\n",
      "2024-07-04 23:35:20,701 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"https-www-nomic-ai-gpt-4-all-ref-therundown-1907899156f\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:35:20,920 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"ef15fb74-5366-4fd4-9ced-06ce936ccaab\",\"title\":\"GPT4All\",\"url\":\"https://www.nomic.ai/gpt4all?ref=therundown\",\"author\":null,\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sFEYiFq3AJZNc0AOguBGbrLuBAv3DsYxAVaeZpqKti1g/https://homepage-gw3wguthh-nomic-ai.vercel.app/opengraph-image-gpt4all.png\",\"savedAt\":\"2024-07-03T12:37:00.000Z\",\"createdAt\":\"2024-07-03T12:36:56.000Z\",\"publishedAt\":null,\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://www.nomic.ai/gpt4all?ref=therundown\",\"readingProgressPercent\":100,\"readingProgressTopPercent\":87,\"readingProgressAnchorIndex\":91,\"slug\":\"https-www-nomic-ai-gpt-4-all-ref-therundown-1907899156f\",\"isArchived\":false,\"description\":\"Run Large Language Models Locally: privacy-first and no internet required\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":323,\"content\":\"## Run Large Language Models Locally\\n\\nPrivacy first\\n\\nNo internet required\\n\\n[![macOS](https://proxy-prod.omnivore-image-cache.app/0x0,sPY6Ilt22xKPduHXj22g7FVIL684ENoBNw8xMRNX7vKI/https://www.nomic.ai/gpt4all/logo_macOS_white.svg)](https://gpt4all.io/installers/gpt4all-installer-darwin.dmg)\\n\\n3rd Fastest-Growing GitHub Repository of All Time\\n\\n250,000+ Monthly Active Users\\n\\n70,000+ Python Package Monthly Downloads\\n\\n## Your chats are _private_ and never leave your device\\n\\nGPT4All is built with privacy and security first. Use LLMs with your sensitive local data without it ever leaving your device.\\n\\n![Image 1](https://proxy-prod.omnivore-image-cache.app/0x0,s6Ru9-72wcwMXqfi3ln6lgoyindYX6F5xX6xSl7c2Ct8/https://www.nomic.ai/gpt4all/illu_privacy.png)\\n\\n![Image 2](https://proxy-prod.omnivore-image-cache.app/0x0,sERnxVeSGnwwDBAA-J99yjNg59hXcaf-75g4iP-3DIow/https://www.nomic.ai/gpt4all/illu_branch.png)\\n\\n## Run language models on _consumer_ hardware\\n\\nGPT4All allows you to run LLMs on CPUs and GPUs. It fully supports Mac M Series chips, AMD, and NVIDIA GPUs.\\n\\n## Chat with your _local_ files\\n\\nGrant your local LLM access to your private, sensitive information with LocalDocs. It works without internet and no data leaves your device.\\n\\n![Image 3](https://proxy-prod.omnivore-image-cache.app/0x0,sQujWI8nJnxdmBNRmUUJQH_a_FvePmzWQzQKmx1tboSo/https://www.nomic.ai/gpt4all/illu_localdocs.png)\\n\\n![Image 4](https://proxy-prod.omnivore-image-cache.app/0x0,sFMGkJdrBAICsoiYueLkOMtsVHn48_u84istcaHab_e4/https://www.nomic.ai/gpt4all/illu_llms.png)\\n\\n## Explore over 1000 _open-source_ language models\\n\\nGPT4All supports popular models like LLaMa, Mistral, Nous-Hermes, and hundreds more.\\n\\n## and more...\\n\\n![Image 4](https://proxy-prod.omnivore-image-cache.app/0x0,sqRkCkdb3S9XVyAjIAKxtCbFEMKkUJgnjADX76lJOjYs/https://www.nomic.ai/gpt4all/illu_network.png)\\n\\n## Chat without internet\\n\\nLocally-running LLMs allow you to chat anytime on your laptop or device, even on the beach or in an airplane\\n\\n![Image 4](https://proxy-prod.omnivore-image-cache.app/0x0,ssuZOeUvJ63GbxbeHgmCrqOjDrkcF9lw_zwWOm82D0Ig/https://www.nomic.ai/gpt4all/illu_community.png)\\n\\n## Join the community\\n\\nBenefit from the support of a large community of GPT4All users and developers\\n\\n![Image 4](https://proxy-prod.omnivore-image-cache.app/0x0,stv7BY2PKO2csbjZMGieDDO-YUAqMnggS9fj_eJckqs4/https://www.nomic.ai/gpt4all/illu_opensource.png)\\n\\n## Trust open source\\n\\nThe GPT4All code base on GitHub is completely MIT-licensed, open-source, and auditable\\n\\n![Image 4](https://proxy-prod.omnivore-image-cache.app/0x0,swZ0nsvLvPa5VmT32rBhbDlbleF3U7FK4LS8fvSU2HNY/https://www.nomic.ai/gpt4all/illu_custom.png)\\n\\n## Customize your chat\\n\\nFully customize your chatbot experience with your own system prompts, temperature, context length, batch size, and more\\n\\n## Dive into the GPT4All Data Lake\\n\\nAnyone can contribute to the democratic process of training a large language model. By default, GPT4All will not let any conversation history leave your computer — the Data Lake is opt-in.\\n\\n## GPT4All Enterprise\\n\\nWant to deploy local AI for your business? Nomic offers an enterprise edition of GPT4All packed with support, enterprise features and security guarantees on a per-device license. In our experience, organizations that want to install GPT4All on more than 25 devices can benefit from this offering.\\n\\nRemember, your business can always install and use the official open-source, community edition of the GPT4All Desktop application commercially without talking to Nomic.\\n\\n[Contact Us](mailto:sales@nomic.ai)\\n\\n## Explore the GPT4All open-source ecosystem\\n\\nMaintained and initially developed by the team at Nomic AI, producers of\\n\\n[Nomic Atlas](https://atlas.nomic.ai/)\\n\\nand\\n\\n[Nomic Embed](https://blog.nomic.ai/posts/nomic-embed-text-v1)\",\"highlights\":[],\"labels\":[{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\",\"description\":\"\",\"createdAt\":\"2023-12-30T20:44:43.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:35:20,925 - INFO - Processing article: GPT4All\n",
      "2024-07-04 23:35:26,554 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"https-samestuffdifferentday-net-2024-06-27-learning-part-2-19064954fdc\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:35:26,775 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"73d61177-38d3-442b-9ad7-a41bd7800591\",\"title\":\"My 5 favorite ways of keeping the technical axe sharp - same stuff, different day\",\"url\":\"https://samestuffdifferentday.net/2024/06/27/learning-part2/\",\"author\":\"Michael Eaton\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sGqD6dR3e0aHiXwDyRtGAC6A5SpbmDkmANshRHKpJqUs/https://samestuffdifferentday.net/assets/2024/learning.jpg\",\"savedAt\":\"2024-06-29T15:20:25.000Z\",\"createdAt\":\"2024-06-29T15:20:25.000Z\",\"publishedAt\":\"2024-06-27T11:00:00.000Z\",\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://samestuffdifferentday.net/2024/06/27/learning-part2/\",\"readingProgressPercent\":0.1,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"slug\":\"https-samestuffdifferentday-net-2024-06-27-learning-part-2-19064954fdc\",\"isArchived\":false,\"description\":\"The one where I talk about keeping my tech skills sharp.\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":567,\"content\":\"![My 5 favorite ways of keeping the technical axe sharp](https://proxy-prod.omnivore-image-cache.app/0x0,syj8KVLcc5ns2Km0aDyckDdWqwzbb7HWHL8aLmdJeUws/https://samestuffdifferentday.net/assets/2024/learning.jpg) \\n\\n 2 minute read  article  Leadership Technology Wisdom Career Learning [Comments](https://samestuffdifferentday.net/2024/06/27/learning-part2/#disqus%5Fthread) \\n\\nTo stick with the topic of [learning](https://samestuffdifferentday.net/2024/06/26/learning/), I wanted to talk about some of the methods I use to keep my tech skills sharp.\\n\\n## Side projects[Permalink](#side-projects \\\"Permalink\\\")\\n\\nWhen I say side projects, I don’t mean full-blown open source projects, but instead small things to make life easier.\\n\\nOver the years, I’ve sprinkled my personal dev folder with all sorts of little things to make life easier. It’s a good way to play with new language features especially if your company or client won’t be upgrading anytime soon. Don’t let them hold you back when it comes to learning. Get ahead of the curve, so when (if?) the time comes, you’ll be ready because you’ve been using the new features in your own projects.\\n\\nAt my last job I had a bunch of .Net projects that still had bindings for TFS so whenever you opened the project, you’d get nagged. I wrote a small Python app to do the dirty work for me.\\n\\nAt the job before that I got tired of flipping between multiple Azure DevOps projects so I wrote a small console application to hit the API and present the data I needed with just a few keystrokes.\\n\\nEven today I realized I wanted to reduce some of the friction for this blog, so I’m working on a small C# app that will take some of the manual work out of creating new posts.\\n\\n## Koans[Permalink](#koans \\\"Permalink\\\")\\n\\nI really enjoy Koans and was first introduced to them by the devs at EdgeCase back in the day. I had the privilege of meeting and talking to Jim Weirich, too.\\n\\nFind your path to enlightenment with Koans.\\n\\n* [Ruby Koans](https://github.com/spatten/ruby%5Fkoans)\\n* [Python Koans](https://github.com/gregmalcolm/python%5Fkoans)\\n* [Go Koans](https://github.com/cdarwin/go-koans)\\n* [Elixir Koans](https://github.com/elixirkoans/elixir-koans)\\n* [Javascript Koans](https://github.com/mrdavidlaing/javascript-koans)\\n* [C# Koans](https://github.com/DotNetKoans/DotNetKoans)\\n\\nThis is just a sample - search GitHub for “koans” and I’m sure you’ll find one for your language.\\n\\n## Katas[Permalink](#katas \\\"Permalink\\\")\\n\\nI love doing coding katas and thankfully, there are a lot of them. I think my favorite is Gilded Rose, but I’ve been having fun with Vending Machine, too.\\n\\nNote: There is some overlap in these lists, and again, just search GitHub for “kata” and you’ll come up with a lot.\\n\\n* [Emily Bache’s list of Katas on GitHub](https://github.com/emilybache)\\n* [Steve Smith’s list of Katas on GitHub](https://github.com/ardalis/kata-catalog)\\n* [Gilded Rose Kata](https://github.com/NotMyself/GildedRose)\\n* [Vending Machine Kata](https://github.com/guyroyse/vending-machine-kata)\\n\\n## My Weekly Links post[Permalink](#my-weekly-links-post \\\"Permalink\\\")\\n\\nThe research I do for my weekly [Interesting Links](https://samestuffdifferentday.net/links) post turns up a ton of great content. I follow a couple hundred blogs on many different topics, so I’m always running into content that teaches me something.\\n\\n## Video Content[Permalink](#video-content \\\"Permalink\\\")\\n\\nWhen it comes to great video content, especially around Azure, I love the work coming from John Savill. I also love watching Adam Savage’s Tested on YouTube just to see a creative mind at work.\\n\\nI have my own Pluralsight subscription, and work provides Udemy for us. I try to catch Pluralsight sales each year to cut my cost in half. I don’t mind Udemy, but when work owns the account, it’s tough because someone can decide to pull it anytime.\\n\\n## Final Thoughts[Permalink](#final-thoughts \\\"Permalink\\\")\\n\\nNo matter what you do, keeping your technical skills up-to-date and sharp is important. Things change so quickly that you should have a plan for getting up to speed on new languages and tech.\\n\\n---\\n\\n[![A seal indicating this page was written by a human](https://proxy-prod.omnivore-image-cache.app/0x0,sW-nmrwACLVtMR3YFUEv5wUxlGn-ornkTqNfARQR2_Vw/https://samestuffdifferentday.net/assets/images/18-real50.jpeg)](https://jasongullickson.com/getting-real.html)\",\"highlights\":[],\"labels\":[{\"id\":\"8ccf8c92-a729-11ee-86b2-131a6b51de26\",\"name\":\"learning\",\"color\":\"#DEF0BA\",\"description\":null,\"createdAt\":\"2023-12-30T15:38:59.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:35:26,779 - INFO - Processing article: My 5 favorite ways of keeping the technical axe sharp - same stuff, different day\n",
      "2024-07-04 23:35:32,041 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"https-pub-towardsai-net-build-rag-with-llamaindex-to-make-llm-an-1905674e7f5\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:35:32,300 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"af8eec2b-780e-4a94-bf7a-19e2a72d0ea1\",\"title\":\"Build Rag With Llamaindex To Make LLM Answer About Yourself, Like in an Interview or About General Information | by Lakshmi Narayana Santha | May, 2024 | Towards AI\",\"url\":\"https://pub.towardsai.net/build-rag-with-llamaindex-to-make-llm-answer-about-yourself-like-in-interview-or-about-general-68bb2037f8b6?gi=d379a686b47c\",\"author\":\"Lakshmi Narayana Santha\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sF_ePdV29i1LheQhORBjVkHFTGUYA0d4sx8ExVHt8_Mk/https://miro.medium.com/v2/resize:fit:1200/1*6q69styF-M0oDu-f9k8AHw.jpeg\",\"savedAt\":\"2024-06-26T21:30:25.000Z\",\"createdAt\":\"2024-06-26T21:30:26.000Z\",\"publishedAt\":\"2024-05-26T21:05:24.000Z\",\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://pub.towardsai.net/build-rag-with-llamaindex-to-make-llm-answer-about-yourself-like-in-interview-or-about-general-68bb2037f8b6?gi=d379a686b47c\",\"readingProgressPercent\":0.1,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"slug\":\"https-pub-towardsai-net-build-rag-with-llamaindex-to-make-llm-an-1905674e7f5\",\"isArchived\":false,\"description\":\"From the day ChatGPT was introduced, the whole NLP/AI ecosystem was changed and came up with numerous new techniques to integrate the LLMs into various fields and use-cases. One of those gems that…\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":1769,\"content\":\"![](https://proxy-prod.omnivore-image-cache.app/700x439,sYa9dxopRsY1HTIUp1FF_CAFhBOZKurtbWeDPUVDjlsc/https://miro.medium.com/v2/resize:fit:700/1*6q69styF-M0oDu-f9k8AHw.jpeg)\\n\\nAdvanced RAG pipeline with Llamaindex for chatting with yourself\\n\\nFrom the day ChatGPT was introduced, the whole NLP/AI ecosystem was changed and came up with numerous new techniques to integrate the LLMs into various fields and use-cases. One of those gems that evolved along with the LLMs is **RAG (Retrieved Augmentation Generation)**. Even with LLMs like Gemini supporting context up to millions of length, RAG is still relevant and has been used for building various applications like chatting with the documents, helping with research processes for specific domain, providing domain-specific data for LLM to inference, and mostly providing companies to integrate AI capabilities with their sensitive customer data.\\n\\nIn this blog, we will see how to build one such use-case with RAG to make LLM answer about yourself. The input data could be your resume or even general information about yourself. I have used some general information like my interests in movies and TV, and brief technical information of my professional career.\\n\\nCheck out my Github repo for a full-stack chat bot application that I have built with Docker, Next.js, and Python (FastAPI, Llamaindex). Refer to the sub-repo **doppalf-ai** for the Python application\\n\\nAfter the final building of the RAG pipeline with Llamaindex, we can see the response from LLM like the following:\\n\\n![](https://proxy-prod.omnivore-image-cache.app/1000x482,s4ZE0Wx4UFl3J8JHyo6qpFkTk5b0u8qPFDmGd4r75c9Q/https://miro.medium.com/v2/resize:fit:1000/1*Oh7txTjBpyIaNJuQrGU7HA.png)\\n\\nA simple response from LLM that assumes your character and answers about you\\n\\nI have used Cohere as LLM and Qdrant for storing vector embeddings. You can create free APIs for both of these to use.\\n\\nCreate [Cohere API trail key](https://dashboard.cohere.com/api-keys) and [Qdrant Cloud API key](https://cloud.qdrant.io/) that offers a free 1 GB cluster for storing vectors.\\n\\n> You can use any other LLM and vector store (or even in-memory storage)\\n\\nWith Llamaindex, we can build a full chat engine with the following steps:\\n\\n1. Load Documents from the directory\\n2. Parse text into Sentences (as nodes) with a Window size as 1 (configurable)\\n3. Get vector embeddings for each node (sentences) (Cohere embeddings)\\n4. Index the nodes and store the vector embeddings (Qdrant cloud)\\n5. Persist the index for re-use further run-times\\n6. Build a Chat engine from the index with a retrieval strategy as “Small-to-Big” and with some buffered chat memory history\\n7. Provide the retrieved context and use Cohere Rerank for re-ranking the retrieved nodes\\n8. Synthesis the response using LLM (Cohere AI) with the retrieved context\\n\\nThe following is the whole RAG pipeline we will build with Llamaindex\\n\\n![](https://proxy-prod.omnivore-image-cache.app/700x439,sYa9dxopRsY1HTIUp1FF_CAFhBOZKurtbWeDPUVDjlsc/https://miro.medium.com/v2/resize:fit:700/1*6q69styF-M0oDu-f9k8AHw.jpeg)\\n\\nThe whole RAG pipeline described above\\n\\nInstall the following Python packages first\\n\\npython-dotenv  \\nfastapi  \\nuvicorn  \\nllama-index  \\nllama-index-embeddings-cohere  \\nllama-index-llms-cohere  \\nllama-index-postprocessor-cohere-rerank  \\nllama-index-vector-stores-qdrant  \\ncohere  \\nqdrant-client\\n\\nThe above dependencies install the FastAPI and core Llamaindex packages. As I am using Cohere and Qdrant with Llamaindex, the above list contains those Llamaindex support packages.\\n\\nGetting into the real action. First, we will get the required configuration (like API Keys, documents location, etc.,) from _.env_ file and load them into the runtime using **python-dotenv** package\\n\\nDOCS_DIR=\\\"documents\\\"  \\nINDEX_STORAGE_DIR=\\\"pstorage\\\"  \\nCOLLECTION_NAME=\\\"ps_rag\\\"\\n\\nMAX_BUFFER_MEMORY_TOKENS=4096\\n\\nCOHERE_API_KEY=<cohere-api-key>  \\nQDRANT_API_KEY=<qdrant-api-key>  \\nQDRANT_CLOUD_URL=<qdrant-cloud-url>\\n\\nLoad the above _.env_ file into the program runtime as\\n\\nfrom typing import Self  \\nimport os  \\nfrom threading import Lock\\n\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\nenv_keys = {  \\n    \\\"DOCS_DIR\\\": \\\"DOCS_DIR\\\",  \\n    \\\"INDEX_STORAGE_DIR\\\": \\\"INDEX_STORAGE_DIR\\\",  \\n    \\\"COLLECTION_NAME\\\": \\\"COLLECTION_NAME\\\",  \\n    \\\"MAX_BUFFER_MEMORY_TOKENS\\\": \\\"MAX_BUFFER_MEMORY_TOKENS\\\",  \\n    \\\"COHERE_API_KEY\\\": \\\"COHERE_API_KEY\\\",  \\n    \\\"QDRANT_API_KEY\\\": \\\"QDRANT_API_KEY\\\",  \\n    \\\"QDRANT_CLOUD_URL\\\": \\\"QDRANT_CLOUD_URL\\\",  \\n}\\n\\ndef check_all_dict_keys_not_none(o: dict) -> bool:  \\n    for v in o.values():  \\n        if v is None:  \\n            return False\\n\\n        return True\\n\\nclass ENV():  \\n    _env_instance = None  \\n    _env_config = {}  \\n    _lock = Lock()\\n\\n    def __new__(cls) -> Self:  \\n        if cls._env_instance is None:  \\n            with cls._lock:  \\n                if cls._env_instance is None:  \\n                    cls._env_instance = super(ENV, cls).__new__(cls)  \\n                    cls._env_instance._load_env()\\n\\n        return cls._env_instance\\n\\n        def _load_env(self):  \\n        config = {}  \\n        for v in env_keys.values():  \\n            config[v] = os.getenv(v)\\n\\n        if not check_all_dict_keys_not_none(config):  \\n            raise ValueError(\\\"env has some values missing\\\")\\n\\n        self._env_config = config\\n\\n        def get(self, key:str) -> any:  \\n        return self._env_config.get(key)\\n\\nWe have loaded the environment variables into a Single class and we can get the loaded object that has environment variables stored.\\n\\nI have used the following brief information about my professional career:\\n\\nSantha Lakshmi Narayana holds the role of Senior Software Engineer at Nouveau Labs in Bengaluru, India. His expertise lies in AI, Machine Learning, and Backend technologies, with a deep understanding of Advanced Image Processing, Computer Vision, NLP, and System Design & Architecture. Throughout his career, he has contributed to various projects, including Contact-center solutions (both call and chat), AutoML, Image enhancement, Search information extraction, and Name matching & mapping.\\n\\nWith a strong belief in prioritizing performance-optimized code quality over quantity, Lakshmi Narayana is dedicated to delivering robust software solutions that remain resilient even with new additions or modifications.\\n\\nHis core proficiencies encompass Python, Go, OpenCV, Keras, Pytorch, Tensorflow, Redis, and MySQL. Additionally, he has experience in JavaScript, TypeScript, React, React Native, Next.js, Flutter, and Dart.\\n\\nFor effective service management, he relies on tools such as Git, Nginx, Docker, and Kubernetes. He actively shares his insights, project developments, comprehensive research, and other tech-related content through his blog hosted at https://santhalakshminarayana.github.io.\\n\\nHe also maintains an active presence on GitHub (https://github.com/santhalakshminarayana), where he oversees repositories for side projects like AutoML and Image enhancement.\\n\\nAlong with this I have also provided some personal interests in Movies and TV. All these documents are stored inside the directory **_documents,_** and Llamaindex loads the documents from this directory\\n\\nAnd finally, the whole code for the RAG pipeline is\\n\\nfrom llama_index.core import load_index_from_storage  \\nfrom llama_index.core.memory import ChatMemoryBuffer  \\nfrom llama_index.core.node_parser import SentenceWindowNodeParser  \\nfrom llama_index.core.postprocessor import MetadataReplacementPostProcessor  \\nfrom llama_index.embeddings.cohere import CohereEmbedding  \\nfrom llama_index.llms.cohere import Cohere  \\nfrom llama_index.postprocessor.cohere_rerank import CohereRerank  \\nfrom llama_index.vector_stores.qdrant import QdrantVectorStore  \\nfrom qdrant_client import QdrantClient\\n\\nfrom src.config.env import ENV, env_keys  \\nfrom src.config.logger import get_logger\\n\\nfrom .constants import CHAT_PROMPT\\n\\nenvk = ENV()  \\nlogger = get_logger()\\n\\nindex = None  \\nchat_engine = None\\n\\ndef load_rag() -> None:  \\n    global index  \\n    global chat_engine\\n\\n    cdir = os.getcwd()  \\n    docs_dir = envk.get(env_keys.get(\\\"DOCS_DIR\\\"))  \\n    docs_path = os.path.join(cdir, docs_dir)\\n\\n      \\n    if not os.path.exists(docs_path):  \\n        raise FileNotFoundError(f\\\"Documents dir at path: {docs_path} not exists.\\\")  \\n    if not os.listdir(docs_dir):  \\n        raise FileNotFoundError(f\\\"Provide documents inside directory: {docs_path} for indexing.\\\")\\n\\n        storage_dir = envk.get(env_keys.get(\\\"INDEX_STORAGE_DIR\\\"))  \\n    storage_path = os.path.join(cdir, storage_dir)\\n\\n        cohere_api_key = envk.get(env_keys.get(\\\"COHERE_API_KEY\\\"))  \\n    qdrant_api_key = envk.get(env_keys.get(\\\"QDRANT_API_KEY\\\"))\\n\\n    Settings.llm = Cohere(  \\n        api_key=cohere_api_key,  \\n        model=\\\"command-r-plus\\\",   \\n    )  \\n    Settings.embed_model = CohereEmbedding(  \\n        cohere_api_key=cohere_api_key,  \\n        model_name=\\\"embed-english-v3.0\\\",  \\n        input_type=\\\"search_document\\\",  \\n    )\\n\\n        qd_client = QdrantClient(  \\n        envk.get(env_keys.get(\\\"QDRANT_CLOUD_URL\\\")),  \\n        api_key=qdrant_api_key,  \\n    )\\n\\n    sentence_node_parser = SentenceWindowNodeParser.from_defaults(  \\n        window_size=1,  \\n        window_metadata_key=\\\"window\\\",  \\n        original_text_metadata_key=\\\"original_text\\\",   \\n    )\\n\\n    vector_store = QdrantVectorStore(  \\n        client=qd_client,   \\n        collection_name=envk.get(env_keys.get(\\\"COLLECTION_NAME\\\")),  \\n    )\\n\\n      \\n    if os.path.exists(storage_path) and os.listdir(storage_path):  \\n        logger.debug(\\\"Using existing index.\\\")  \\n        storage_context = StorageContext.from_defaults(  \\n            vector_store=vector_store, persist_dir=storage_path  \\n        )\\n\\n                index = load_index_from_storage(storage_context)\\n\\n    else:  \\n        logger.debug(\\\"Creating new index for documents.\\\")  \\n        reader = SimpleDirectoryReader(input_dir=docs_path)\\n\\n                all_docs = []  \\n        for docs in reader.iter_data():  \\n            all_docs.extend(docs)\\n\\n                for doc in all_docs:  \\n            logger.debug(f\\\"id: {doc.doc_id}\\\\nmetada: {doc.metadata}\\\")\\n\\n        nodes = sentence_node_parser.get_nodes_from_documents(all_docs)\\n\\n                storage_context = StorageContext.from_defaults(vector_store=vector_store)\\n\\n                index = VectorStoreIndex(nodes, storage_context=storage_context)\\n\\n        index.storage_context.persist(persist_dir=storage_path)\\n\\n    chat_engine = index.as_chat_engine(  \\n        chat_mode=\\\"condense_plus_context\\\",  \\n        memory=ChatMemoryBuffer.from_defaults(token_limit=int(envk.get(env_keys.get(\\\"MAX_BUFFER_MEMORY_TOKENS\\\")))),  \\n        context_prompt=CHAT_PROMPT,  \\n        similarity_top_k=3,   \\n        node_postprocessors=[  \\n            MetadataReplacementPostProcessor(target_metadata_key=\\\"window\\\"),  \\n            CohereRerank(api_key=cohere_api_key, top_n=3),  \\n        ],  \\n        verbose=False,  \\n    )\\n\\ndef chat(query: str):  \\n    global chat_engine\\n\\n        response = chat_engine.stream_chat(query)  \\n    for res in response.response_gen:  \\n        yield f\\\"data: {json.dumps({\\\"message\\\":res})}\\\\n\\\\n\\\"\\n\\nThe **load\\\\_rag()** function will first check if any previously stored index exists for re-using else it will build one. If no index is stored in the given _storage\\\\_path_ directory, it will build the index by loading the documents from the _docs\\\\_dir_ directory. **SentenceWindowNodeParser** is used for parsing the sentences into nodes with a window size of 1\\\\. This window size makes the post-retrieval context have surrounding sentences also part of it for better answer synthesis.\\n\\nFor created nodes, get the vector embeddings from the Cohere embeddings and store them in the Qdrant Cloud. And finally store the index for skipping this whole process again when the application restarts.\\n\\nFrom the index, build the chat engine with some memory (4096 tokens here) for memorising past conversations with the user and provide Cohere Re-ranker as post node retrieval processer for reranking the nodes based on the query relevancy. This chat engine retrieves the surrounding context for each retrieved node for more information and finally sends the whole retrieved-context and the query to the LLM for answer generation as a prompt. I have used a custom prompt for making LLM answer as me.\\n\\nCHAT_PROMPT=(  \\n    \\\"You are impersonating the human 'Lakshmi Narayana' and so your name.\\\"  \\n    \\\"So you are Lakshmi Narayana and answers in first person.When asked any question about you, you will answer as if Lakshmi Narayana is answering.\\\"  \\n    \\\"You will answer politely and take the help of the following context for more relevant answers.\\\"  \\n    \\\"If you don't have any sufficient information from the context, use your knowledge to answer.\\\"  \\n    \\\"Or don't hallucinate if you are sure you cannot answer.\\\"  \\n    \\\"Here are the relevant documents for the context:\\\\n{context_str}\\\\n\\\"  \\n    \\\"Instruction: Use the previous chat history, or the context above, to interact and help the user and answer as if you are Lakshmi Narayana.\\\"  \\n    \\\"Don't add any additional data if the answer can be derived from context.\\\"  \\n    \\\"Generate the response in markdown format.\\\"  \\n)\\n\\nLLamaindex uses this prompt for context ingestion and sends this to LLM for answer generation.\\n\\nFinally, the chat generation API is exposed for streaming the response using FastAPI as follows\\n\\nfrom fastapi import APIRouter, HTTPException  \\nfrom pydantic import BaseModel  \\nfrom starlette.responses import StreamingResponse\\n\\nfrom .rag import chat\\n\\nclass GenerateModel(BaseModel):  \\n    message: str\\n\\ngrouter = APIRouter(tags=[\\\"generate\\\"])\\n\\n@grouter.post(\\\"\\\")  \\nasync def generate(data: GenerateModel):  \\n    try:  \\n        return StreamingResponse(  \\n            chat(data.message),   \\n            media_type='text/event-stream',  \\n        )  \\n    except Exception as e:  \\n        raise HTTPException(status_code=500, detail=e)\\n\\nThe above API **generate** takes the user query as part of request body data with key message and calls the **chat** function for generating the answer.\\n\\nThis will generate the response and stream to the client as SSE (Server Sent Event).\\n\\nWith all of the above things done, if the API is requested with a user query like the following and the LLM will answer about me as\\n\\n![](https://proxy-prod.omnivore-image-cache.app/1000x477,saESyWojxwuHGO219-k6dvefb9rUmT0yF-9QTeO_O8AU/https://miro.medium.com/v2/resize:fit:1000/1*bf1wFfW86EQZ_PZebnlhrA.png)\\n\\nWith the help Llamaindex and a small RAG pipeline we could build a AI chat bot that answer about ourselves. Hope this small article provides a guidance on how to build simple RAG powered chat bot applications for real world scenarios.\\n\\nI have written a comprehensive blog about this whole full-stack project Doppalf on my personal blog. Read the following blog for more details\\n\\n![](https://proxy-prod.omnivore-image-cache.app/1000x479,scyAEMs6XoQvMPLNM2aS6nDFFO_Y229YSf-ktWDCpykk/https://miro.medium.com/v2/resize:fit:1000/1*u9a5nLTTnkDzbQgQG6RjFQ.gif)\\n\\nChatbot with UI like Chat GPT\\n\\nYou can get the whole project code for end-to-end chatbot application with UI (streaming answers like ChatGPT) and backend in my Github repo:\",\"highlights\":[],\"labels\":[{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\",\"description\":\"\",\"createdAt\":\"2023-12-30T20:44:43.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"},{\"id\":\"23050f0a-a754-11ee-9ac0-7781771f40cc\",\"name\":\"rag\",\"color\":\"#2B33B3\",\"description\":\"\",\"createdAt\":\"2023-12-30T20:43:50.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:35:32,303 - INFO - Processing article: Build Rag With Llamaindex To Make LLM Answer About Yourself, Like in an Interview or About General Information | by Lakshmi Narayana Santha | May, 2024 | Towards AI\n",
      "2024-07-04 23:35:38,339 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"https-github-com-squaredtechnologies-thread-19007f81c32\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:35:38,576 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"2b01bd32-2b2b-48a2-9269-75c3fe1e973c\",\"title\":\"GitHub - squaredtechnologies/thread: AI-Powered Jupyter Notebook built using React\",\"url\":\"https://github.com/squaredtechnologies/thread\",\"author\":\"squaredtechnologies\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,svAp5XibUO3Uvpk8PCo6uVacWJlrnUJalSbKo_T0Zs4I/https://github.com/AI-Powered%20Jupyter%20Notebook%20built%20using%20React.%20Contribute%20to%20squaredtechnologies/thread%20development%20by%20creating%20an%20account%20on%20GitHub.\",\"savedAt\":\"2024-06-11T15:43:42.000Z\",\"createdAt\":\"2024-06-11T15:43:39.000Z\",\"publishedAt\":null,\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://github.com/squaredtechnologies/thread\",\"readingProgressPercent\":79,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":12,\"slug\":\"https-github-com-squaredtechnologies-thread-19007f81c32\",\"isArchived\":false,\"description\":\"AI-Powered Jupyter Notebook built using React. Contribute to squaredtechnologies/thread development by creating an account on GitHub.\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":74,\"content\":\"* * [ Actions Automate any workflow ](https://github.com/features/actions)  \\n   * [ Packages Host and manage packages ](https://github.com/features/packages)  \\n   * [ Security Find and fix vulnerabilities ](https://github.com/features/security)  \\n   * [ Codespaces Instant dev environments ](https://github.com/features/codespaces)  \\n   * [ GitHub Copilot Write better code with AI ](https://github.com/features/copilot)  \\n   * [ Code review Manage code changes ](https://github.com/features/code-review)  \\n   * [ Issues Plan and track work ](https://github.com/features/issues)  \\n   * [ Discussions Collaborate outside of code ](https://github.com/features/discussions)\\n* * [ GitHub Sponsors Fund open source developers ](https://github.com/sponsors)  \\n   * [ The ReadME Project GitHub community articles ](https://github.com/readme)\\n* * [ Enterprise platform AI-powered developer platform ](https://github.com/enterprise)\\n* [Pricing](https://github.com/pricing)\\n\\n##  Provide feedback\\n\\n##  Saved searches\\n\\n## Use saved searches to filter your results more quickly\\n\\n[ Sign up](https://github.com/signup?ref%5Fcta=Sign+up&ref%5Floc=header+logged+out&ref%5Fpage=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source%5Frepo=squaredtechnologies%2Fthread) \",\"highlights\":[],\"labels\":[{\"id\":\"4784410c-3160-11ef-af1b-d3d9c4d57542\",\"name\":\"jupyter-notebook\",\"color\":\"#5791C7\",\"description\":null,\"createdAt\":\"2024-06-23T12:58:25.000Z\"},{\"id\":\"4d188510-3160-11ef-95ac-476b5d5c1917\",\"name\":\"ollama\",\"color\":\"#CC5433\",\"description\":null,\"createdAt\":\"2024-06-23T12:58:35.000Z\"},{\"id\":\"7b8cce22-ad05-11ee-8a20-cb19d834d783\",\"name\":\"ai\",\"color\":\"#FFFCE3\",\"description\":\"\",\"createdAt\":\"2024-01-07T02:35:55.000Z\"},{\"id\":\"b02fecd0-b7f6-11ee-a2a9-c3207c9538ff\",\"name\":\"python\",\"color\":\"#21BDFF\",\"description\":null,\"createdAt\":\"2024-01-21T00:47:44.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:35:38,581 - INFO - Processing article: GitHub - squaredtechnologies/thread: AI-Powered Jupyter Notebook built using React\n",
      "2024-07-04 23:35:42,756 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"https-www-marktechpost-com-2024-05-19-meet-verba-1-0-run-state-o-18f9da53dc3\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:35:43,014 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"933c6b4b-0a25-4f5a-9b0f-e44b352bddd8\",\"title\":\"Meet Verba 1.0: Run State-of-the-Art RAG Locally with Ollama Integration and Open Source Models - MarkTechPost\",\"url\":\"https://www.marktechpost.com/2024/05/19/meet-verba-1-0-run-state-of-the-art-rag-locally-with-ollama-integration-and-open-source-models/?amp=\",\"author\":\"Asif Razzaq\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,svK9eP_lW5jXltNjE2p6kB7-ajWFH1QTZ3X3Q3eKGAxY/https://www.marktechpost.com/wp-content/uploads/2024/05/verba_screen.png\",\"savedAt\":\"2024-05-22T00:13:26.000Z\",\"createdAt\":\"2024-05-22T00:13:23.000Z\",\"publishedAt\":\"2024-05-20T04:45:10.000Z\",\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://www.marktechpost.com/2024/05/19/meet-verba-1-0-run-state-of-the-art-rag-locally-with-ollama-integration-and-open-source-models/?amp=\",\"readingProgressPercent\":94,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":28,\"slug\":\"https-www-marktechpost-com-2024-05-19-meet-verba-1-0-run-state-o-18f9da53dc3\",\"isArchived\":false,\"description\":\"Retrieval-augmented generation (RAG) is a cutting-edge technique in artificial intelligence that combines the strengths of retrieval-based approaches with generative models. This integration allows for creating high-quality, contextually relevant responses by leveraging vast datasets. RAG has significantly improved the performance of virtual assistants, chatbots, and information retrieval systems by ensuring that generated responses are accurate and contextually appropriate. The synergy of retrieval and generation enhances the user experience by providing detailed and specific information. One of the primary challenges in AI is delivering precise and contextually relevant information from extensive datasets. Traditional methods often need help maintaining the necessary context, leading\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":755,\"content\":\"[![](https://proxy-prod.omnivore-image-cache.app/0x0,sbx_Gs7P_Bjj-Gj2KVzmp6Sv351thU7Km2xmgYswB_1U/https://www.marktechpost.com/wp-content/uploads/2024/05/verba_screen.png \\\"verba_screen\\\")](https://www.marktechpost.com/wp-content/uploads/2024/05/verba%5Fscreen.png)\\n\\nhttps://github.com/weaviate/Verba\\n\\nRetrieval-augmented generation (RAG) is a cutting-edge technique in artificial intelligence that combines the strengths of retrieval-based approaches with generative models. This integration allows for creating high-quality, contextually relevant responses by leveraging vast datasets. RAG has significantly improved the performance of virtual assistants, chatbots, and information retrieval systems by ensuring that generated responses are accurate and contextually appropriate. The synergy of retrieval and generation enhances the user experience by providing detailed and specific information.\\n\\nOne of the primary challenges in AI is delivering precise and contextually relevant information from extensive datasets. Traditional methods often need help maintaining the necessary context, leading to generic or inaccurate responses. This problem is particularly evident in applications requiring detailed information retrieval and a deep understanding of context. The inability to seamlessly integrate retrieval and generation processes has been a significant barrier to advancing AI applications in various fields.\\n\\nCurrent methods in the field include keyword-based search engines and advanced neural network models like BERT and GPT. While these tools have significantly improved information retrieval, they cannot often effectively combine retrieval and generation. Keyword-based search engines can retrieve relevant documents but do not generate new insights. On the other hand, generative models can produce coherent text but may need help to retrieve the most pertinent information. \\n\\nResearchers from Weaviate have introduced[**Verba 1.0**](https://github.com/weaviate/Verba/releases), a solution that can bridge retrieval and generation to enhance the overall effectiveness of AI systems. Verba 1.0 integrates state-of-the-art RAG techniques with a context-aware database. The tool is designed to improve the accuracy and relevance of AI-generated responses by combining advanced retrieval and generative capabilities. This collaboration has resulted in a versatile tool that can handle diverse data formats and provide contextually accurate information. [**Check out the release video!**](https://www.youtube.com/watch?v=swKKRdLBhas&ab%5Fchannel=Weaviate%E2%80%A2VectorDatabase)\\n\\nVerba 1.0 employs a variety of models, including Ollama’s Llama3, HuggingFace’s MiniLMEmbedder, Cohere’s Command R+, Google’s Gemini, and OpenAI’s GPT-4\\\\. These models support embedding and generation, allowing Verba to process various data types, such as PDFs and CSVs. The tool’s customizable approach enables users to select the most suitable models and techniques for their specific use cases. For instance, Ollama’s Llama3 provides robust local embedding and generation capabilities, while HuggingFace’s MiniLMEmbedder offers efficient local embedding models. Cohere’s Command R+ enhances embedding and generation, and Google’s Gemini and OpenAI’s GPT-4 further expand Verba’s capabilities.\\n\\nVerba 1.0 has demonstrated significant improvements in information retrieval and response generation. Its hybrid search and semantic caching features enable faster and more accurate data retrieval. For example, Verba’s hybrid search combines semantic search with keyword search, saving and retrieving results based on semantic meaning. This approach has enhanced query precision and the ability to handle diverse data formats, making Verba a versatile solution for numerous applications. The tool’s ability to suggest autocompletion and apply filters before performing RAG has further improved its performance.\\n\\nNotable results from Verba 1.0 include the successful handling of complex queries and the efficient retrieval of relevant information. The tool’s semantic caching and hybrid search capabilities have significantly enhanced performance. Verba’s support for various data formats, including PDFs, CSVs, and unstructured data, has made it a valuable asset for diverse applications. The tool’s performance metrics indicate substantial improvements in query precision and response accuracy, highlighting its potential to transform AI applications.\\n\\nIn conclusion, Verba 1.0 addresses the challenges of precise information retrieval and context-aware response generation by integrating advanced RAG techniques and supporting multiple data formats. The tool’s ability to combine retrieval and generative capabilities has enhanced query precision and efficiently handled diverse data formats. Verba 1.0’s innovative approach and robust performance make it a valuable addition to the AI toolkit, promising to improve the quality and relevance of generated responses across various applications.\\n\\n---\\n\\n**Sources**\\n\\n* <https://github.com/weaviate/Verba/releases>\\n* <https://github.com/weaviate/Verba>\\n* https://x.com/victorialslocum/status/1791127879209631799\\n\\n[ ![](https://proxy-prod.omnivore-image-cache.app/150x150,sYzmwL91t6iHEjvGnvG9XzoU3JX3hWwRG5yPdp6fMLeE/https://www.marktechpost.com/wp-content/uploads/2019/06/Screen-Shot-2021-09-14-at-9.02.24-AM-150x150.png)![](https://proxy-prod.omnivore-image-cache.app/0x0,sK6Db_4MnnQ9LrZ8isKcBpf7eEM1WlehwsH0WuUvXLd4/https://www.marktechpost.com/wp-content/uploads/2019/06/Screen-Shot-2021-09-14-at-9.02.24-AM-150x150.png) ](https://www.marktechpost.com/author/6flvq/?amp) \\n\\nAsif Razzaq is the CEO of Marktechpost Media Inc.. As a visionary entrepreneur and engineer, Asif is committed to harnessing the potential of Artificial Intelligence for social good. His most recent endeavor is the launch of an Artificial Intelligence Media Platform, Marktechpost, which stands out for its in-depth coverage of machine learning and deep learning news that is both technically sound and easily understandable by a wide audience. The platform boasts of over 2 million monthly views, illustrating its popularity among audiences.\",\"highlights\":[],\"labels\":[{\"id\":\"23050f0a-a754-11ee-9ac0-7781771f40cc\",\"name\":\"rag\",\"color\":\"#2B33B3\",\"description\":\"\",\"createdAt\":\"2023-12-30T20:43:50.000Z\"},{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\",\"description\":\"\",\"createdAt\":\"2023-12-30T20:44:43.000Z\"},{\"id\":\"8f4ce554-2916-11ef-8161-fbb712d47c7f\",\"name\":\"github\",\"color\":\"#3B7AD6\",\"description\":null,\"createdAt\":\"2024-06-12T23:50:34.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"},{\"id\":\"ccd77f96-315a-11ef-9ad5-3f5267ab5c7e\",\"name\":\"_add2blog\",\"color\":\"#DC34FF\",\"description\":\"\",\"createdAt\":\"2024-06-23T12:19:12.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:35:43,019 - INFO - Processing article: Meet Verba 1.0: Run State-of-the-Art RAG Locally with Ollama Integration and Open Source Models - MarkTechPost\n",
      "2024-07-04 23:35:48,954 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"https-www-freecodecamp-org-news-beginners-guide-to-langchain-18ed9ea2aae\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:35:49,204 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"81756117-7cc2-4c9a-8f99-2ad9b09072d8\",\"title\":\"How to Use LangChain to Build With LLMs – A Beginner's Guide\",\"url\":\"https://www.freecodecamp.org/news/beginners-guide-to-langchain/\",\"author\":\"Jacob Lee\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,slAcKNRHBeiEW8ZyPZLa2cI44rOXxk049Ah0RHUQePmg/https://www.freecodecamp.org/news/content/images/2024/04/freecodecamp_cover_image.png\",\"savedAt\":\"2024-04-14T00:03:10.000Z\",\"createdAt\":\"2024-04-14T00:03:06.000Z\",\"publishedAt\":\"2024-04-11T23:11:37.000Z\",\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://www.freecodecamp.org/news/beginners-guide-to-langchain/\",\"readingProgressPercent\":0,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"slug\":\"https-www-freecodecamp-org-news-beginners-guide-to-langchain-18ed9ea2aae\",\"isArchived\":false,\"description\":\"Large language models (LLMs) are incredibly powerful general reasoning tools\\nthat are useful in a wide range of situations. \\n\\nBut working with LLMs presents challenges that are different from building\\ntraditional software:\\n\\n * Calls tend to be long-running, and stream generate output as it becomes\\n   available.\\n * Instead of structured input (something like JSON) with fixed parameters, they\\n   take unstructured and arbitrary natural language as input. They are capable\\n   of “understanding” subtl\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":2572,\"content\":\"![How to Use LangChain to Build With LLMs – A Beginner's Guide](https://proxy-prod.omnivore-image-cache.app/1792x1024,sTj-2mr8KhCiQAK1nR3ZolsBXMd0XEDNOS8accV2XajY/https://www.freecodecamp.org/news/content/images/size/w2000/2024/04/freecodecamp_cover_image.png) \\n\\nLarge language models (LLMs) are incredibly powerful general reasoning tools that are useful in a wide range of situations. \\n\\nBut working with LLMs presents challenges that are different from building traditional software:\\n\\n* Calls tend to be long-running, and stream generate output as it becomes available.\\n* Instead of structured input (something like JSON) with fixed parameters, they take unstructured and arbitrary natural language as input. They are capable of “understanding” subtleties of that language.\\n* They are non-deterministic. You may get different outputs even with the same input.\\n\\n[LangChain](https://langchain.com/) is a popular framework for creating LLM-powered apps. It was built with these and other factors in mind, and provides a wide range of [integrations](https://python.langchain.com/docs/integrations/platforms/) with closed-source model providers (like [OpenAI](https://openai.com/), [Anthropic](https://www.anthropic.com/), and [Google](https://gemini.google.com/)), open source models, and other third-party components like vectorstores.\\n\\nThis article will walk through the fundamentals of building with LLMs and [LangChain’s Python library](https://python.langchain.com/). The only requirement is basic familiarity with Python, – no machine learning experience needed!\\n\\nYou’ll learn about:\\n\\n* [Basic project setup](#project-setup)\\n* [Using Chat Models and other fundamental LangChain components](#first-steps)\\n* [Using LangChain Expression Language to create chains](#chaining)\\n* [Streaming output as soon as it is generated](#streaming)\\n* [Passing context to steer the model’s output (basic RAG concepts)](#how-to-guide-generation-with-context)\\n* [Debugging and tracing the internals of your chains](#debugging)\\n\\nLet’s dive in!\\n\\n## Project Setup\\n\\nWe recommend using a [Jupyter notebook](https://jupyter.org/) to run the code in this tutorial since it provides a clean, interactive environment. See [this page](https://jupyter.org/install) for instructions on setting it up locally, or check out [Google Colab](https://colab.research.google.com/) for an in-browser experience.\\n\\nThe first thing you'll need to do is choose which Chat Model you want to use. If you've ever used an interface like ChatGPT before, the basic idea of a Chat Model will be familiar to you – the model takes messages as input, and returns messages as output. The difference is that we'll be doing it in code.\\n\\nThis guide defaults to [Anthropic](https://python.langchain.com/docs/integrations/platforms/anthropic/) and their Claude 3 Chat Models, but LangChain also has a [wide range of other integrations](https://python.langchain.com/docs/integrations/chat/) to choose from, including OpenAI models like GPT-4.\\n\\n```cmake\\npip install langchain_core langchain_anthropic\\n\\n```\\n\\nIf you’re working in a Jupyter notebook, you’ll need to prefix `pip` with a `%` symbol like this: `%pip install langchain_core langchain_anthropic`.\\n\\nYou’ll also need an Anthropic API key, which you can [obtain here](https://console.anthropic.com/) from their console. Once you have it, set as an environment variable named `ANTHROPIC_API_KEY`:\\n\\n```routeros\\nexport ANTHROPIC_API_KEY=\\\"...\\\"\\n\\n```\\n\\nYou can also pass a key directly into the model if you prefer.\\n\\n## First steps\\n\\nYou can initialize your model like this:\\n\\n```routeros\\nfrom langchain_anthropic import ChatAnthropic\\n\\nchat_model = ChatAnthropic(\\n    model=,\\n    temperature=0\\n)\\n\\n# If you prefer to pass your key explicitly\\n# chat_model = ChatAnthropic(\\n\\n#   temperature=0,\\n#   api_key=\\\"YOUR_ANTHROPIC_API_KEY\\\"\\n# )\\n```\\n\\nThe `model` parameter is a string that matches one of [Anthropic’s supported models](https://docs.anthropic.com/claude/docs/models-overview#model-comparison). At the time of writing, Claude 3 Sonnet strikes a good balance between speed, cost, and reasoning capability. \\n\\n`temperature` is a measure of the amount of randomness the model uses to generate responses. For consistency, in this tutorial, we set it to `0` but you can experiment with higher values for creative use cases.\\n\\nNow, let’s try running it:\\n\\n```less\\nchat_model.invoke(\\\"Tell me a joke about bears!\\\")\\n\\n```\\n\\nHere’s the output:\\n\\n```gcode\\nAIMessage(content=\\\"Here's a bear joke for you:\\\\\\\\n\\\\\\\\nWhy did the bear dissolve in water?\\\\\\\\nBecause it was a polar bear!\\\")\\n\\n```\\n\\nYou can see that the output is something called an `AIMessage`. This is because Chat Models use [Chat Messages](https://python.langchain.com/docs/modules/model%5Fio/chat/message%5Ftypes/) as input and output.\\n\\n**Note:** You were able to pass a simple string as input in the previous example because LangChain accepts a few forms of convenience shorthand that it automatically converts to the proper format. In this case, a single string is turned into an array with a single `HumanMessage`.\\n\\nLangChain also contains abstractions for pure text-completion LLMs, which are string input and string output. But at the time of writing, the chat-tuned variants have overtaken LLMs in popularity. For example, GPT-4 and Claude 3 are both Chat Models.\\n\\nTo illustrate what’s going on, you can call the above with a more explicit list of messages:\\n\\n```capnproto\\nfrom langchain_core.messages import HumanMessage\\n\\nchat_model.invoke([\\n    HumanMessage(\\\"Tell me a joke about bears!\\\")\\n])\\n\\n```\\n\\nAnd you get a similar output:\\n\\n```gcode\\nAIMessage(content=\\\"Here's a bear joke for you:\\\\\\\\n\\\\\\\\nWhy did the bear bring a briefcase to work?\\\\\\\\nHe was a business bear!\\\")\\n\\n```\\n\\n### Prompt Templates\\n\\nModels are useful on their own, but it’s often convenient to parameterize inputs so that you don’t repeat boilerplate. LangChain provides **[Prompt Templates](https://python.langchain.com/docs/modules/model%5Fio/prompts/)** for this purpose. \\n\\n![prompt_and_model--1-](https://proxy-prod.omnivore-image-cache.app/1396x680,sJWS5sBx1eVBz1xsFjAm_mT70K6M7WIJJ99Efo70s_TQ/https://www.freecodecamp.org/news/content/images/2024/04/prompt_and_model--1-.png)\\n\\nPrompt templates in LangChain\\n\\nA simple example would be something like this:\\n\\n```smalltalk\\nfrom langchain_core.prompts import ChatPromptTemplate\\n\\njoke_prompt = ChatPromptTemplate.from_messages([\\n    (\\\"system\\\", \\\"You are a world class comedian.\\\"),\\n    (\\\"human\\\", \\\"Tell me a joke about {topic}\\\")\\n])\\n\\n```\\n\\nYou can apply the templating using the same `.invoke()` method as with Chat Models:\\n\\n```llvm\\njoke_prompt.invoke({\\\"topic\\\": \\\"beets\\\"})\\n\\n```\\n\\nHere’s the result:\\n\\n```lisp\\nChatPromptValue(messages=[\\n    SystemMessage(content='You are a world class comedian.'),\\n    HumanMessage(content='Tell me a joke about beets')\\n])\\n\\n```\\n\\nLet’s go over each step:\\n\\n* You construct a prompt template consisting of templates for a `SystemMessage` and a `HumanMessage` using `from_messages`.\\n* You can think of `SystemMessages` as meta-instructions that are not part of the current conversation, but purely guide input.\\n* The prompt template contains `{topic}` in curly braces. This denotes a required parameter named `\\\"topic\\\"`.\\n* You invoke the prompt template with a dict with a key named `\\\"topic\\\"` and a value `\\\"beets\\\"`.\\n* The result contains the formatted messages.\\n\\nNext, you'll learn how to use this prompt template with your Chat Model.\\n\\n## Chaining\\n\\nYou may have noticed that both the Prompt Template and Chat Model implement the `.invoke()` method. In LangChain terms, they are both instances of **[Runnables](https://python.langchain.com/docs/expression%5Flanguage/interface/).**\\n\\nYou can compose Runnables into “chains” using the pipe (`|`) operator where you `.invoke()` the next step with the output of the previous one. Here’s an example:\\n\\n```ini\\nchain = joke_prompt | chat_model\\n\\n```\\n\\nThe resulting `chain` is itself a Runnable and automatically implements `.invoke()` (as well as several other methods, as we’ll see later). This is the foundation of [LangChain Expression Language (LCEL)](https://www.notion.so/freeCodeCamp-tutorial-2bc41bae0989431a8dabc5ec30173352?pvs=21).\\n\\nLet’s invoke this new chain:\\n\\n```llvm\\nchain.invoke({\\\"topic\\\": \\\"beets\\\"})\\n\\n```\\n\\nThe chain returns a joke whose topic is beets:\\n\\n```gcode\\nAIMessage(content=\\\"Here's a beet joke for you:\\\\\\\\n\\\\\\\\nWhy did the beet blush? Because it saw the salad dressing!\\\")\\n\\n```\\n\\nNow, let’s say you want to work with just the raw string output of the message. LangChain has a component called an **[Output Parser](https://python.langchain.com/docs/modules/model%5Fio/output%5Fparsers/)**, which, as the name implies, is responsible for parsing the output of a model into a more accessible format. Since composed chains are also Runnable, you can again use the pipe operator:\\n\\n```capnproto\\nfrom langchain_core.output_parsers import StrOutputParser\\n\\nstr_chain = chain | StrOutputParser()\\n\\n# Equivalent to:\\n# str_chain = joke_prompt | chat_model | StrOutputParser()\\n\\n```\\n\\nCool! Now let’s invoke it:\\n\\n```llvm\\nstr_chain.invoke({\\\"topic\\\": \\\"beets\\\"})\\n\\n```\\n\\nAnd the result is now a string as we’d hoped:\\n\\n```smalltalk\\n\\\"Here's a beet joke for you:\\\\\\\\n\\\\\\\\nWhy did the beet blush? Because it saw the salad dressing!\\\"\\n\\n```\\n\\nYou still pass `{\\\"topic\\\": \\\"beets\\\"}` as input to the new `str_chain` because the first Runnable in the sequence is still the Prompt Template you declared before.\\n\\n![prompt_model_and_output_parser--1-](https://proxy-prod.omnivore-image-cache.app/772x329,sp2Qbkztiieq0hNiHGaVhixlOcYL3RyenGI5A0QsAp0Y/https://www.freecodecamp.org/news/content/images/2024/04/prompt_model_and_output_parser--1-.png)\\n\\nPrompt model and output parser\\n\\n## Streaming\\n\\nOne of the biggest advantages to composing chains with LCEL is the streaming experience. \\n\\nAll Runnables implement the `.stream()`method (and `.astream()` if you’re working in async environments), including chains. This method returns a generator that will yield output as soon as it’s available, which allows us to get output as quickly as possible.\\n\\nWhile every Runnable implements `.stream()`, not all of them support multiple chunks. For example, if you call `.stream()` on a Prompt Template, it will just yield a single chunk with the same output as `.invoke()`.\\n\\nYou can iterate over the output using `for ... in` syntax. Try it with the `str_chain` you just declared:\\n\\n```routeros\\nfor chunk in str_chain.stream({\\\"topic\\\": \\\"beets\\\"}):\\n    print(chunk, end=\\\"|\\\")\\n\\n```\\n\\nAnd you get multiple strings as output (chunks are separated by a `|` character in the print function):\\n\\n```gherkin\\nHere|'s| a| b|eet| joke| for| you|:|\\n\\nWhy| did| the| b|eet| bl|ush|?| Because| it| saw| the| sal|ad| d|ressing|!|\\n\\n```\\n\\nChains composed like `str_chain` will start streaming as early as possible, which in this case is the Chat Model in the chain. \\n\\nSome Output Parsers (like the `StrOutputParser` used here) and many LCEL [Primitives](https://python.langchain.com/docs/expression%5Flanguage/primitives/) are able to process streamed chunks from previous steps as they are generated – essentially acting as transform streams or passthroughs – and do not disrupt streaming.\\n\\n## How to Guide Generation with Context\\n\\nLLMs are trained on large quantities of data and have some innate “knowledge” of various topics. Still, it’s common to pass the model private or more specific data as context when answering to glean useful information or insights. If you've heard the term \\\"RAG\\\", or \\\"retrieval-augmented generation\\\" before, this is the core principle behind it.\\n\\nOne of the simplest examples of this is telling the LLM what the current date is. Because LLMs are snapshots of when they are trained, they can’t natively determine the current time. Here’s an example:\\n\\n```isbl\\nchat_model = ChatAnthropic(model_name=)\\n\\nchat_model.invoke(\\\"What is the current date?\\\")\\n\\n```\\n\\nThe response:\\n\\n```gcode\\nAIMessage(content=\\\"Unfortunately, I don't actually have a concept of the current date and time. As an AI assistant without an integrated calendar, I don't have a dynamic sense of the present date. I can provide you with today's date based on when I was given my training data, but that may not reflect the actual current date you're asking about.\\\")\\n\\n```\\n\\nNow, let’s see what happens when you give the model the current date as context:\\n\\n```applescript\\nfrom datetime import date\\n\\nprompt = ChatPromptTemplate.from_messages([\\n    (\\\"system\\\", 'You know that the current date is \\\"{current_date}\\\".'),\\n    (\\\"human\\\", \\\"{question}\\\")\\n])\\n\\nchain = prompt | chat_model | StrOutputParser()\\n\\nchain.invoke({\\n    \\\"question\\\": \\\"What is the current date?\\\",\\n    \\\"current_date\\\": date.today()\\n})\\n\\n```\\n\\nAnd you can see, the model generates the current date:\\n\\nNice! Now, let's take it a step further. Language models are trained on vast quantities of data, but they don't know everything. Here's what happens if you directly ask the Chat Model a very specific question about a local restaurant:\\n\\n```less\\nchat_model.invoke(\\n    \\\"What was the Old Ship Saloon's total revenue in Q1 2023?\\\"\\n )\\n```\\n\\nThe model doesn't know the answer natively, or even know which of the many Old Ship Saloons in the world we may be talking about:\\n\\n```gcode\\nAIMessage(content=\\\"I'm sorry, I don't have any specific financial data about the Old Ship Saloon's revenue in Q1 2023. As an AI assistant without access to the saloon's internal records, I don't have information about their future projected revenues. I can only provide responses based on factual information that has been provided to me.\\\")\\n```\\n\\nHowever, if we can give the model more context, we can guide it to come up with a good answer:\\n\\n```awk\\nSOURCE = \\\"\\\"\\\"\\nOld Ship Saloon 2023 quarterly revenue numbers:\\nQ1: $174782.38\\nQ2: $467372.38\\nQ3: $474773.38\\nQ4: $389289.23\\n\\\"\\\"\\\"\\n\\nrag_prompt = ChatPromptTemplate.from_messages([\\n    (\\\"system\\\", 'You are a helpful assistant. Use the following context when responding:\\\\n\\\\n{context}.'),\\n    (\\\"human\\\", \\\"{question}\\\")\\n])\\n\\nrag_chain = rag_prompt | chat_model | StrOutputParser()\\n\\nrag_chain.invoke({\\n    \\\"question\\\": \\\"What was the Old Ship Saloon's total revenue in Q1 2023?\\\",\\n    \\\"context\\\": SOURCE\\n})\\n\\n```\\n\\nThis time, here's the result:\\n\\n```smalltalk\\n\\\"According to the provided context, the Old Ship Saloon's revenue in Q1 2023 was $174,782.38.\\\"\\n```\\n\\nThe result looks good! Note that augmenting generation with additional context is a very deep topic - in the real world, this would likely take the form of a longer financial document or portion of a document retrieved from some other data source. RAG is a powerful technique to answer questions over large quantities of information.\\n\\nYou can check out [LangChain’s retrieval-augmented generation (RAG) docs](https://python.langchain.com/docs/use%5Fcases/question%5Fanswering/) to learn more.\\n\\n## Debugging\\n\\nBecause LLMs are non-deterministic, it becomes more and more important to see the internals of what’s going on as your chains get more complex.\\n\\nLangChain has a `set_debug()` method that will return more granular logs of the chain internals: Let’s see it with the above example:\\n\\n```applescript\\nfrom langchain.globals import set_debug\\n\\nset_debug(True)\\n\\nfrom datetime import date\\n\\nprompt = ChatPromptTemplate.from_messages([\\n    (\\\"system\\\", 'You know that the current date is \\\"{current_date}\\\".'),\\n    (\\\"human\\\", \\\"{question}\\\")\\n])\\n\\nchain = prompt | chat_model | StrOutputParser()\\n\\nchain.invoke({\\n    \\\"question\\\": \\\"What is the current date?\\\",\\n    \\\"current_date\\\": date.today()\\n})\\n\\n```\\n\\nThere’s a lot more information!\\n\\n```sql\\n[chain/start] [1:chain:RunnableSequence] Entering Chain run with input:\\n[inputs]\\n[chain/start] [1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] Entering Prompt run with input:\\n[inputs]\\n[chain/end] [1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\\n[outputs]\\n[llm/start] [1:chain:RunnableSequence > 3:llm:ChatAnthropic] Entering LLM run with input:\\n{\\n  \\\"prompts\\\": [\\n    \\\"System: You know that the current date is \\\\\\\\\\\"2024-04-05\\\\\\\\\\\".\\\\\\\\nHuman: What is the current date?\\\"\\n  ]\\n}\\n...\\n[chain/end] [1:chain:RunnableSequence] [885ms] Exiting Chain run with output:\\n{\\n  \\\"output\\\": \\n}\\n\\n```\\n\\nYou can see [this guide](https://python.langchain.com/docs/guides/development/debugging/) for more information on debugging.\\n\\nYou can also use the `astream_events()` [method](https://python.langchain.com/docs/expression%5Flanguage/streaming/#using-stream-events) to return this data. This is useful if you want to use intermediate steps in your application logic. Note that this is an `async` method, and requires an extra `version` flag since it’s still in beta:\\n\\n```routeros\\n# Turn off debug mode for clarity\\nset_debug(False)\\n\\nstream = chain.astream_events({\\n    \\\"question\\\": \\\"What is the current date?\\\",\\n    \\\"current_date\\\": date.today()\\n}, version=\\\"v1\\\")\\n\\nasync for event in stream:\\n    print(event)\\n    print(\\\"-----\\\")\\n\\n```\\n\\n```lua\\n{'event': 'on_chain_start', 'run_id': '90785a49-987e-46bf-99ea-d3748d314759', 'name': 'RunnableSequence', 'tags': [], 'metadata': {}, 'data': {'input': {'question': 'What is the current date?', 'current_date': datetime.date(2024, 4, 5)}}}\\n-----\\n{'event': 'on_prompt_start', 'name': 'ChatPromptTemplate', 'run_id': '54b1f604-6b2a-48eb-8b4e-c57a66b4c5da', 'tags': ['seq:step:1'], 'metadata': {}, 'data': {'input': {'question': 'What is the current date?', 'current_date': datetime.date(2024, 4, 5)}}}\\n-----\\n{'event': 'on_prompt_end', 'name': 'ChatPromptTemplate', 'run_id': '54b1f604-6b2a-48eb-8b4e-c57a66b4c5da', 'tags': ['seq:step:1'], 'metadata': {}, 'data': {'input': {'question': 'What is the current date?', 'current_date': datetime.date(2024, 4, 5)}, 'output': ChatPromptValue(messages=[SystemMessage(content=), HumanMessage(content='What is the current date?')])}\\n-----\\n{'event': 'on_chat_model_start', 'name': 'ChatAnthropic', 'run_id': 'f5caa4c6-1b51-49dd-b304-e9b8e176623a', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'input': {'messages': [[SystemMessage(content=), HumanMessage(content='What is the current date?')]]}}}\\n-----\\n...\\n{'event': 'on_chain_end', 'name': 'RunnableSequence', 'run_id': '90785a49-987e-46bf-99ea-d3748d314759', 'tags': [], 'metadata': {}, 'data': {'output': }}\\n-----\\n```\\n\\nFinally, you can use an external service like [LangSmith](https://smith.langchain.com/) to add tracing. Here’s an example:\\n\\n```clean\\n# Sign up at <https://smith.langchain.com/>\\n# Set environment variables\\n\\n# import os\\n\\n# os.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\n# os.environ[\\\"LANGCHAIN_API_KEY\\\"] = \\\"YOUR_KEY\\\"\\n# os.environ[\\\"LANGCHAIN_PROJECT\\\"] = \\\"YOUR_PROJECT\\\"\\n\\nchain.invoke({\\n  \\\"question\\\": \\\"What is the current date?\\\",\\n  \\\"current_date\\\": date.today()\\n})\\n\\n```\\n\\nLangSmith will capture the internals at each step, giving you a result [like this](https://smith.langchain.com/public/628a15bb-45c8-4d39-987a-2896684a66c2/r).\\n\\nYou can also tweak prompts and rerun model calls in a playground. Due to the non-deterministic nature of LLMs, you can also tweak prompts and rerun model calls in a playground, as well as create datasets and test cases to evaluate changes to your app and catch regressions.\\n\\n## Thank you!\\n\\nYou’ve now learned the basics of:\\n\\n* LangChain’s [Chat Model](https://python.langchain.com/docs/modules/model%5Fio/chat/), [Prompt Template](https://python.langchain.com/docs/modules/model%5Fio/prompts/), and [Output Parser](https://python.langchain.com/docs/modules/model%5Fio/output%5Fparsers/) components\\n* How to chain components together with streaming.\\n* Using outside information to guide model generation.\\n* How to debug the internals of your chains.\\n\\nCheck out the following for some good resources to continue your generative AI journey:\\n\\n* [LangChain’s Python docs](https://python.langchain.com/)\\n* [LangChain’s YouTube channel](https://www.youtube.com/@LangChain)\\n\\nYou can also follow LangChain on X (formerly Twitter) [@LangChainAI](https://twitter.com/LangChainAI) for the latest news, or me [@Hacubu](https://x.com/hacubu/).\\n\\nHappy prompting!\\n\\n---\\n\\n---\\n\\n Learn to code for free. freeCodeCamp's open source curriculum has helped more than 40,000 people get jobs as developers. [Get started](https://www.freecodecamp.org/learn/) \",\"highlights\":[],\"labels\":[{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\",\"description\":\"\",\"createdAt\":\"2023-12-30T20:44:43.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"},{\"id\":\"e50d4514-3164-11ef-897b-8f6ac75b1612\",\"name\":\"langchain\",\"color\":\"#7BE4FF\",\"description\":null,\"createdAt\":\"2024-06-23T13:31:28.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:35:49,210 - INFO - Processing article: How to Use LangChain to Build With LLMs – A Beginner's Guide\n",
      "2024-07-04 23:35:55,713 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"introduction-open-interpreter-18e7765057c\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:35:55,934 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"1a1a23df-2977-455b-80f8-7958f2d8c11b\",\"title\":\"Introduction - Open Interpreter\",\"url\":\"https://docs.openinterpreter.com/getting-started/introduction\",\"author\":null,\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sJhVNVdK3qw95mAyrYEbDZDcIFesQNquDiDAbDCQOSu8/https://docs.openinterpreter.com/api/og?division=Documentation%C2%A7ion=Getting+Started&title=Introduction&description=A+new+way+to+use+computers&logoLight=https%3A%2F%2Fmintlify.s3-us-west-1.amazonaws.com%2Fopeninterpreter%2Fassets%2Flogo%2Fcircle.png&logoDark=https%3A%2F%2Fmintlify.s3-us-west-1.amazonaws.com%2Fopeninterpreter%2Fassets%2Flogo%2Fcircle-inverted.png&primaryColor=%23000000&lightColor=%23FFFFFF&darkColor=%23000000\",\"savedAt\":\"2024-04-01T00:42:33.000Z\",\"createdAt\":\"2024-03-25T20:54:53.000Z\",\"publishedAt\":null,\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://docs.openinterpreter.com/getting-started/introduction\",\"readingProgressPercent\":100,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"slug\":\"introduction-open-interpreter-18e7765057c\",\"isArchived\":false,\"description\":\"A new way to use computers\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":104,\"content\":\"##### Getting Started\\n\\n* [](https://docs.openinterpreter.com/getting-started/introduction)\\n* [](https://docs.openinterpreter.com/getting-started/setup)\\n\\n##### Guides\\n\\n* [](https://docs.openinterpreter.com/guides/basic-usage)\\n* [](https://docs.openinterpreter.com/guides/running-locally)\\n* [](https://docs.openinterpreter.com/guides/streaming-response)\\n* [](https://docs.openinterpreter.com/guides/advanced-terminal-usage)\\n* [](https://docs.openinterpreter.com/guides/multiple-instances)\\n* [](https://docs.openinterpreter.com/guides/os-mode)\\n\\n##### Settings\\n\\n* [](https://docs.openinterpreter.com/settings/all-settings)\\n\\n##### Language Models\\n\\n* [](https://docs.openinterpreter.com/language-models/introduction)\\n* [](https://docs.openinterpreter.com/language-models/custom-models)\\n* [](https://docs.openinterpreter.com/language-models/settings)\\n* [](https://docs.openinterpreter.com/language-models/usage)\\n\\n##### Code Execution\\n\\n* [](https://docs.openinterpreter.com/code-execution/settings)\\n* [](https://docs.openinterpreter.com/code-execution/usage)\\n* [](https://docs.openinterpreter.com/code-execution/computer-api)\\n* [](https://docs.openinterpreter.com/code-execution/custom-languages)\\n\\n##### Protocols\\n\\n* [](https://docs.openinterpreter.com/protocols/lmc-messages)\\n\\n##### Integrations\\n\\n* [](https://docs.openinterpreter.com/integrations/e2b)\\n* [](https://docs.openinterpreter.com/integrations/docker)\\n\\n##### Safety\\n\\n* [](https://docs.openinterpreter.com/safety/introduction)\\n* [](https://docs.openinterpreter.com/safety/isolation)\\n* [](https://docs.openinterpreter.com/safety/safe-mode)\\n* [](https://docs.openinterpreter.com/safety/best-practices)\\n\\n##### Telemetry\\n\\n* [](https://docs.openinterpreter.com/telemetry/telemetry)\\n\\nA new way to use computers\\n\\n![thumbnail](https://proxy-prod.omnivore-image-cache.app/0x0,s56PiQpxG2Hn1MSTgtZPsYrI5nmAOQhhcmCzJ6fu2C6Q/https://openinterpreter.com/assets/banner.jpg)\\n\\n**Open Interpreter** lets language models run code.\\n\\nYou can chat with Open Interpreter through a ChatGPT-like interface in your terminal by running `interpreter` after installing.\\n\\nThis provides a natural-language interface to your computer’s general-purpose capabilities:\\n\\n* Create and edit photos, videos, PDFs, etc.\\n* Control a Chrome browser to perform research\\n* Plot, clean, and analyze large datasets\\n* …etc.\\n  \\n---\\n\\n## Quick start\\n\\nIf you already use Python, you can install Open Interpreter via `pip`:\\n\\nInstall\\n\\n```sql\\npip install open-interpreter\\n\\n```\\n\\nWe’ve also developed [one-line installers](https://docs.openinterpreter.com/getting-started/setup) that install Python and set up Open Interpreter.\\n\\n* [Introduction](#introduction)\\n* [Quick start](#quick-start)\",\"highlights\":[],\"labels\":[{\"id\":\"8f4ce554-2916-11ef-8161-fbb712d47c7f\",\"name\":\"github\",\"color\":\"#3B7AD6\",\"description\":null,\"createdAt\":\"2024-06-12T23:50:34.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:35:55,937 - INFO - Processing article: Introduction - Open Interpreter\n",
      "2024-07-04 23:36:01,377 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"https-ollama-com-blog-python-javascript-libraries-18e970293fe\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:36:01,591 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"12efde9d-aec8-4604-99ea-b140a5cb9b16\",\"title\":\"Python & JavaScript Libraries · Ollama Blog\",\"url\":\"https://ollama.com/blog/python-javascript-libraries\",\"author\":null,\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sh_dHK_3wIH8JihLKmaH7nJq-niK_G2seQYIRSbzczUg/https://ollama.com/public/og-twitter.png\",\"savedAt\":\"2024-04-01T00:15:13.000Z\",\"createdAt\":\"2024-04-01T00:15:12.000Z\",\"publishedAt\":\"2024-01-23T00:00:00.000Z\",\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://ollama.com/blog/python-javascript-libraries\",\"readingProgressPercent\":28,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":6,\"slug\":\"https-ollama-com-blog-python-javascript-libraries-18e970293fe\",\"isArchived\":false,\"description\":\"The initial versions of the Ollama Python and JavaScript libraries are now available, making it easy to integrate your Python or JavaScript, or Typescript app with Ollama in a few lines of code. Both libraries include all the features of the Ollama REST API, are familiar in design, and compatible with new and previous versions of Ollama.\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":330,\"content\":\"## Python & JavaScript Libraries\\n\\n![Python & JavaScript Libraries](https://proxy-prod.omnivore-image-cache.app/0x0,scZmXQDMajypxiV4ZV0CJYOy6j2zMgoI4qxFn4MQomTc/https://ollama.com/public/blog/libraries.svg)\\n\\nThe initial versions of the Ollama Python and JavaScript libraries are now available:\\n\\n* [Ollama Python Library](https://github.com/ollama/ollama-python)\\n* [Ollama JavaScript Library](https://github.com/ollama/ollama-js)\\n\\nBoth libraries make it possible to integrate new and existing apps with Ollama in a few lines of code, and share the features and feel of the Ollama REST API.\\n\\n## Getting Started\\n\\nPython\\n\\n```cmake\\npip install ollama\\n\\n```\\n\\n```markdown\\nimport ollama\\nresponse = ollama.chat(model='llama2', messages=[\\n  {\\n    'role': 'user',\\n    'content': 'Why is the sky blue?',\\n  },\\n])\\nprint(response['message']['content'])\\n\\n```\\n\\nJavaScript\\n\\n```cmake\\nnpm install ollama\\n\\n```\\n\\n```javascript\\nimport ollama from 'ollama'\\n\\nconst response = await ollama.chat({\\n  model: 'llama2',\\n  messages: [{ role: 'user', content: 'Why is the sky blue?' }],\\n})\\nconsole.log(response.message.content)\\n\\n```\\n\\n## Use cases\\n\\nBoth libraries support Ollama’s full set of features. Here are some examples in Python:\\n\\n#### Streaming\\n\\n```routeros\\nfor chunk in chat('mistral', messages=messages, stream=True):\\n  print(chunk['message']['content'], end='', flush=True)\\n\\n```\\n\\n#### Multi-modal\\n\\n```vim\\nwith open('image.png', 'rb') as file:\\n  response = ollama.chat(\\n    model='llava',\\n    messages=[\\n      {\\n        'role': 'user',\\n        'content': 'What is strange about this image?',\\n        'images': [file.read()],\\n      },\\n    ],\\n  )\\nprint(response['message']['content'])\\n\\n```\\n\\n#### Text Completion\\n\\n```routeros\\nresult = ollama.generate(\\n  model='stable-code',\\n  prompt='// A c function to reverse a string\\\\n',\\n)\\nprint(result['response'])\\n\\n```\\n\\n#### Creating custom models\\n\\n```awk\\nmodelfile='''\\nFROM llama2\\nSYSTEM You are mario from super mario bros.\\n'''\\n\\nollama.create(model='example', modelfile=modelfile)\\n\\n```\\n\\n#### Custom client\\n\\n```reasonml\\nollama = Client(host='my.ollama.host')\\n\\n```\\n\\nMore examples are available in the GitHub repositories for the [Python](https://github.com/ollama/ollama-python/tree/main/examples) and [JavaScript](https://github.com/ollama/ollama-js/tree/main/examples) libraries.\\n\\n## New GitHub handle\\n\\n![GitHub handle](https://proxy-prod.omnivore-image-cache.app/0x0,sJulaR3fp3Wo8FRtN4ZHrw4YmhJtSMdCWgNeF5uYRHTY/https://ollama.com/public/blog/github-handle.svg)\\n\\nThese libraries, and the main Ollama repository now live in a new GitHub organization: **[ollama](https://github.com/ollama)**! Thank you to all the amazing community members who maintain libraries to interact with Ollama via Dart, Swift, C#, Java, PHP, Rust and more – a full list is available [here](https://github.com/jmorganca/ollama?tab=readme-ov-file#libraries) – please don’t hesitate to make a pull request to add a library you’ve built or enjoy using.\\n\\nSpecial thank you to [Saul](https://github.com/saul-jb), the original author of `ollama-js`, and everyone else who has worked on community libraries to make Ollama more accessible from different programming languages.\",\"highlights\":[],\"labels\":[{\"id\":\"4d188510-3160-11ef-95ac-476b5d5c1917\",\"name\":\"ollama\",\"color\":\"#CC5433\",\"description\":null,\"createdAt\":\"2024-06-23T12:58:35.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:36:01,595 - INFO - Processing article: Python & JavaScript Libraries · Ollama Blog\n",
      "2024-07-04 23:36:08,212 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"data-science-projects-aman-kharwal-18d9509d85d\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:36:09,457 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"d56091fb-d260-4a7b-8eee-09402b5bc07d\",\"title\":\"Data Science Projects | Aman Kharwal\",\"url\":\"https://thecleverprogrammer.com/2022/03/09/data-science-projects\",\"author\":\"Aman Kharwal\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sC2g9xmhEhGKgP8hLCKLbzbo9GjO-owKdy2l1nrfU52M/https://i0.wp.com/thecleverprogrammer.com/wp-content/uploads/2024/02/185-Data-Science-Projects-using-Python.png?fit=2240%2C1260&ssl=1\",\"savedAt\":\"2024-02-10T22:01:07.000Z\",\"createdAt\":\"2024-02-10T22:01:07.000Z\",\"publishedAt\":\"2022-03-09T07:53:07.000Z\",\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://thecleverprogrammer.com/2022/03/09/data-science-projects\",\"readingProgressPercent\":0,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":0,\"slug\":\"data-science-projects-aman-kharwal-18d9509d85d\",\"isArchived\":false,\"description\":\"In this article, I will take you through a list of data science projects with Python that will help you learn and implement Data Science.\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":977,\"content\":\"As a beginner in data science, it’s hard to understand all the concepts you learn without implementing them on a dataset. Working on data science projects and **[case studies](https://statso.io/case-studies/)** will help you improve your data science skills. If you’re struggling to come up with data science project ideas and how to start and end a data science project, this article is for you. In this article, I will take you through a list of data science projects with Python that will help you learn and implement all the concepts of Data Science by using the Python programming language.\\n\\nBelow is a list of Data Science projects with Python that you can try as a beginner. Each of the projects below is solved and explained using Python:\\n\\n1. **[Music Recommendation System using Spotify API](https://thecleverprogrammer.com/2023/07/31/music-recommendation-system-using-python/)**\\n2. **[Delhi Metro Network Analysis](https://thecleverprogrammer.com/2024/01/29/delhi-metro-network-analysis-using-python/)**\\n3. **[Quantitative Analysis of Stock Market](https://thecleverprogrammer.com/2024/01/15/quantitative-analysis-of-stock-market-using-python/)**\\n4. **[End to End Predictive Model](https://thecleverprogrammer.com/2023/12/18/build-an-end-to-end-machine-learning-model/)**\\n5. **[Build An Analytics Dashboard](https://thecleverprogrammer.com/2024/01/01/analytics-dashboard-using-python/)**\\n6. **[Text Generation Model](https://thecleverprogrammer.com/2024/01/22/text-generation-model-using-python/)**\\n7. **[Car Insurance Modelling](https://thecleverprogrammer.com/2024/01/08/car-insurance-modelling-using-python/)**\\n8. **[App Reviews Sentiment Analysis](https://thecleverprogrammer.com/2023/12/04/app-reviews-sentiment-analysis-using-python/)**\\n9. **[Cohort Analysis](https://thecleverprogrammer.com/2023/11/27/cohort-analysis-using-python/)**\\n10. **[Real Estate Price Prediction](https://thecleverprogrammer.com/2023/12/11/real-estate-price-prediction-using-python/)**\\n11. **[Ads CTR Forecasting](https://thecleverprogrammer.com/2023/10/23/ads-ctr-forecasting-using-python/)**\\n12. **[Stock Market Comparison Analysis](https://thecleverprogrammer.com/2023/10/09/stock-market-comparison-analysis-using-python/)**\\n13. **[Netflix Subscriptions Forecasting](https://thecleverprogrammer.com/2023/08/07/netflix-subscriptions-forecasting-using-python/)**\\n14. **[Search Queries Anomaly Detection](https://thecleverprogrammer.com/2023/11/20/search-queries-anomaly-detection-using-python/)**\\n15. **[Text Analysis](https://thecleverprogrammer.com/2023/10/02/text-analysis-using-python/)**\\n16. **[Consumer Behaviour Analysis](https://thecleverprogrammer.com/2023/11/06/customer-behaviour-analysis-using-python/)**\\n17. **[Air Quality Index Analysis](https://thecleverprogrammer.com/2023/09/18/air-quality-index-analysis-using-python/)**\\n18. **[Market Basket Analysis](https://thecleverprogrammer.com/2023/10/16/market-basket-analysis-using-python/)**\\n19. **[Book Recommendation System](https://thecleverprogrammer.com/2023/10/30/book-recommendation-system-with-python/)**\\n20. **[Fitness Watch Data Analysis](https://thecleverprogrammer.com/2023/09/04/fitness-watch-data-analysis-using-python/)**\\n21. **[Demand Forecasting & Inventory Optimization](https://thecleverprogrammer.com/2023/08/28/demand-forecasting-and-inventory-optimization-using-python/)**\\n22. **[Customer Acquisition Cost Analysis](https://thecleverprogrammer.com/2023/09/25/customer-acquisition-cost-analysis-using-python/)**\\n23. **[Dating Recommendations](https://thecleverprogrammer.com/2023/09/11/dating-recommendations-using-python/)**\\n24. **[Anomaly Detection in Transactions](https://thecleverprogrammer.com/2023/08/21/anomaly-detection-in-transactions-using-python/)**\\n25. **[Credit Scoring & Segmentation](https://thecleverprogrammer.com/2023/07/03/credit-scoring-and-segmentation-using-python/)**\\n26. **[Next Word Prediction Model](https://thecleverprogrammer.com/2023/07/17/next-word-prediction-model-using-python/)**\\n27. **[Dynamic Pricing Strategy](https://thecleverprogrammer.com/2023/06/26/dynamic-pricing-strategy-using-python/)**\\n28. **[Web Data ETL Pipeline](https://thecleverprogrammer.com/2023/08/14/web-data-etl-pipeline-using-python/)**\\n29. **[Demand Forecasting & Inventory Optimization](https://thecleverprogrammer.com/2023/08/28/demand-forecasting-and-inventory-optimization-using-python/)**\\n30. **[A/B Testing of Themes](https://thecleverprogrammer.com/2023/07/24/a-b-testing-of-themes-using-python/)**\\n31. **[Data Preprocessing Pipeline](https://thecleverprogrammer.com/2023/06/19/data-preprocessing-pipeline-using-python/)**\\n32. **[User Engagement Analysis](https://thecleverprogrammer.com/2023/07/10/user-engagement-analysis-using-python/)**\\n33. **[RFM Analysis](https://thecleverprogrammer.com/2023/06/12/rfm-analysis-using-python/)**\\n34. **[Stock Market Performance Analysis](https://thecleverprogrammer.com/2023/05/08/stock-market-performance-analysis-using-python/)**\\n35. **[Hybrid Recommendation System](https://thecleverprogrammer.com/2023/06/05/hybrid-recommendation-system-using-python/)**\\n36. **[B2B Courier Charges Accuracy Analysis](https://thecleverprogrammer.com/2023/05/22/b2b-courier-charges-accuracy-analysis-using-python/)**\\n37. **[Currency Exchange Rate Forecasting](https://thecleverprogrammer.com/2023/05/29/currency-exchange-rate-forecasting-using-python/)**\\n38. [**Instagram Reach Analysis & Forecasting**](https://thecleverprogrammer.com/2023/04/24/instagram-reach-forecasting-using-python/)\\n39. [**Retail Price Optimization**](https://thecleverprogrammer.com/2023/04/17/retail-price-optimization-using-python/)\\n40. **[Loan Approval Prediction](https://thecleverprogrammer.com/2023/05/15/loan-approval-prediction-using-python/)**\\n41. [**Supply Chain Analysis**](https://thecleverprogrammer.com/2023/04/03/supply-chain-analysis-using-python/)\\n42. [**End to End Chatbot**](https://thecleverprogrammer.com/2023/03/27/end-to-end-chatbot-using-python/)\\n43. [**Store Sales & Profit Analysis**](https://thecleverprogrammer.com/2023/04/10/store-sales-and-profit-analysis-using-python/)\\n44. [**Customer Lifetime Value Analysis**](https://thecleverprogrammer.com/2023/05/01/customer-lifetime-value-analysis-using-python/)\\n45. **[Exploratory Data Analysis](https://thecleverprogrammer.com/2023/05/30/exploratory-data-analysis-using-python/)**\\n46. **[Accelerometer Data Analysis](https://thecleverprogrammer.com/2023/03/13/accelerometer-data-analysis-using-python/)**\\n47. **[Recession Analysis](https://thecleverprogrammer.com/2023/02/20/recession-analysis-using-python/)**\\n48. **[Demand & Supply Analysis](https://thecleverprogrammer.com/2023/02/27/demand-and-supply-analysis-using-python/)**\\n49. **[Data ETL Pipeline](https://thecleverprogrammer.com/2023/03/20/data-etl-pipeline-using-python/)**\\n50. **[Algorithmic Trading](https://thecleverprogrammer.com/2023/01/23/algorithmic-trading-using-python/)**\\n51. **[Food Delivery Time Prediction](https://thecleverprogrammer.com/2023/01/02/food-delivery-time-prediction-using-python/)**\\n52. **[A/B Testing](https://thecleverprogrammer.com/2022/11/14/a-b-testing-using-python/)**\\n53. **[Credit Score Classification](https://thecleverprogrammer.com/2022/12/05/credit-score-classification-with-machine-learning/)**\\n54. **[App User Segmentation](https://thecleverprogrammer.com/2023/01/30/app-user-segmentation-using-python/)**\\n55. **[Text Emotions Classification](https://thecleverprogrammer.com/2023/02/06/text-emotions-classification-using-python/)**\\n56. **[T20 World Cup 2022 Analysis](https://thecleverprogrammer.com/2022/11/21/t20-world-cup-2022-analysis-using-python/)**\\n57. [**Weather Forecasting**](https://thecleverprogrammer.com/2022/10/17/weather-forecasting-using-python/)\\n58. **[Topic Modelling](https://thecleverprogrammer.com/2023/02/13/topic-modelling-using-python/)**\\n59. **[Ads Click Through Rate Prediction](https://thecleverprogrammer.com/2023/01/16/ads-click-through-rate-prediction-using-python/)**\\n60. **[Survey Analysis](https://thecleverprogrammer.com/2023/01/09/career-aspirations-survey-analysis-using-python/)**\\n61. **[Fashion Recommendation System](https://thecleverprogrammer.com/2022/12/19/fashion-recommendation-system-using-python/)**\\n62. **[Twitter Timeline in the Stock Market Analysis](https://thecleverprogrammer.com/2022/11/07/twitter-stock-market-analysis-using-python/)**\\n63. [**Screen Time Analysis**](https://thecleverprogrammer.com/2022/10/24/screen-time-analysis-using-python/)\\n64. [**Stock Market Analysis**](https://thecleverprogrammer.com/2022/07/12/stock-market-analysis-using-python/)\\n65. **[Social Progress Index Analysis](https://thecleverprogrammer.com/2022/12/26/social-progress-index-analysis-using-python/)**\\n66. **[Job Recommendation System](https://thecleverprogrammer.com/2022/12/12/job-recommendation-system-using-python/)**\\n67. **[Consumer Complaint Classification](https://thecleverprogrammer.com/2022/11/28/consumer-complaint-classification-with-machine-learning/)**\\n68. **[Business Forecasting](https://thecleverprogrammer.com/2022/09/05/business-forecasting-using-python/)**\\n69. **[News Recommendation System](https://thecleverprogrammer.com/2022/09/12/news-recommendation-system-using-python/)**\\n70. **[iPhone Sales Analysis](https://thecleverprogrammer.com/2022/09/19/iphone-sales-analysis-using-python/)**\\n71. [**Salary Prediction**](https://thecleverprogrammer.com/2022/10/31/salary-prediction-with-machine-learning/)\\n72. [**Flipkart Sale Analysis**](https://thecleverprogrammer.com/2022/10/10/flipkart-sale-analysis-using-python/)\\n73. [**Credit Card Clustering**](https://thecleverprogrammer.com/2022/10/03/credit-card-clustering-with-machine-learning/)\\n74. **[Diamond Price Analysis and prediction](https://thecleverprogrammer.com/2022/09/26/diamond-price-analysis-using-python/)**\\n75. **[Step by Step NLP with Python](https://thecleverprogrammer.com/2022/08/29/process-of-nlp-using-python/)**\\n76. [**Netflix Recommendation System**](https://thecleverprogrammer.com/2022/07/05/netflix-recommendation-system-using-python/)\\n77. **[House Rent Prediction](https://thecleverprogrammer.com/2022/08/15/house-rent-prediction-with-machine-learning/)**\\n78. **[Password Strength Checker with Machine Learning](https://thecleverprogrammer.com/2022/08/22/password-strength-checker-with-machine-learning/)**\\n79. **[Classification Model Evaluation](https://thecleverprogrammer.com/2022/08/09/classification-model-evaluation-in-machine-learning/)**\\n80. [**Spam Comments Detection**](https://thecleverprogrammer.com/2022/08/02/spam-comments-detection-with-machine-learning/)\\n81. [**Website Traffic Forecasting**](https://thecleverprogrammer.com/2022/06/28/website-traffic-forecasting-using-python/)\\n82. **[Complete Process of NLP with Python](https://thecleverprogrammer.com/2022/08/29/process-of-nlp-using-python/)**\\n83. [**Restaurant Recommendation System**](https://thecleverprogrammer.com/2022/07/26/restaurant-recommendation-system-using-python/)\\n84. [**Online Food Order Prediction**](https://thecleverprogrammer.com/2022/06/07/online-food-order-prediction-with-machine-learning/)\\n85. [**Virat Kohli Performance Analysis**](https://thecleverprogrammer.com/2022/05/10/virat-kohli-performance-analysis-using-python/)\\n86. [**Book Recommendation System**](https://thecleverprogrammer.com/2022/07/19/book-recommendation-system-using-python/)\\n87. [**Time Series Forecasting with ARIMA**](https://thecleverprogrammer.com/2022/06/21/time-series-forecasting-with-arima/)\\n88. [**Smartwatch Data Analysis**](https://thecleverprogrammer.com/2022/05/31/smartwatch-data-analysis-using-python/)\\n89. [**IPL 2022 Analysis using Python**](https://thecleverprogrammer.com/2022/05/03/ipl-2022-analysis-using-python/)\\n90. [**Instagram Recommendation System**](https://thecleverprogrammer.com/2022/06/14/instagram-recommendation-system-with-machine-learning/)\\n91. [**MNIST Digits Classification**](https://thecleverprogrammer.com/2022/05/17/mnist-digits-classification-with-machine-learning/)\\n92. [**Covid-19 Spread and Impacts Analysis**](https://thecleverprogrammer.com/2022/04/19/covid-19-impacts-analysis-using-python/)\\n93. [**Instagram Reach Analysis and Prediction**](https://thecleverprogrammer.com/2022/03/22/instagram-reach-analysis-using-python/)\\n94. [**Tinder Reviews Sentiment Analysis**](https://thecleverprogrammer.com/2022/05/24/tinder-reviews-sentiment-analysis-using-python/)\\n95. [**Student Marks Prediction**](https://thecleverprogrammer.com/2022/04/26/student-marks-prediction-with-machine-learning/)\\n96. [**Online Payments Fraud Detection**](https://thecleverprogrammer.com/2022/02/22/online-payments-fraud-detection-with-machine-learning/)\\n97. [**Waiter Tips Analysis & Prediction**](https://thecleverprogrammer.com/2022/02/01/waiter-tips-prediction-with-machine-learning/)\\n98. [**Tiktok Reviews Sentiment Analysis**](https://thecleverprogrammer.com/2022/04/12/tiktok-reviews-sentiment-analysis-using-python/)\\n99. **[Clustering Music Genres with Machine Learning](https://thecleverprogrammer.com/2022/04/05/clustering-music-genres-with-machine-learning/)**\\n100. [**Ukraine vs Russia Twitter Sentiment Analysis**](https://thecleverprogrammer.com/2022/03/15/ukraine-russia-war-twitter-sentiment-analysis-using-python/)\\n101. [**Stock Price Prediction**](https://thecleverprogrammer.com/2020/11/14/stock-price-prediction-using-machine-learning/)\\n102. [**Cryptocurrency Price Prediction for the next 30 days**](https://thecleverprogrammer.com/2021/12/27/cryptocurrency-price-prediction-with-machine-learning/)\\n103. [**Breast Cancer Survival Prediction**](https://thecleverprogrammer.com/2022/03/08/breast-cancer-survival-prediction-with-machine-learning/)\\n104. [**Covid-19 Deaths Prediction**](https://thecleverprogrammer.com/2022/03/29/covid-19-deaths-prediction-with-machine-learning/)\\n105. [**Flipkart Reviews Sentiment Analysis**](https://thecleverprogrammer.com/2022/02/15/flipkart-reviews-sentiment-analysis-using-python/)\\n106. [**Stock Price Prediction with LSTM Neural Network**](https://thecleverprogrammer.com/2022/01/03/stock-price-prediction-with-lstm/)\\n107. [**Future Sales Prediction**](https://thecleverprogrammer.com/2022/03/01/future-sales-prediction-with-machine-learning/)\\n108. [**Article Recommendation System**](https://thecleverprogrammer.com/2021/11/10/article-recommendation-system-with-machine-learning/)\\n109. [**Netflix Stock Price Prediction**](https://thecleverprogrammer.com/2022/02/08/netflix-stock-price-prediction-with-machine-learning/)\\n110. [**Time Series Analysis**](https://thecleverprogrammer.com/2022/01/17/time-series-analysis-using-python/)\\n111. [**Classification with Neural Networks**](https://thecleverprogrammer.com/2022/01/10/classification-with-neural-networks-using-python/)\\n112. [**Stress Detection**](https://thecleverprogrammer.com/2021/12/20/stress-detection-with-machine-learning/)\\n113. [**AlexNet Neural Network Architecture**](https://thecleverprogrammer.com/2021/12/13/alexnet-architecture-using-python/)\\n114. [**Visualizing a Machine Learning Algorithm**](https://thecleverprogrammer.com/2021/12/29/visualize-a-machine-learning-algorithm-using-python/)\\n115. [**Training and Giving Inputs to a Machine Learning Model**](https://thecleverprogrammer.com/2021/11/29/how-to-give-inputs-to-a-machine-learning-model/)\\n116. [**Product Demand Prediction**](https://thecleverprogrammer.com/2021/11/22/product-demand-prediction-with-machine-learning/)\\n117. [**Electricity Price Prediction**](https://thecleverprogrammer.com/2021/11/15/electricity-price-prediction-with-machine-learning/)\\n118. [**Language Detection**](https://thecleverprogrammer.com/2021/10/30/language-detection-with-machine-learning/)\\n119. [**Adding Labels to a Dataset for Sentiment Analysis**](https://thecleverprogrammer.com/2021/11/24/add-labels-to-a-dataset-for-sentiment-analysis/)\\n120. [**Pfizer Vaccine Sentiment Analysis**](https://thecleverprogrammer.com/2021/10/12/pfizer-vaccine-sentiment-analysis-using-python/)\\n121. [**News Classification**](https://thecleverprogrammer.com/2021/10/07/news-classification-with-machine-learning/)\\n122. [**Omicron Variant Sentiment Analysis**](https://thecleverprogrammer.com/2021/12/06/omicron-sentiment-analysis-using-python/)\\n123. [**Iris Flower Classification**](https://thecleverprogrammer.com/2021/10/17/iris-flower-classification-with-machine-learning/)\\n124. [**Water Quality Analysis**](https://thecleverprogrammer.com/2021/08/19/water-quality-analysis/)\\n125. [**Twitter Sentiment Analysis**](https://thecleverprogrammer.com/2021/09/13/twitter-sentiment-analysis-using-python/)\\n126. [**Squid Game Sentiment Analysis**](https://thecleverprogrammer.com/2021/11/03/squid-game-sentiment-analysis-using-python/)\\n127. [**Comparison of Classification Algorithms**](https://thecleverprogrammer.com/2021/10/02/comparison-of-classification-algorithms-in-machine-learning/)\\n128. [**Tata Motors Stock Price Prediction**](https://thecleverprogrammer.com/2021/10/22/tata-motors-stock-price-prediction-with-machine-learning/)\\n129. [**Health Insurance Premium Prediction**](https://thecleverprogrammer.com/2021/10/26/health-insurance-premium-prediction-with-machine-learning/)\\n130. [**Movie Rating Analysis for Beginners**](https://thecleverprogrammer.com/2021/09/22/movie-rating-analysis-using-python/)\\n131. [**Number of Orders Prediction**](https://thecleverprogrammer.com/2021/09/27/number-of-orders-prediction-with-machine-learning/)\\n132. [**Apple Stock Price Prediction**](https://thecleverprogrammer.com/2021/09/08/apple-stock-price-prediction-with-machine-learning/)\\n133. [**Insurance Prediction**](https://thecleverprogrammer.com/2021/09/03/insurance-prediction-with-machine-learning/)\\n134. [**Worldwide Billionaires Analysis**](https://thecleverprogrammer.com/2021/06/24/billionaires-analysis-with-python/)\\n135. [**Unemployment Analysis**](https://thecleverprogrammer.com/2021/07/12/unemployment-analysis-with-python/)\\n136. [**Car Price Prediction Model**](https://thecleverprogrammer.com/2021/08/04/car-price-prediction-with-machine-learning/)\\n137. [**Spam Detection**](https://thecleverprogrammer.com/2021/06/27/spam-detection-with-machine-learning/)\\n138. [**Count Objects in Image**](https://thecleverprogrammer.com/2021/05/11/count-objects-in-image-using-python/)\\n139. [**WhatsApp Chats Sentiment Analysis**](https://thecleverprogrammer.com/2021/06/06/whatsapp-chat-sentiment-analysis-using-python/)\\n140. [**WhatsApp Chats Analysis**](https://thecleverprogrammer.com/2021/04/09/whatsapp-chat-analysis-with-python/)\\n141. [**Microsoft Stock Price Prediction**](https://thecleverprogrammer.com/2021/06/21/microsoft-stock-price-prediction-with-machine-learning/)\\n142. [**Covid-19 Vaccine Analysis**](https://thecleverprogrammer.com/2021/04/13/covid-19-vaccines-analysis-with-python/)\\n143. [**Video Game Sales Prediction Model**](https://thecleverprogrammer.com/2021/05/28/video-game-sales-prediction-model-with-python/)\\n144. [**Student Grades Prediction Model**](https://thecleverprogrammer.com/2021/04/16/student-grades-prediction-with-machine-learning/)\\n145. [**Saving a Machine Learning Model**](https://thecleverprogrammer.com/2021/05/13/how-to-save-a-machine-learning-model/)\\n146. [**Uber Trips Analysis**](https://thecleverprogrammer.com/2021/04/21/uber-trips-analysis-using-python/)\\n147. [**Google Search Analysis**](https://thecleverprogrammer.com/2021/04/27/google-search-analysis-with-python/)\\n148. [**Tesla Stock Price Prediction Model**](https://thecleverprogrammer.com/2021/03/27/tesla-stock-price-prediction-with-machine-learning/)\\n149. [**Financial Budget Analysis**](https://thecleverprogrammer.com/2021/04/05/financial-budget-analysis-with-python/)\\n150. [**Click-Through Rate Prediction Model**](https://thecleverprogrammer.com/2021/01/24/click-through-rate-prediction-with-machine-learning/)\\n151. [**Interactive Language Translator**](https://thecleverprogrammer.com/2021/04/02/language-translator-using-python/)\\n152. [**Language Detection**](https://thecleverprogrammer.com/2021/04/04/language-detection-with-python/)\\n153. [**Create a Chatbot with Python**](https://thecleverprogrammer.com/2021/03/25/chatbot-using-python/)\\n154. [**Best Streaming Service Analysis**](https://thecleverprogrammer.com/2021/01/21/best-streaming-service-analysis-with-python/)\\n155. [**Data Science Project on President Heights**](https://thecleverprogrammer.com/2020/05/08/data-science-project-on-president-heights/)\\n156. [**Data Science Project on Birth Rate Analysis**](https://thecleverprogrammer.com/2020/05/08/data-science-project-on-birth-rate-analysis/)\\n157. [**Data Science Project on Time Series**](https://thecleverprogrammer.com/2020/05/08/data-science-project-on-time-series/)\\n158. [**Data Science Project on Area and Population**](https://thecleverprogrammer.com/2020/05/09/data-science-project-on-area-and-population/)\\n159. [**A Complete Machine Learning Project Walkthrough**](https://thecleverprogrammer.com/2020/12/18/machine-learning-project-walkthrough-with-python/)\\n160. [**Text Summarization**](https://thecleverprogrammer.com/2020/12/31/text-summarization-with-python/)\\n161. [**Keyword Extraction**](https://thecleverprogrammer.com/2021/02/07/extract-keywords-using-python/)\\n162. [**Sarcasm Detection**](https://thecleverprogrammer.com/2021/08/24/sarcasm-detection-with-machine-learning/)\\n163. [**Social Media Followers Prediction**](https://thecleverprogrammer.com/2021/08/09/social-media-followers-prediction-with-machine-learning/)\\n164. [**Amazon Product Reviews Sentiment Analysis**](https://thecleverprogrammer.com/2021/07/20/amazon-product-reviews-sentiment-analysis-with-python/)\\n165. [**Hate Speech Detection**](https://thecleverprogrammer.com/2021/07/25/hate-speech-detection-with-machine-learning/)\\n166. [**End-to-end Hate Speech Detection System**](https://thecleverprogrammer.com/2021/07/30/end-to-end-hate-speech-detection-with-python/)\\n167. [**End-to-end Fake News Detection System**](https://thecleverprogrammer.com/2021/07/09/end-to-end-fake-news-detection-with-python/)\\n168. [**End-to-end Spam Detection System**](https://thecleverprogrammer.com/2021/07/06/end-to-end-spam-detection-with-python/)\\n169. [**Hotel Reviews Sentiment Analysis**](https://thecleverprogrammer.com/2021/07/03/hotel-reviews-sentiment-analysis-with-python/)\\n170. [**Real-time Gender Detection System**](https://thecleverprogrammer.com/2021/06/18/real-time-gender-detection-using-python/)\\n171. [**Dogecoin Price Prediction**](https://thecleverprogrammer.com/2021/05/25/dogecoin-price-prediction-with-machine-learning/)\\n172. [**Google Play Store Sentiment Analysis**](https://thecleverprogrammer.com/2021/05/31/google-play-store-sentiment-analysis-using-python/)\\n173. [**Amazon Alexa Reviews Sentiment Analysis**](https://thecleverprogrammer.com/2021/06/12/amazon-alexa-reviews-sentiment-analysis-using-python/)\\n174. [**Social Media Ads Classification**](https://thecleverprogrammer.com/2021/06/15/social-media-ads-classification-with-machine-learning/)\\n175. [**Fake News Detection**](https://thecleverprogrammer.com/2021/06/30/fake-news-detection-with-machine-learning/)\\n176. [**End-to-End Machine Learning Model**](https://thecleverprogrammer.com/2021/06/03/end-to-end-machine-learning-model/)\\n177. [**Gender Detection**](https://thecleverprogrammer.com/2021/05/15/gender-detection-with-machine-learning/)\\n178. [**Sales Prediction**](https://thecleverprogrammer.com/2021/05/19/sales-prediction-with-machine-learning/)\\n179. [**Currency Exchange Rate Prediction**](https://thecleverprogrammer.com/2021/05/22/currency-exchange-rate-prediction-with-machine-learning/)\\n180. [**End-to-end Machine Learning Project**](https://thecleverprogrammer.com/2021/03/21/end-to-end-machine-learning-project/)\\n181. [**Profit Prediction Model**](https://thecleverprogrammer.com/2021/04/29/profit-prediction-with-machine-learning/)\\n182. [**Automatic Time Series Forecasting**](https://thecleverprogrammer.com/2021/04/19/autots-in-python-tutorial/)\\n183. [**Ted-Talks Recommendation System**](https://thecleverprogrammer.com/2021/04/01/ted-talks-recommendation-system-with-machine-learning/)\\n184. [**Real-time Sentiment Analysis**](https://thecleverprogrammer.com/2021/03/09/real-time-sentiment-analysis-using-python/)\\n185. [**Amazon Recommendation System**](https://thecleverprogrammer.com/2021/03/23/amazon-recommendation-system-using-python/)\\n186. [**Mobile Price Classification**](https://thecleverprogrammer.com/2021/03/05/mobile-price-classification-with-machine-learning/)\\n187. [**Future Sales Prediction**](https://thecleverprogrammer.com/2022/03/01/future-sales-prediction-with-machine-learning/)\\n\\nThe above list of data science projects contains projects based on classification (Binary and Multiclass), regression, sentiment analysis, text analysis, recommendation systems, and many more. I will update this list of data science projects with more projects regularly.\\n\\n### Summary\\n\\nWorking on data science projects and case studies will help you improve your data science skills. The above list of Data Science projects will be updated daily with more projects. I hope you liked this article on data science projects with Python. Feel free to ask valuable questions in the comments section below.\\n\\n#####  Aman Kharwal \\n\\nI'm a writer and data scientist on a mission to educate others about the incredible power of data📈.\\n\\n[Articles: 1566](https://thecleverprogrammer.com/author/amankharwal/) \\n\\n[ ![Breast Cancer Survival Prediction with Machine Learning](https://proxy-prod.omnivore-image-cache.app/300x169,szFRjnyArTd1LbstGspfBKAGlxU8vcEuTCHezjNfAqEg/https://i0.wp.com/thecleverprogrammer.com/wp-content/uploads/2022/03/Breast-Cancer-Survival-Prediction-with-Machine-Learning.png?fit=300%2C169&ssl=1)  Previous Post  Breast Cancer Survival Prediction with Machine Learning ](https://thecleverprogrammer.com/2022/03/08/breast-cancer-survival-prediction-with-machine-learning/) [  Next Post  Scrape Table from a Website using Python ![Scrape Table from a Website using Python](https://proxy-prod.omnivore-image-cache.app/300x169,sj_we4iAgKp_S2U6PEXKMoAnD_4aRR14fBdd-7QqAhj0/https://i0.wp.com/thecleverprogrammer.com/wp-content/uploads/2022/03/Learn-How-to-Scrape-Tables-from-Websites-using-Python.png?fit=300%2C169&ssl=1) ](https://thecleverprogrammer.com/2022/03/10/scrape-table-from-a-website-using-python/) \",\"highlights\":[],\"labels\":[{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"},{\"id\":\"fcf97d42-3163-11ef-be29-f7e1d42d0b74\",\"name\":\"data-science\",\"color\":\"#7CFF7B\",\"description\":null,\"createdAt\":\"2024-06-23T13:24:58.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:36:09,461 - INFO - Processing article: Data Science Projects | Aman Kharwal\n",
      "2024-07-04 23:36:15,484 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"an-introduction-to-building-autonomous-ai-agents-geeky-gadgets-18d3e8fd387\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:36:15,836 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"415a74b1-a135-4178-bb5f-c20d0ba5a6dc\",\"title\":\"An introduction to building autonomous AI agents - Geeky Gadgets\",\"url\":\"https://www.geeky-gadgets.com/building-autonomous-ai-agents/\",\"author\":\"Julian Horsey\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,s7Ulpb4bZxOJaErnZY6kbQfrrNrVY66IqLsw8n7qleNk/https://www.geeky-gadgets.com/wp-content/uploads/2023/09/building-autonomous-AI-agents.jpg\",\"savedAt\":\"2024-01-25T03:00:29.000Z\",\"createdAt\":\"2024-01-25T03:00:28.000Z\",\"publishedAt\":\"2023-09-08T07:55:11.000Z\",\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://www.geeky-gadgets.com/building-autonomous-ai-agents/\",\"readingProgressPercent\":100,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":90,\"slug\":\"an-introduction-to-building-autonomous-ai-agents-geeky-gadgets-18d3e8fd387\",\"isArchived\":false,\"description\":\"If you would like to learn the basics of what an AI agent is and how to build autonomous AI agents for business, clients or personal workflows\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":1194,\"content\":\"* [ Skip to main content](#genesis-content)\\n* [ Skip to secondary menu](#genesis-nav-secondary)\\n* [ Skip to primary sidebar](#genesis-sidebar-primary)\\n* [ Skip to footer](#genesis-footer-widgets)\\n  \\n  \\n![building autonomous AI agents](https://proxy-prod.omnivore-image-cache.app/700x466,srVn9yNKnBcB845x708QjEUQfC3nvaSSLDDezPadHDK0/https://www.geeky-gadgets.com/wp-content/uploads/2023/09/building-autonomous-AI-agents.webp)\\n\\nIf you are considering building your very own AI agents to either resell or streamline your workflow and business you might be interested in this overview guide which provides a little more **insight on where to get started**. With the recent explosion of [ChatGPT](https://openai.com/blog/chatgpt) and other similar services such as[ Llama 2](https://www.geeky-gadgets.com/llama-2-code-llama-online-free/) an open source version which can be installed locally and trained using your own data. Artificial Intelligence (AI) agents will play a pivotal role in how these new technologies can be used to **streamline mundane tasks as well as more complicated tasks** such as customer interactions and more.\\n\\n## What are AI Agents?\\n\\nAn AI agent is essentially a software program that can perform tasks, make decisions, and even learn from its interactions. Unlike traditional software, **AI agents are designed to operate with some level of autonomy**, guided by algorithms and machine learning models.\\n\\nFirst, think of a software program as a set of instructions that tells a computer what to do. For example, a simple calculator program tells the computer to take two numbers, perform an operation like addition or multiplication, and then show the result.\\n\\nNow, traditional software programs can be pretty smart, but they only do exactly what they’re programmed to do. They can’t adapt or change their behavior based on new information. An AI agent, on the other hand, is like a **more advanced version of a software program.** It not only follows instructions but can also “think” for itself to some extent.\\n\\nWhen we say AI agents operate with “**some level of autonomy,**” we mean that they can make decisions without a human telling them what to do every step of the way. For instance, if an AI agent is programmed to sort emails, it could decide on its own which emails are spam and which ones are important, based on what it has learned.\\n\\n**Algorithms are like the “brain” of the AI agent.** They’re complex mathematical rules that help the agent decide what to do. Sometimes these algorithms can “learn” from past experiences, which is where machine learning comes in.\\n\\nMachine learning **models allow the AI agent to get better at its job over time.** For example, let’s say the AI agent makes a mistake and puts an important email in the spam folder. If you correct it, the agent can “learn” from this experience and is less likely to make the same mistake in the future.\\n\\nThe coolest part is that AI agents can interact with their environment (which could be a website, a database, or even sensors in the real world) and **learn from these interactions.** This is similar to how you learn from your experiences; if you touch a hot stove, you learn not to do it again.\\n\\nSo, in a nutshell, an AI agent is like a super-smart software program that can not only follow instructions but also make its own decisions and learn from its mistakes, all thanks to complex algorithms and machine learning models.\\n\\n## An overview of how to build autonomous AI agents\\n\\nCheck out the video and pointers below for an overview of what AI agents are capable of and future uses to inspire you to create your very own and tailor them to your exact workflows or those of your clients.\\n\\nOther articles you may find of interest on the subject of AI agents :\\n\\n* [Abacus AI helps you build and host LLMs apps and AI Agents at](https://www.geeky-gadgets.com/build-and-host-llm-and-ai-agents/)\\n* [How to install SuperAGI for autonomous AI agent deployment](https://www.geeky-gadgets.com/how-to-install-superagi/)\\n* [What is the best AI Agent LLM for AI reasoning?](https://www.geeky-gadgets.com/the-best-ai/)\\n* [Build an autonomous AI research agent with no hallucinations](https://www.geeky-gadgets.com/autonomous-ai-research-agent/)\\n* [Zoom Virtual Agent conversational AI and chatbot](https://www.geeky-gadgets.com/zoom-virtual-agent-25-01-2023/)\\n\\n### Key Characteristics of AI Agents:\\n\\n* **Autonomy**: Ability to operate without human intervention.\\n* **Adaptability**: Capability to learn and improve from experience.\\n* **Goal-Oriented**: Designed to achieve specific objectives.\\n\\n**Types of AI Agents**\\n\\nDepending on your business needs, various types of AI agents can be employed. These include:\\n\\n* **Reactive Agents**: Respond to external stimuli and follow predefined rules. Ideal for customer service chatbots.\\n* **Model-Based Agents**: Utilize an internal model of the world to make decisions. Useful for inventory management.\\n* **Goal-Based Agents**: Equipped with a set of objectives and make decisions to achieve them. Often used in marketing analytics.\\n* **Utility-Based Agents**: Evaluate the utility or usefulness of each action to make the best decision. Commonly found in financial analysis.\\n\\nCreating an AI agent from scratch requires expertise in programming and machine learning. But, to enhance your experience, many platforms offer pre-built agents that can be modified to fit your specific requirements.\\n\\n### Things to consider when building a custom AI agent\\n\\n1. **Identify Objectives**: Clearly define what you want the agent to achieve.\\n2. **Choose the Type**: Select the type of agent that best suits your needs.\\n3. **Data Collection**: Gather the data the agent will need for training.\\n4. **Training and Testing**: Use machine learning algorithms to train the agent and then test its performance.\\n5. **Deployment**: Once satisfied, integrate the agent into your business processes.\\n\\n## Fine tuning automation for specific tasks\\n\\nFine-tuning involves making incremental adjustments to the agent’s algorithms to better suit its tasks. For example, if your chatbot is not adequately resolving customer queries, you might tweak its natural language processing (NLP) algorithms for better comprehension.\\n\\n* **Algorithm Efficiency**: Optimize the algorithms to perform tasks faster.\\n* **Data Sensitivity**: Adjust how sensitive the agent is to variations in data.\\n* **User Interaction**: Improve the user interface for better user-agent interaction.\\n\\n## AI agents for business\\n\\nCompanies like Google and IBM have significantly contributed to AI agent development through platforms like [Dialogflow](https://cloud.google.com/dialogflow/) and [Watson](https://www.ibm.com/products/watsonx-ai). These platforms offer a range of customization options, making it easier for businesses to adopt AI agents into their ecosystems.\\n\\nThese programmable AI agents can handle a multitude of tasks, from customer service to supply chain management. In this article, we’ll delve deep into what AI agents are, how they can be customized, and fine-tuned to automate business processes. However should be aware that AI agents require ongoing maintenance to adapt to changing conditions or to incorporate new data. Regular updates and fine-tuning are essential for optimum performance.\\n\\nAI agents offer a **dynamic solution for automating business processes**. By understanding their types and characteristics, and by following the steps for customization and fine-tuning, you can integrate these powerful tools into your business ecosystem. Whether it’s customer service, marketing, or any other domain, AI agents provide a scalable and efficient way to meet your business objectives.\\n\\nA few other articles you may find of interest on developing AI agents for autonomous workflows :\\n\\n* [How to build a Llama 2 LangChain conversational agent](https://www.geeky-gadgets.com/llama-2-langchain-conversational-agent/)\\n* [Conversational AI can help answer your customers questions](https://www.geeky-gadgets.com/conversational-ai/)\\n* [5 AI tools to improve your coding or workflow](https://www.geeky-gadgets.com/ai-tools-28-06-2023/)\\n* [New AgentBench LLM AI model benchmarking tool](https://www.geeky-gadgets.com/new-agentbench-llm-ai-model-benchmarking-tool-and-leaderboards/)\\n* [How to use GPT Engineer to build complete apps](https://www.geeky-gadgets.com/how-to-use-gpt-engineer/)\\n* [ ](https://www.facebook.com/dialog/feed?app%5Fid=364456067078847&display=popup&caption=An%20introduction%20to%20building%20autonomous%20AI%20agents&link=https%3A%2F%2Fwww.geeky-gadgets.com%2Fbuilding-autonomous-ai-agents%2F&description=%0D%0A%0D%0AIf%20you%20are%20considering%20building%20your%20very%20own%20AI%20agents%20to%20either%20resell%20or%20streamline%20your%20workflow%20and%20business%20you%20might%20be%20interested%20in%20this%20overview%20guide%20which%20provides%20a%20little%20more%20insight%20on%20where%20%E2%80%A6&picture=https%3A%2F%2Fwww.geeky-gadgets.com%2Fwp-content%2Fuploads%2F2023%2F09%2Fbuilding-autonomous-AI-agents.jpg \\\"Share on Facebook\\\")\\n* [ ](https://twitter.com/intent/tweet?text=An%20introduction%20to%20building%20autonomous%20AI%20agents%20https%3A%2F%2Fwww.geeky-gadgets.com%2Fbuilding-autonomous-ai-agents%2F \\\"Tweet\\\")\\n* [ ](https://pinterest.com/pin/create/bookmarklet/?media=https%3A%2F%2Fwww.geeky-gadgets.com%2Fwp-content%2Fuploads%2F2023%2F09%2Fbuilding-autonomous-AI-agents.jpg&url=https%3A%2F%2Fwww.geeky-gadgets.com%2Fbuilding-autonomous-ai-agents%2F&is%5Fvideo=false&description=An%20introduction%20to%20building%20autonomous%20AI%20agents%20-%20%0D%0A%0D%0AIf%20you%20are%20considering%20building%20your%20very%20own%20AI%20agents%20to%20either%20resell%20or%20streamline%20your%20workflow%20and%20business%20you%20might%20be%20interested%20in%20this%20overview%20guide%20which%20provides%20a%20little%20more%20insight%20on%20where%20%E2%80%A6 \\\"Pin\\\")\\n* [ ](mailto:?subject=An%20introduction%20to%20building%20autonomous%20AI%20agents&body=%0D%0A%0D%0AIf%20you%20are%20considering%20building%20your%20very%20own%20AI%20agents%20to%20either%20resell%20or%20streamline%20your%20workflow%20and%20business%20you%20might%20be%20interested%20in%20this%20overview%20guide%20which%20provides%20a%20little%20more%20insight%20on%20where%20%E2%80%A6%20https%3A%2F%2Fwww.geeky-gadgets.com%2Fbuilding-autonomous-ai-agents%2F \\\"Email\\\")\\n\\nFiled Under: [Guides](https://www.geeky-gadgets.com/category/guides/), [Top News](https://www.geeky-gadgets.com/category/top-news/)\\n\\n**Latest Geeky Gadgets Deals**\\n\\n**Disclosure:** Some of our articles include affiliate links. If you buy something through one of these links, Geeky Gadgets may earn an affiliate commission. Learn about our [ Disclosure Policy](https://www.geeky-gadgets.com/disclosure-policy/).\",\"highlights\":[],\"labels\":[{\"id\":\"b1cf66be-3164-11ef-b788-e783d7a226aa\",\"name\":\"ai-agents\",\"color\":\"#FF5D99\",\"description\":null,\"createdAt\":\"2024-06-23T13:30:02.000Z\"},{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\",\"description\":\"\",\"createdAt\":\"2023-12-30T20:44:43.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:36:15,841 - INFO - Processing article: An introduction to building autonomous AI agents - Geeky Gadgets\n",
      "2024-07-04 23:36:22,471 - INFO - >>> {\"query\": \"query GetArticle($username: String!, $slug: String!, $format: String, $includeFriendsHighlights: Boolean) {\\n  article(username: $username, slug: $slug, format: $format) {\\n    ... on ArticleSuccess {\\n      article {\\n        ...ArticleFields\\n        content\\n        highlights(input: {includeFriends: $includeFriendsHighlights}) {\\n          ...HighlightFields\\n        }\\n        labels {\\n          ...LabelFields\\n        }\\n        recommendations {\\n          ...RecommendationFields\\n        }\\n      }\\n    }\\n    ... on ArticleError {\\n      errorCodes\\n    }\\n  }\\n}\\n\\nfragment ArticleFields on Article {\\n  id\\n  title\\n  url\\n  author\\n  image\\n  savedAt\\n  createdAt\\n  publishedAt\\n  contentReader\\n  originalArticleUrl\\n  readingProgressPercent\\n  readingProgressTopPercent\\n  readingProgressAnchorIndex\\n  slug\\n  isArchived\\n  description\\n  linkId\\n  state\\n  wordsCount\\n}\\n\\nfragment HighlightFields on Highlight {\\n  id\\n  type\\n  shortId\\n  quote\\n  prefix\\n  suffix\\n  patch\\n  annotation\\n  createdByMe\\n  createdAt\\n  updatedAt\\n  sharedAt\\n  highlightPositionPercent\\n  highlightPositionAnchorIndex\\n  labels {\\n    id\\n    name\\n    color\\n    createdAt\\n  }\\n}\\n\\nfragment LabelFields on Label {\\n  id\\n  name\\n  color\\n  description\\n  createdAt\\n}\\n\\nfragment RecommendationFields on Recommendation {\\n  id\\n  name\\n  note\\n  user {\\n    userId\\n    name\\n    username\\n    profileImageURL\\n  }\\n  recommendedAt\\n}\", \"variables\": {\"username\": \"toddwalters\", \"slug\": \"how-to-build-an-autonomous-ai-research-agent-running-24-7-geeky--18d3e8facb2\", \"format\": \"markdown\"}}\n",
      "2024-07-04 23:36:22,690 - INFO - <<< {\"data\":{\"article\":{\"article\":{\"id\":\"287583a2-3237-4f86-a2a1-26df352bc21c\",\"title\":\"How to build an autonomous AI research agent running 24/7 - Geeky Gadgets\",\"url\":\"https://www.geeky-gadgets.com/build-an-autonomous-ai-research-agent/\",\"author\":\"Julian Horsey\",\"image\":\"https://proxy-prod.omnivore-image-cache.app/320x320,sh0ra00QgWg-ZNzSdIu7E7vcalX2_z0YaiZrYCHnLE2k/https://www.geeky-gadgets.com/wp-content/uploads/2023/09/build-an-autonomous-AI-research-agent.jpg\",\"savedAt\":\"2024-01-25T03:00:18.000Z\",\"createdAt\":\"2024-01-25T03:00:17.000Z\",\"publishedAt\":\"2023-09-22T13:35:37.000Z\",\"contentReader\":\"WEB\",\"originalArticleUrl\":\"https://www.geeky-gadgets.com/build-an-autonomous-ai-research-agent/\",\"readingProgressPercent\":100,\"readingProgressTopPercent\":0,\"readingProgressAnchorIndex\":74,\"slug\":\"how-to-build-an-autonomous-ai-research-agent-running-24-7-geeky--18d3e8facb2\",\"isArchived\":false,\"description\":\"Learn how to build an autonomous AI research agent using LangChain allowing you to can doubt research 24-hour is a day seven days a week.\",\"linkId\":null,\"state\":\"SUCCEEDED\",\"wordsCount\":715,\"content\":\"* [ Skip to main content](#genesis-content)\\n* [ Skip to secondary menu](#genesis-nav-secondary)\\n* [ Skip to primary sidebar](#genesis-sidebar-primary)\\n* [ Skip to footer](#genesis-footer-widgets)\\n  \\n  \\n![How to build an autonomous AI research agent](https://proxy-prod.omnivore-image-cache.app/700x466,sgXOD5fhbhLlvrwibYOrP_JEVOchdv4iy24OST6YcNpw/https://www.geeky-gadgets.com/wp-content/uploads/2023/09/How-to-build-an-autonomous-AI-research-agent.webp)\\n\\nIf you would like to build your very own **autonomous AI research agent** that is capable of **running 24-hours** a day seven days a week scouring the web for anything you ask it. You might be interested in a new tutorial by [Michael Borman](https://www.youtube.com/@michaelborman) who has kindly uploaded the code to GitHub for you to download and tweak to your exact requirements.\\n\\nBuilding a research agent using **LangChain** and integrating it into a product is a complex yet rewarding process. This process involves several steps, including building a tool for search and scraping, creating a Lang chain agent, hosting the web app using Streamlit, and using**[ Fast API](https://fastapi.tiangolo.com/) to turn the code into an API.** The API can then be integrated into a product through Zapier automation, hosted as an API using Fast API, and connected to Google Sheets or a CRM using Zapier.\\n\\nThe first step in building a research agent using Lang chain code is to create a tool for search and scraping. This tool uses a web search tool to find links and a web scraper tool to extract data from those pages. The agent iterates these steps until it has enough research to answer the question, then passes the output back. The video demonstrates how to build the search and scraping tools, using the [SerpApi](https://serpapi.com/) for web search and the [BrowseList API](https://github.com/browserslist/browserslist) for web scraping.\\n\\nOther articles you may find of interest on the subject of LangChain and autonomous AI agents :\\n\\n* [How to use LangChain with cloud hosted Redis](https://www.geeky-gadgets.com/how-to-use-langchain-with-redis/)\\n* [How to build a Llama 2 LangChain conversational agent](https://www.geeky-gadgets.com/llama-2-langchain-conversational-agent/)\\n* [How to fine tune ChatGPT 3.5 Turbo for LangChain Agents](https://www.geeky-gadgets.com/fine-tune-chatgpt/)\\n* [Make a personal AI assistant from scratch using RAG and LangChain](https://www.geeky-gadgets.com/build-a-personal-ai-assistant/)\\n* [How to use LangChain to extend ChatGPT search](https://www.geeky-gadgets.com/how-to-use-langchain/)\\n\\nOnce the search and scraping tools are built, the next step is to create a Lang chain agent. This agent is instantiated with a list of tools, a language model, and a type of agent. The agent is given a general system message that instructs it on its task and how many iterations to perform. The Python library Beautiful Soup is used to clean the data and extract the text from the HTML page. The agent then uses a summarizer to reduce the data to the necessary information, using a method called Map Reduce.\\n\\nAfter the Lang chain agent is created, the next step is to host the web app using [Streamlit](https://streamlit.io/). A simple front-end that can quickly get the application up and running. The agent can be tested using Streamlit to ensure it is functioning correctly. Once the web app is hosted and tested, the next step is to use Fast API to turn the code into an API. This allows the agent to be hosted as an API, which can be queried from anywhere on the web. The API can be [hosted on Render](https://render.com/pricing), a platform that allows for easy hosting of applications.\\n\\nThe final step in building a research agent using LangChain code is to integrate the API into a product through Zapier automation. This allows the API to be connected to Google Sheets or a CRM using [Zapier](https://learn.zapier.com/). This integration allows for automated research on leads, making the research agent a valuable tool for identifying the best prospects for a product.\\n\\nBuilding a research agent using Lang chain code and integrating it into a product involves several steps, but the end result is a powerful tool for automated research. By following these steps, one can create a research agent that can scrape the web, provide research on any topic, and be integrated into a product for automated lead research.\\n\\n**You might be interested in other automation systems created using AI and Zapier :**\\n\\n* [ChatGPT Zapier plugin makes AI automation](https://www.geeky-gadgets.com/ai-automation-chatgpt-zapier-plugin/)\\n* [Automate Shopify product creation using ChatGPT and Zapier](https://www.geeky-gadgets.com/automate-shopify/)\\n* [How to use ChatGPT and Zapier to create no-code automation](https://www.geeky-gadgets.com/chatgpt-zapier-workflows/)\\n* [Automate tasks with ChatGPT and no-code automation](https://www.geeky-gadgets.com/chatgpt-zapier/)\\n* [Learn how to use ChatGPT AI automation with Zapier](https://www.geeky-gadgets.com/chatgpt-automation/)\\n* [ ](https://www.facebook.com/dialog/feed?app%5Fid=364456067078847&display=popup&caption=How%20to%20build%20an%20autonomous%20AI%20research%20agent%20running%2024%2F7&link=https%3A%2F%2Fwww.geeky-gadgets.com%2Fbuild-an-autonomous-ai-research-agent%2F&description=%0D%0A%0D%0AIf%20you%20would%20like%20to%20build%20your%20very%20own%20autonomous%20AI%20research%20agent%20that%20is%20capable%20of%20running%2024-hours%20a%20day%20seven%20days%20a%20week%20scouring%20the%20web%20for%20anything%20you%20ask%20it.%20You%20might%20%E2%80%A6&picture=https%3A%2F%2Fwww.geeky-gadgets.com%2Fwp-content%2Fuploads%2F2023%2F09%2Fbuild-an-autonomous-AI-research-agent.jpg \\\"Share on Facebook\\\")\\n* [ ](https://twitter.com/intent/tweet?text=How%20to%20build%20an%20autonomous%20AI%20research%20agent%20running%2024%2F7%20https%3A%2F%2Fwww.geeky-gadgets.com%2Fbuild-an-autonomous-ai-research-agent%2F \\\"Tweet\\\")\\n* [ ](https://pinterest.com/pin/create/bookmarklet/?media=https%3A%2F%2Fwww.geeky-gadgets.com%2Fwp-content%2Fuploads%2F2023%2F09%2Fbuild-an-autonomous-AI-research-agent.jpg&url=https%3A%2F%2Fwww.geeky-gadgets.com%2Fbuild-an-autonomous-ai-research-agent%2F&is%5Fvideo=false&description=How%20to%20build%20an%20autonomous%20AI%20research%20agent%20running%2024%2F7%20-%20%0D%0A%0D%0AIf%20you%20would%20like%20to%20build%20your%20very%20own%20autonomous%20AI%20research%20agent%20that%20is%20capable%20of%20running%2024-hours%20a%20day%20seven%20days%20a%20week%20scouring%20the%20web%20for%20anything%20you%20ask%20it.%20You%20might%20%E2%80%A6 \\\"Pin\\\")\\n* [ ](mailto:?subject=How%20to%20build%20an%20autonomous%20AI%20research%20agent%20running%2024%2F7&body=%0D%0A%0D%0AIf%20you%20would%20like%20to%20build%20your%20very%20own%20autonomous%20AI%20research%20agent%20that%20is%20capable%20of%20running%2024-hours%20a%20day%20seven%20days%20a%20week%20scouring%20the%20web%20for%20anything%20you%20ask%20it.%20You%20might%20%E2%80%A6%20https%3A%2F%2Fwww.geeky-gadgets.com%2Fbuild-an-autonomous-ai-research-agent%2F \\\"Email\\\")\\n\\nFiled Under: [Guides](https://www.geeky-gadgets.com/category/guides/), [Top News](https://www.geeky-gadgets.com/category/top-news/)\\n\\n**Latest Geeky Gadgets Deals**\\n\\n**Disclosure:** Some of our articles include affiliate links. If you buy something through one of these links, Geeky Gadgets may earn an affiliate commission. Learn about our [ Disclosure Policy](https://www.geeky-gadgets.com/disclosure-policy/).\",\"highlights\":[],\"labels\":[{\"id\":\"431a395a-a754-11ee-b441-e7703958e2e7\",\"name\":\"llm\",\"color\":\"#F73600\",\"description\":\"\",\"createdAt\":\"2023-12-30T20:44:43.000Z\"},{\"id\":\"b1cf66be-3164-11ef-b788-e783d7a226aa\",\"name\":\"ai-agents\",\"color\":\"#FF5D99\",\"description\":null,\"createdAt\":\"2024-06-23T13:30:02.000Z\"},{\"id\":\"c5345604-3161-11ef-b94c-b32e8e412360\",\"name\":\"projects\",\"color\":\"#FF4A2B\",\"description\":null,\"createdAt\":\"2024-06-23T13:09:06.000Z\"}],\"recommendations\":[]}}}}\n",
      "\n",
      "2024-07-04 23:36:22,693 - INFO - Processing article: How to build an autonomous AI research agent running 24/7 - Geeky Gadgets\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import pandas as pd\n",
    "import logging\n",
    "import re\n",
    "from omnivoreql import OmnivoreQL\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Omnivore and OpenAI API details\n",
    "OMNIVORE_API_KEY = os.getenv(\"OMNIVORE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OMNIVORE_USERNAME = os.getenv(\"OMNIVORE_USERNAME\")\n",
    "\n",
    "# Validate API keys\n",
    "if not OMNIVORE_API_KEY or not OPENAI_API_KEY or not OMNIVORE_USERNAME:\n",
    "    logging.error(\"Missing API key(s). Ensure OMNIVORE_API_KEY, OPENAI_API_KEY, and OMNIVORE_USERNAME are set.\")\n",
    "    exit(1)\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Initialize Omnivore client\n",
    "omnivore_client = OmnivoreQL(OMNIVORE_API_KEY)\n",
    "\n",
    "def get_my_articles_with_label(label, filename=\"articles.json\"):\n",
    "    \"\"\"Fetch articles with a specific label, caching results to a file.\"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            with open(filename, 'r') as file:\n",
    "                return json.load(file)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading articles from file: {e}\")\n",
    "\n",
    "    try:\n",
    "        response = omnivore_client.get_articles(\n",
    "            format=\"markdown\",\n",
    "            limit=100,\n",
    "            query=f\"in:inbox AND label:{label}\",\n",
    "            include_content=False\n",
    "        )\n",
    "        articles = [item['node'] for item in response['search']['edges']]\n",
    "\n",
    "        try:\n",
    "            with open(filename, 'w') as file:\n",
    "                json.dump(articles, file)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error writing articles to file: {e}\")\n",
    "\n",
    "        return articles\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching articles: {e}\")\n",
    "        return []\n",
    "    \n",
    "def openai_request(prompt, max_tokens=150):\n",
    "    \"\"\"Send a request to the OpenAI API.\"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        return response.choices[0].message['content'].strip()\n",
    "    except openai.OpenAIError as e:\n",
    "        logging.error(f\"OpenAI error: {e}\")\n",
    "        return \"Error during OpenAI request\"\n",
    "    \n",
    "def summarize_article(content):\n",
    "    \"\"\"Generate a summary for an article using the OpenAI API.\"\"\"\n",
    "    try:\n",
    "        return openai_request(f\"Summarize the following article in three sentences:\\n\\n{content}\", max_tokens=150)\n",
    "    except openai.Error as e:\n",
    "        # Log OpenAI API specific errors\n",
    "        logging.error(f\"OpenAI API error: {e}\")\n",
    "    except Exception as e:\n",
    "        # Log other exceptions\n",
    "        logging.error(f\"General error when calling OpenAI API: {e}\")\n",
    "\n",
    "def generate_tags(content, labels):\n",
    "    \"\"\"Generate tags for an article using the OpenAI API.\"\"\"\n",
    "    tags = \"ai, ai-governance, ai-optimization, ai-reliability, ai-security, agi, anthropic, apple, automation, aws, azure, claude, cloud, cloud-computing, cyber-security, data-science, deep-learning, developer-experience, ethical-ai, enterprise-architecture, fin-ops, gcp, generative-ai, github, github-actions, github-repo, gpt-4, jupyter-notebooks, langchain, llm, machine-learning, nlp, openai, personal-development, projects, python, rag, responsible-ai, security\"\n",
    "    prompt = (\n",
    "        f\"Extract and process the tags from the following list: {labels}. \"\n",
    "        f\"Remove all single quotes and brackets, resulting in a comma-separated list of tags that only contains letters, numbers, and dashes. \"\n",
    "        f\"From this list, determine how many tags are present and subtract that number from five to determine how many additional tags are needed. \"\n",
    "        f\"From the following list of available tags: {tags}, select additional tags that match the content of the article below, ensuring the total number of tags is five. \"\n",
    "        f\"If there are not enough matching tags from the provided list, create new tags following these rules: \"\n",
    "        f\"1. Use no more than three words, \"\n",
    "        f\"2. Use only lowercase letters, \"\n",
    "        f\"3. Replace spaces with dashes. \"\n",
    "        f\"Return exactly five tags as a comma-separated list with no additional text or explanation. \"\n",
    "        f\"Here is the article content:\\n\\n{content}\"\n",
    "    )\n",
    "    try:\n",
    "        return openai_request(prompt, max_tokens=150)\n",
    "    except openai.Error as e:\n",
    "        # Log OpenAI API specific errors\n",
    "        logging.error(f\"OpenAI API error: {e}\")\n",
    "    except Exception as e:\n",
    "        # Log other exceptions\n",
    "        logging.error(f\"General error when calling OpenAI API: {e}\")\n",
    "\n",
    "\n",
    "def get_web_page_content(slug):\n",
    "    \"\"\"Retrieve the web page content for a given article slug.\"\"\"\n",
    "    try:\n",
    "        response = omnivore_client.get_article(\n",
    "            username=OMNIVORE_USERNAME,\n",
    "            slug=slug,\n",
    "            format=\"markdown\"\n",
    "        )\n",
    "        return response['article']['article']['content']\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching article content: {e}\")\n",
    "        return \"\"\n",
    "    \n",
    "def process_articles(articles, exclude_label):\n",
    "    \"\"\"Process articles to generate summaries and tags.\"\"\"\n",
    "    processed_articles = []\n",
    "    if os.path.exists('processed_articles.csv'):\n",
    "        processed_articles = pd.read_csv('processed_articles.csv').to_dict('records')\n",
    "    else:\n",
    "        for article in articles:\n",
    "            title = article.get(\"title\", \"Untitled\")\n",
    "            site_name = article.get(\"siteName\", \"Unknown\")\n",
    "            description = article.get(\"description\", \"\")\n",
    "            link = article.get(\"url\", \"\")\n",
    "            slug = article.get(\"slug\", \"\")\n",
    "            labels = [label['name'] for label in article['labels'] if label['name'] != exclude_label]\n",
    "            content = get_web_page_content(slug)\n",
    "            if content:\n",
    "                logging.info(f\"Processing article: {title}\")\n",
    "                summary = summarize_article(content)\n",
    "                if \"no content\" in summary.lower():\n",
    "                    tags = ['None']\n",
    "                else:\n",
    "                    tags = generate_tags(content, labels).split(\",\")\n",
    "                    tags = [tag.strip() for tag in tags]\n",
    "                processed_articles.append({\n",
    "                    \"title\": title,\n",
    "                    \"tags\": tags,\n",
    "                    \"site_name\": site_name,\n",
    "                    \"description\": description,\n",
    "                    \"link\": link,\n",
    "                    \"slug\": slug,\n",
    "                    \"content\": content,\n",
    "                    \"summary\": summary\n",
    "                })\n",
    "            else:\n",
    "                logging.warning(f\"Skipping article {title} due to missing content\")\n",
    "        pd.DataFrame(processed_articles).to_csv('processed_articles.csv', index=False)\n",
    "    return processed_articles\n",
    "\n",
    "def create_markdown_content(processed_articles):\n",
    "    \"\"\"Create markdown content from processed articles.\"\"\"\n",
    "    md_content = \"# Articles Summary\\n\\n\"\n",
    "    for article in processed_articles:\n",
    "        # Ensure article['tags'] is a list\n",
    "        tags = article['tags'] if isinstance(article['tags'], list) else [article['tags']]\n",
    "        \n",
    "        # Prepend '#' to each tag and join them with a space\n",
    "        formatted_tags = ', '.join([f\"#{tag}\" for tag in tags])\n",
    "        md_content += (\n",
    "            f\"### [{article['title']}]({article['link']})\\n\\n\"\n",
    "            f\"**Tags:** *{formatted_tags}*\\n\\n\"\n",
    "            f\"**Site Name:** {article['site_name']}\\n\\n\"\n",
    "            f\"**Omnivore Description:** {article['description']}\\n\\n\"\n",
    "            f\"**ChatGPT Summary:** {article['summary']}\\n\\n\"\n",
    "        )\n",
    "    return md_content\n",
    "\n",
    "def write_to_markdown_with_grouping(processed_articles, blog_title, filename):\n",
    "    \"\"\"Write processed articles to a markdown file with front matter and tags.\"\"\"\n",
    "    unique_tags = sorted({tag for article in processed_articles for tag in article['tags'] if tag != 'None'})\n",
    "    formatted_tags = \", \".join([f'\"{tag.strip()}\"' for tag in unique_tags])\n",
    "    current_datetime = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "    blog_article_md = create_markdown_content(processed_articles)\n",
    "    front_matter = f\"---\\ntitle: {blog_title}\\ndate: {current_datetime}\\ntags: [{formatted_tags}]\\n---\\n\\n\"\n",
    "    blog_article_md = front_matter + blog_article_md\n",
    "    \n",
    "    return front_matter, blog_article_md\n",
    "\n",
    "def extract_articles(content):\n",
    "    \"\"\"Extract articles from the given content.\"\"\"\n",
    "    try:\n",
    "        articles = re.findall(\n",
    "            r'### \\[(.*?)\\]\\((.*?)\\)\\n\\n\\*\\*Tags:\\*\\* \\*(.*?)\\*\\n\\n\\*\\*Site Name:\\*\\* (.*?)\\n\\n\\*\\*Omnivore Description:\\*\\* (.*?)\\n\\n\\*\\*ChatGPT Summary:\\*\\* (.*?)\\n\\n',\n",
    "            content, re.DOTALL\n",
    "        )\n",
    "        return [{'title': title, 'link': link, 'tags': tags, 'site_name': site_name, 'description': description, 'summary': summary} for title, link, tags, site_name, description, summary in articles]\n",
    "    except openai.Error as e:\n",
    "        # Log OpenAI API specific errors\n",
    "        logging.error(f\"OpenAI API error: {e}\")\n",
    "    except Exception as e:\n",
    "        # Log other exceptions\n",
    "        logging.error(f\"General error when calling OpenAI API: {e}\")\n",
    "\n",
    "\n",
    "def generate_categories(articles):\n",
    "    \"\"\"Generate categories for articles using OpenAI API.\"\"\"\n",
    "    prompts = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Group the following articles into 2-5 broad categories based on their tags and content. Provide category names and associate each article with a single category. Format the output as follows:\\n\\n- Category Name\\n  - Article Title\\n  - Article Title\\n\\nThe articles are: \" + \"\\n\".join([f\"Title: {article['title']}, Tags: {article['tags']}\" for article in articles])}\n",
    "    ]\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=prompts,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        return response.choices[0].message['content'].strip()\n",
    "    except openai.Error as e:\n",
    "        # Log OpenAI API specific errors\n",
    "        logging.error(f\"OpenAI API error: {e}\")\n",
    "    except Exception as e:\n",
    "        # Log other exceptions\n",
    "        logging.error(f\"General error when calling OpenAI API: {e}\")\n",
    "\n",
    "\n",
    "def parse_categories_response(response):\n",
    "    \"\"\"Parse the categories response from the OpenAI API.\"\"\"\n",
    "    categories = {}\n",
    "    current_category = None\n",
    "    for line in response.split(\"\\n\"):\n",
    "        if line.startswith(\"- \"):\n",
    "            current_category = line[2:].strip()\n",
    "            categories[current_category] = []\n",
    "        elif line.startswith(\"  - \") and current_category:\n",
    "            title = line[4:].strip()\n",
    "            categories[current_category].append(title)\n",
    "    return categories\n",
    "\n",
    "def map_articles_to_categories(articles, categories):\n",
    "    \"\"\"Map articles to categories and extract unique tags.\"\"\"\n",
    "    categorized_articles = {category: {'articles': [], 'tags': set()} for category in categories.keys()}\n",
    "    for article in articles:\n",
    "        for category, titles in categories.items():\n",
    "            if article['title'] in titles:\n",
    "                categorized_articles[category]['articles'].append(article)\n",
    "                for tag in article['tags'].split(','):\n",
    "                    categorized_articles[category]['tags'].add(tag.strip())\n",
    "                break\n",
    "    return categorized_articles\n",
    "\n",
    "def create_table_of_contents(categorized_articles):\n",
    "    \"\"\"Create a table of contents for the categorized articles.\"\"\"\n",
    "    toc = \"# Table of Contents\\n\\n\"\n",
    "    for category in categorized_articles.keys():\n",
    "        toc += f\"- [{category}](#{category.lower().replace(' ', '-')})\\n\"\n",
    "        for article in categorized_articles[category]['articles']:\n",
    "            toc += f\"  - [{article['title']}]({article['link']})\\n\"\n",
    "    # toc += \"\\n-----\\n\\n\"\n",
    "    return toc\n",
    "\n",
    "def create_categorized_markdown_content(categorized_articles):\n",
    "    \"\"\"Create categorized markdown content.\"\"\"\n",
    "    md_content = \"\"\n",
    "    for category, data in categorized_articles.items():\n",
    "        tags_list = ', '.join(sorted(data['tags']))\n",
    "        md_content += f\"-----\\n\\n# {category}\\n\\n**Category Tags:** {tags_list}\\n\\n\"\n",
    "        for article in data['articles']:\n",
    "            md_content += (\n",
    "                f\"### [{article['title']}]({article['link']})\\n\\n\"\n",
    "                f\"**Tags:** *{article['tags']}*\\n\\n\"\n",
    "                f\"**Site Name:** {article['site_name']}\\n\\n\"\n",
    "                f\"**Omnivore Description:** {article['description']}\\n\\n\"\n",
    "                f\"**ChatGPT Summary:** {article['summary']}\\n\\n\"\n",
    "            )\n",
    "        md_content += \"\\n\"\n",
    "    return md_content\n",
    "\n",
    "def main(blog_title, label, filename):\n",
    "    \"\"\"Main function to process and categorize articles, then generate the markdown file.\"\"\"\n",
    "    articles = get_my_articles_with_label(label)\n",
    "    if articles:\n",
    "        processed_articles = process_articles(articles, label)\n",
    "        front_matter, blog_article_md = write_to_markdown_with_grouping(processed_articles, blog_title, filename)\n",
    "    else:\n",
    "        logging.info(\"No articles found with the specified label.\")\n",
    "        return\n",
    "\n",
    "    extracted_articles = extract_articles(blog_article_md)\n",
    "\n",
    "    # Generate categories and categorize articles\n",
    "    categories_response = generate_categories(extracted_articles)\n",
    "    categories = parse_categories_response(categories_response)\n",
    "    categorized_articles = map_articles_to_categories(extracted_articles, categories)\n",
    "\n",
    "    # Create table of contents\n",
    "    toc = create_table_of_contents(categorized_articles)\n",
    "\n",
    "    # Create markdown content\n",
    "    articles_content = create_categorized_markdown_content(categorized_articles)\n",
    "\n",
    "    # Combine TOC and articles content\n",
    "    final_markdown_content = front_matter + toc + articles_content\n",
    "\n",
    "    # Write the final markdown content to a file\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(final_markdown_content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(blog_title=\"My Blog Title\", label=\"projects\", filename=\"index.md\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
